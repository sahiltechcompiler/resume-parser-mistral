{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9635974304068522,
  "eval_steps": 500,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005353319057815846,
      "grad_norm": 0.0,
      "learning_rate": 2e-05,
      "loss": 1.4505,
      "step": 1
    },
    {
      "epoch": 0.0010706638115631692,
      "grad_norm": 0.0,
      "learning_rate": 1.998929336188437e-05,
      "loss": 1.6336,
      "step": 2
    },
    {
      "epoch": 0.0016059957173447537,
      "grad_norm": 0.0,
      "learning_rate": 1.997858672376874e-05,
      "loss": 1.528,
      "step": 3
    },
    {
      "epoch": 0.0021413276231263384,
      "grad_norm": 0.0,
      "learning_rate": 1.9967880085653108e-05,
      "loss": 1.6774,
      "step": 4
    },
    {
      "epoch": 0.0026766595289079227,
      "grad_norm": 0.0,
      "learning_rate": 1.9957173447537473e-05,
      "loss": 1.4224,
      "step": 5
    },
    {
      "epoch": 0.0032119914346895075,
      "grad_norm": 0.0,
      "learning_rate": 1.994646680942184e-05,
      "loss": 2.0211,
      "step": 6
    },
    {
      "epoch": 0.003747323340471092,
      "grad_norm": 0.0,
      "learning_rate": 1.993576017130621e-05,
      "loss": 1.4537,
      "step": 7
    },
    {
      "epoch": 0.004282655246252677,
      "grad_norm": 0.0,
      "learning_rate": 1.992505353319058e-05,
      "loss": 1.3645,
      "step": 8
    },
    {
      "epoch": 0.004817987152034261,
      "grad_norm": 0.0,
      "learning_rate": 1.9914346895074948e-05,
      "loss": 1.6942,
      "step": 9
    },
    {
      "epoch": 0.0053533190578158455,
      "grad_norm": 0.0,
      "learning_rate": 1.9903640256959316e-05,
      "loss": 1.5919,
      "step": 10
    },
    {
      "epoch": 0.005888650963597431,
      "grad_norm": 0.0,
      "learning_rate": 1.9892933618843685e-05,
      "loss": 1.4134,
      "step": 11
    },
    {
      "epoch": 0.006423982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.9882226980728054e-05,
      "loss": 1.3787,
      "step": 12
    },
    {
      "epoch": 0.006959314775160599,
      "grad_norm": 0.0,
      "learning_rate": 1.987152034261242e-05,
      "loss": 1.7001,
      "step": 13
    },
    {
      "epoch": 0.007494646680942184,
      "grad_norm": 0.0,
      "learning_rate": 1.9860813704496788e-05,
      "loss": 1.533,
      "step": 14
    },
    {
      "epoch": 0.008029978586723769,
      "grad_norm": 0.0,
      "learning_rate": 1.985010706638116e-05,
      "loss": 1.6334,
      "step": 15
    },
    {
      "epoch": 0.008565310492505354,
      "grad_norm": 0.0,
      "learning_rate": 1.983940042826553e-05,
      "loss": 1.5894,
      "step": 16
    },
    {
      "epoch": 0.009100642398286937,
      "grad_norm": 0.0,
      "learning_rate": 1.9828693790149897e-05,
      "loss": 1.7353,
      "step": 17
    },
    {
      "epoch": 0.009635974304068522,
      "grad_norm": 0.0,
      "learning_rate": 1.9817987152034262e-05,
      "loss": 1.6836,
      "step": 18
    },
    {
      "epoch": 0.010171306209850108,
      "grad_norm": 0.0,
      "learning_rate": 1.980728051391863e-05,
      "loss": 1.7192,
      "step": 19
    },
    {
      "epoch": 0.010706638115631691,
      "grad_norm": 0.0,
      "learning_rate": 1.9796573875803e-05,
      "loss": 1.4263,
      "step": 20
    },
    {
      "epoch": 0.011241970021413276,
      "grad_norm": 0.0,
      "learning_rate": 1.9785867237687368e-05,
      "loss": 1.6408,
      "step": 21
    },
    {
      "epoch": 0.011777301927194861,
      "grad_norm": 0.0,
      "learning_rate": 1.9775160599571737e-05,
      "loss": 1.5708,
      "step": 22
    },
    {
      "epoch": 0.012312633832976445,
      "grad_norm": 0.0,
      "learning_rate": 1.9764453961456106e-05,
      "loss": 1.5017,
      "step": 23
    },
    {
      "epoch": 0.01284796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.9753747323340474e-05,
      "loss": 1.6632,
      "step": 24
    },
    {
      "epoch": 0.013383297644539615,
      "grad_norm": 0.0,
      "learning_rate": 1.9743040685224843e-05,
      "loss": 1.7259,
      "step": 25
    },
    {
      "epoch": 0.013918629550321198,
      "grad_norm": 0.0,
      "learning_rate": 1.9732334047109208e-05,
      "loss": 1.546,
      "step": 26
    },
    {
      "epoch": 0.014453961456102784,
      "grad_norm": 0.0,
      "learning_rate": 1.9721627408993577e-05,
      "loss": 1.9092,
      "step": 27
    },
    {
      "epoch": 0.014989293361884369,
      "grad_norm": 0.0,
      "learning_rate": 1.9710920770877946e-05,
      "loss": 1.6299,
      "step": 28
    },
    {
      "epoch": 0.015524625267665952,
      "grad_norm": 0.0,
      "learning_rate": 1.9700214132762314e-05,
      "loss": 1.5832,
      "step": 29
    },
    {
      "epoch": 0.016059957173447537,
      "grad_norm": 0.0,
      "learning_rate": 1.9689507494646683e-05,
      "loss": 2.5118,
      "step": 30
    },
    {
      "epoch": 0.016595289079229122,
      "grad_norm": 0.0,
      "learning_rate": 1.967880085653105e-05,
      "loss": 1.3131,
      "step": 31
    },
    {
      "epoch": 0.017130620985010708,
      "grad_norm": 0.0,
      "learning_rate": 1.966809421841542e-05,
      "loss": 1.8795,
      "step": 32
    },
    {
      "epoch": 0.017665952890792293,
      "grad_norm": 0.0,
      "learning_rate": 1.9657387580299786e-05,
      "loss": 1.5211,
      "step": 33
    },
    {
      "epoch": 0.018201284796573874,
      "grad_norm": 0.0,
      "learning_rate": 1.9646680942184154e-05,
      "loss": 1.9435,
      "step": 34
    },
    {
      "epoch": 0.01873661670235546,
      "grad_norm": 0.0,
      "learning_rate": 1.9635974304068523e-05,
      "loss": 1.4664,
      "step": 35
    },
    {
      "epoch": 0.019271948608137045,
      "grad_norm": 0.0,
      "learning_rate": 1.962526766595289e-05,
      "loss": 1.4449,
      "step": 36
    },
    {
      "epoch": 0.01980728051391863,
      "grad_norm": 0.0,
      "learning_rate": 1.961456102783726e-05,
      "loss": 1.6231,
      "step": 37
    },
    {
      "epoch": 0.020342612419700215,
      "grad_norm": 0.0,
      "learning_rate": 1.960385438972163e-05,
      "loss": 1.8839,
      "step": 38
    },
    {
      "epoch": 0.0208779443254818,
      "grad_norm": 0.0,
      "learning_rate": 1.9593147751605998e-05,
      "loss": 1.6247,
      "step": 39
    },
    {
      "epoch": 0.021413276231263382,
      "grad_norm": 0.0,
      "learning_rate": 1.9582441113490366e-05,
      "loss": 1.5348,
      "step": 40
    },
    {
      "epoch": 0.021948608137044967,
      "grad_norm": 0.0,
      "learning_rate": 1.957173447537473e-05,
      "loss": 1.5886,
      "step": 41
    },
    {
      "epoch": 0.022483940042826552,
      "grad_norm": 0.0,
      "learning_rate": 1.95610278372591e-05,
      "loss": 1.4693,
      "step": 42
    },
    {
      "epoch": 0.023019271948608137,
      "grad_norm": 0.0,
      "learning_rate": 1.9550321199143472e-05,
      "loss": 1.4118,
      "step": 43
    },
    {
      "epoch": 0.023554603854389723,
      "grad_norm": 0.0,
      "learning_rate": 1.953961456102784e-05,
      "loss": 1.5425,
      "step": 44
    },
    {
      "epoch": 0.024089935760171308,
      "grad_norm": 0.0,
      "learning_rate": 1.952890792291221e-05,
      "loss": 1.7314,
      "step": 45
    },
    {
      "epoch": 0.02462526766595289,
      "grad_norm": 0.0,
      "learning_rate": 1.9518201284796575e-05,
      "loss": 1.5379,
      "step": 46
    },
    {
      "epoch": 0.025160599571734475,
      "grad_norm": 0.0,
      "learning_rate": 1.9507494646680944e-05,
      "loss": 1.5782,
      "step": 47
    },
    {
      "epoch": 0.02569593147751606,
      "grad_norm": 0.0,
      "learning_rate": 1.9496788008565312e-05,
      "loss": 1.4503,
      "step": 48
    },
    {
      "epoch": 0.026231263383297645,
      "grad_norm": 0.0,
      "learning_rate": 1.948608137044968e-05,
      "loss": 1.4845,
      "step": 49
    },
    {
      "epoch": 0.02676659528907923,
      "grad_norm": 0.0,
      "learning_rate": 1.947537473233405e-05,
      "loss": 1.4529,
      "step": 50
    },
    {
      "epoch": 0.027301927194860815,
      "grad_norm": 0.0,
      "learning_rate": 1.9464668094218418e-05,
      "loss": 1.574,
      "step": 51
    },
    {
      "epoch": 0.027837259100642397,
      "grad_norm": 0.0,
      "learning_rate": 1.9453961456102787e-05,
      "loss": 1.4097,
      "step": 52
    },
    {
      "epoch": 0.028372591006423982,
      "grad_norm": 0.0,
      "learning_rate": 1.9443254817987152e-05,
      "loss": 1.4748,
      "step": 53
    },
    {
      "epoch": 0.028907922912205567,
      "grad_norm": 0.0,
      "learning_rate": 1.943254817987152e-05,
      "loss": 1.6856,
      "step": 54
    },
    {
      "epoch": 0.029443254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.942184154175589e-05,
      "loss": 1.5378,
      "step": 55
    },
    {
      "epoch": 0.029978586723768737,
      "grad_norm": 0.0,
      "learning_rate": 1.9411134903640258e-05,
      "loss": 1.6205,
      "step": 56
    },
    {
      "epoch": 0.030513918629550323,
      "grad_norm": 0.0,
      "learning_rate": 1.9400428265524627e-05,
      "loss": 1.4556,
      "step": 57
    },
    {
      "epoch": 0.031049250535331904,
      "grad_norm": 0.0,
      "learning_rate": 1.9389721627408996e-05,
      "loss": 1.8696,
      "step": 58
    },
    {
      "epoch": 0.03158458244111349,
      "grad_norm": 0.0,
      "learning_rate": 1.9379014989293364e-05,
      "loss": 1.3533,
      "step": 59
    },
    {
      "epoch": 0.032119914346895075,
      "grad_norm": 0.0,
      "learning_rate": 1.9368308351177733e-05,
      "loss": 1.4627,
      "step": 60
    },
    {
      "epoch": 0.032655246252676656,
      "grad_norm": 0.0,
      "learning_rate": 1.9357601713062098e-05,
      "loss": 1.3942,
      "step": 61
    },
    {
      "epoch": 0.033190578158458245,
      "grad_norm": 0.0,
      "learning_rate": 1.9346895074946467e-05,
      "loss": 1.4912,
      "step": 62
    },
    {
      "epoch": 0.03372591006423983,
      "grad_norm": 0.0,
      "learning_rate": 1.9336188436830836e-05,
      "loss": 1.4372,
      "step": 63
    },
    {
      "epoch": 0.034261241970021415,
      "grad_norm": 0.0,
      "learning_rate": 1.9325481798715204e-05,
      "loss": 2.0181,
      "step": 64
    },
    {
      "epoch": 0.034796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.9314775160599573e-05,
      "loss": 1.548,
      "step": 65
    },
    {
      "epoch": 0.035331905781584586,
      "grad_norm": 0.0,
      "learning_rate": 1.930406852248394e-05,
      "loss": 1.841,
      "step": 66
    },
    {
      "epoch": 0.03586723768736617,
      "grad_norm": 0.0,
      "learning_rate": 1.929336188436831e-05,
      "loss": 1.5558,
      "step": 67
    },
    {
      "epoch": 0.03640256959314775,
      "grad_norm": 0.0,
      "learning_rate": 1.928265524625268e-05,
      "loss": 1.5069,
      "step": 68
    },
    {
      "epoch": 0.03693790149892934,
      "grad_norm": 0.0,
      "learning_rate": 1.9271948608137044e-05,
      "loss": 1.5094,
      "step": 69
    },
    {
      "epoch": 0.03747323340471092,
      "grad_norm": 0.0,
      "learning_rate": 1.9261241970021416e-05,
      "loss": 1.9591,
      "step": 70
    },
    {
      "epoch": 0.03800856531049251,
      "grad_norm": 0.0,
      "learning_rate": 1.9250535331905785e-05,
      "loss": 1.5507,
      "step": 71
    },
    {
      "epoch": 0.03854389721627409,
      "grad_norm": 0.0,
      "learning_rate": 1.9239828693790154e-05,
      "loss": 1.6392,
      "step": 72
    },
    {
      "epoch": 0.03907922912205567,
      "grad_norm": 0.0,
      "learning_rate": 1.9229122055674522e-05,
      "loss": 1.5803,
      "step": 73
    },
    {
      "epoch": 0.03961456102783726,
      "grad_norm": 0.0,
      "learning_rate": 1.9218415417558888e-05,
      "loss": 1.8303,
      "step": 74
    },
    {
      "epoch": 0.04014989293361884,
      "grad_norm": 0.0,
      "learning_rate": 1.9207708779443256e-05,
      "loss": 1.7447,
      "step": 75
    },
    {
      "epoch": 0.04068522483940043,
      "grad_norm": 0.0,
      "learning_rate": 1.9197002141327625e-05,
      "loss": 1.4138,
      "step": 76
    },
    {
      "epoch": 0.04122055674518201,
      "grad_norm": 0.0,
      "learning_rate": 1.9186295503211994e-05,
      "loss": 1.4472,
      "step": 77
    },
    {
      "epoch": 0.0417558886509636,
      "grad_norm": 0.0,
      "learning_rate": 1.9175588865096362e-05,
      "loss": 1.713,
      "step": 78
    },
    {
      "epoch": 0.04229122055674518,
      "grad_norm": 0.0,
      "learning_rate": 1.916488222698073e-05,
      "loss": 1.9824,
      "step": 79
    },
    {
      "epoch": 0.042826552462526764,
      "grad_norm": 0.0,
      "learning_rate": 1.91541755888651e-05,
      "loss": 1.4192,
      "step": 80
    },
    {
      "epoch": 0.04336188436830835,
      "grad_norm": 0.0,
      "learning_rate": 1.9143468950749465e-05,
      "loss": 1.5134,
      "step": 81
    },
    {
      "epoch": 0.043897216274089934,
      "grad_norm": 0.0,
      "learning_rate": 1.9132762312633834e-05,
      "loss": 1.4574,
      "step": 82
    },
    {
      "epoch": 0.04443254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.9122055674518202e-05,
      "loss": 1.4824,
      "step": 83
    },
    {
      "epoch": 0.044967880085653104,
      "grad_norm": 0.0,
      "learning_rate": 1.911134903640257e-05,
      "loss": 1.4062,
      "step": 84
    },
    {
      "epoch": 0.045503211991434686,
      "grad_norm": 0.0,
      "learning_rate": 1.910064239828694e-05,
      "loss": 1.8261,
      "step": 85
    },
    {
      "epoch": 0.046038543897216275,
      "grad_norm": 0.0,
      "learning_rate": 1.9089935760171308e-05,
      "loss": 1.5364,
      "step": 86
    },
    {
      "epoch": 0.046573875802997856,
      "grad_norm": 0.0,
      "learning_rate": 1.9079229122055677e-05,
      "loss": 1.7854,
      "step": 87
    },
    {
      "epoch": 0.047109207708779445,
      "grad_norm": 0.0,
      "learning_rate": 1.9068522483940046e-05,
      "loss": 1.8661,
      "step": 88
    },
    {
      "epoch": 0.04764453961456103,
      "grad_norm": 0.0,
      "learning_rate": 1.905781584582441e-05,
      "loss": 1.8321,
      "step": 89
    },
    {
      "epoch": 0.048179871520342615,
      "grad_norm": 0.0,
      "learning_rate": 1.904710920770878e-05,
      "loss": 1.4096,
      "step": 90
    },
    {
      "epoch": 0.0487152034261242,
      "grad_norm": 0.0,
      "learning_rate": 1.9036402569593148e-05,
      "loss": 1.6048,
      "step": 91
    },
    {
      "epoch": 0.04925053533190578,
      "grad_norm": 0.0,
      "learning_rate": 1.9025695931477517e-05,
      "loss": 1.7153,
      "step": 92
    },
    {
      "epoch": 0.04978586723768737,
      "grad_norm": 0.0,
      "learning_rate": 1.9014989293361886e-05,
      "loss": 1.6852,
      "step": 93
    },
    {
      "epoch": 0.05032119914346895,
      "grad_norm": 0.0,
      "learning_rate": 1.9004282655246254e-05,
      "loss": 1.4767,
      "step": 94
    },
    {
      "epoch": 0.05085653104925054,
      "grad_norm": 0.0,
      "learning_rate": 1.8993576017130623e-05,
      "loss": 1.645,
      "step": 95
    },
    {
      "epoch": 0.05139186295503212,
      "grad_norm": 0.0,
      "learning_rate": 1.8982869379014988e-05,
      "loss": 1.7718,
      "step": 96
    },
    {
      "epoch": 0.05192719486081371,
      "grad_norm": 0.0,
      "learning_rate": 1.8972162740899357e-05,
      "loss": 1.4263,
      "step": 97
    },
    {
      "epoch": 0.05246252676659529,
      "grad_norm": 0.0,
      "learning_rate": 1.896145610278373e-05,
      "loss": 1.5589,
      "step": 98
    },
    {
      "epoch": 0.05299785867237687,
      "grad_norm": 0.0,
      "learning_rate": 1.8950749464668098e-05,
      "loss": 1.5204,
      "step": 99
    },
    {
      "epoch": 0.05353319057815846,
      "grad_norm": 0.0,
      "learning_rate": 1.8940042826552466e-05,
      "loss": 1.5505,
      "step": 100
    },
    {
      "epoch": 0.05406852248394004,
      "grad_norm": 0.0,
      "learning_rate": 1.892933618843683e-05,
      "loss": 1.6524,
      "step": 101
    },
    {
      "epoch": 0.05460385438972163,
      "grad_norm": 0.0,
      "learning_rate": 1.89186295503212e-05,
      "loss": 1.5252,
      "step": 102
    },
    {
      "epoch": 0.05513918629550321,
      "grad_norm": 0.0,
      "learning_rate": 1.890792291220557e-05,
      "loss": 1.6086,
      "step": 103
    },
    {
      "epoch": 0.055674518201284794,
      "grad_norm": 0.0,
      "learning_rate": 1.8897216274089938e-05,
      "loss": 1.629,
      "step": 104
    },
    {
      "epoch": 0.05620985010706638,
      "grad_norm": 0.0,
      "learning_rate": 1.8886509635974306e-05,
      "loss": 1.9452,
      "step": 105
    },
    {
      "epoch": 0.056745182012847964,
      "grad_norm": 0.0,
      "learning_rate": 1.8875802997858675e-05,
      "loss": 1.4602,
      "step": 106
    },
    {
      "epoch": 0.05728051391862955,
      "grad_norm": 0.0,
      "learning_rate": 1.8865096359743044e-05,
      "loss": 1.5507,
      "step": 107
    },
    {
      "epoch": 0.057815845824411134,
      "grad_norm": 0.0,
      "learning_rate": 1.8854389721627412e-05,
      "loss": 1.5703,
      "step": 108
    },
    {
      "epoch": 0.05835117773019272,
      "grad_norm": 0.0,
      "learning_rate": 1.8843683083511778e-05,
      "loss": 1.588,
      "step": 109
    },
    {
      "epoch": 0.058886509635974305,
      "grad_norm": 0.0,
      "learning_rate": 1.8832976445396146e-05,
      "loss": 1.4668,
      "step": 110
    },
    {
      "epoch": 0.059421841541755886,
      "grad_norm": 0.0,
      "learning_rate": 1.8822269807280515e-05,
      "loss": 1.635,
      "step": 111
    },
    {
      "epoch": 0.059957173447537475,
      "grad_norm": 0.0,
      "learning_rate": 1.8811563169164884e-05,
      "loss": 1.5208,
      "step": 112
    },
    {
      "epoch": 0.06049250535331906,
      "grad_norm": 0.0,
      "learning_rate": 1.8800856531049252e-05,
      "loss": 1.678,
      "step": 113
    },
    {
      "epoch": 0.061027837259100645,
      "grad_norm": 0.0,
      "learning_rate": 1.879014989293362e-05,
      "loss": 1.4388,
      "step": 114
    },
    {
      "epoch": 0.06156316916488223,
      "grad_norm": 0.0,
      "learning_rate": 1.877944325481799e-05,
      "loss": 1.5295,
      "step": 115
    },
    {
      "epoch": 0.06209850107066381,
      "grad_norm": 0.0,
      "learning_rate": 1.8768736616702358e-05,
      "loss": 1.4786,
      "step": 116
    },
    {
      "epoch": 0.0626338329764454,
      "grad_norm": 0.0,
      "learning_rate": 1.8758029978586724e-05,
      "loss": 1.7381,
      "step": 117
    },
    {
      "epoch": 0.06316916488222699,
      "grad_norm": 0.0,
      "learning_rate": 1.8747323340471092e-05,
      "loss": 1.5178,
      "step": 118
    },
    {
      "epoch": 0.06370449678800856,
      "grad_norm": 0.0,
      "learning_rate": 1.873661670235546e-05,
      "loss": 2.0646,
      "step": 119
    },
    {
      "epoch": 0.06423982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.872591006423983e-05,
      "loss": 1.4792,
      "step": 120
    },
    {
      "epoch": 0.06477516059957174,
      "grad_norm": 0.0,
      "learning_rate": 1.8715203426124198e-05,
      "loss": 1.5901,
      "step": 121
    },
    {
      "epoch": 0.06531049250535331,
      "grad_norm": 0.0,
      "learning_rate": 1.8704496788008567e-05,
      "loss": 1.7953,
      "step": 122
    },
    {
      "epoch": 0.0658458244111349,
      "grad_norm": 0.0,
      "learning_rate": 1.8693790149892936e-05,
      "loss": 1.6723,
      "step": 123
    },
    {
      "epoch": 0.06638115631691649,
      "grad_norm": 0.0,
      "learning_rate": 1.86830835117773e-05,
      "loss": 1.6489,
      "step": 124
    },
    {
      "epoch": 0.06691648822269808,
      "grad_norm": 0.0,
      "learning_rate": 1.8672376873661673e-05,
      "loss": 1.7243,
      "step": 125
    },
    {
      "epoch": 0.06745182012847965,
      "grad_norm": 0.0,
      "learning_rate": 1.866167023554604e-05,
      "loss": 1.4683,
      "step": 126
    },
    {
      "epoch": 0.06798715203426124,
      "grad_norm": 0.0,
      "learning_rate": 1.865096359743041e-05,
      "loss": 1.4586,
      "step": 127
    },
    {
      "epoch": 0.06852248394004283,
      "grad_norm": 0.0,
      "learning_rate": 1.864025695931478e-05,
      "loss": 1.5185,
      "step": 128
    },
    {
      "epoch": 0.0690578158458244,
      "grad_norm": 0.0,
      "learning_rate": 1.8629550321199144e-05,
      "loss": 1.8419,
      "step": 129
    },
    {
      "epoch": 0.069593147751606,
      "grad_norm": 0.0,
      "learning_rate": 1.8618843683083513e-05,
      "loss": 1.5832,
      "step": 130
    },
    {
      "epoch": 0.07012847965738758,
      "grad_norm": 0.0,
      "learning_rate": 1.860813704496788e-05,
      "loss": 1.7501,
      "step": 131
    },
    {
      "epoch": 0.07066381156316917,
      "grad_norm": 0.0,
      "learning_rate": 1.859743040685225e-05,
      "loss": 1.424,
      "step": 132
    },
    {
      "epoch": 0.07119914346895075,
      "grad_norm": 0.0,
      "learning_rate": 1.858672376873662e-05,
      "loss": 1.5724,
      "step": 133
    },
    {
      "epoch": 0.07173447537473233,
      "grad_norm": 0.0,
      "learning_rate": 1.8576017130620988e-05,
      "loss": 1.6076,
      "step": 134
    },
    {
      "epoch": 0.07226980728051392,
      "grad_norm": 0.0,
      "learning_rate": 1.8565310492505356e-05,
      "loss": 1.3298,
      "step": 135
    },
    {
      "epoch": 0.0728051391862955,
      "grad_norm": 0.0,
      "learning_rate": 1.8554603854389725e-05,
      "loss": 1.7244,
      "step": 136
    },
    {
      "epoch": 0.07334047109207709,
      "grad_norm": 0.0,
      "learning_rate": 1.854389721627409e-05,
      "loss": 1.4609,
      "step": 137
    },
    {
      "epoch": 0.07387580299785867,
      "grad_norm": 0.0,
      "learning_rate": 1.853319057815846e-05,
      "loss": 1.5577,
      "step": 138
    },
    {
      "epoch": 0.07441113490364026,
      "grad_norm": 0.0,
      "learning_rate": 1.8522483940042828e-05,
      "loss": 1.4937,
      "step": 139
    },
    {
      "epoch": 0.07494646680942184,
      "grad_norm": 0.0,
      "learning_rate": 1.8511777301927196e-05,
      "loss": 2.1691,
      "step": 140
    },
    {
      "epoch": 0.07548179871520343,
      "grad_norm": 0.0,
      "learning_rate": 1.8501070663811565e-05,
      "loss": 1.6261,
      "step": 141
    },
    {
      "epoch": 0.07601713062098502,
      "grad_norm": 0.0,
      "learning_rate": 1.8490364025695934e-05,
      "loss": 1.7687,
      "step": 142
    },
    {
      "epoch": 0.07655246252676659,
      "grad_norm": 0.0,
      "learning_rate": 1.8479657387580302e-05,
      "loss": 1.4492,
      "step": 143
    },
    {
      "epoch": 0.07708779443254818,
      "grad_norm": 0.0,
      "learning_rate": 1.8468950749464668e-05,
      "loss": 1.5651,
      "step": 144
    },
    {
      "epoch": 0.07762312633832977,
      "grad_norm": 0.0,
      "learning_rate": 1.8458244111349036e-05,
      "loss": 1.4875,
      "step": 145
    },
    {
      "epoch": 0.07815845824411134,
      "grad_norm": 0.0,
      "learning_rate": 1.8447537473233405e-05,
      "loss": 1.7592,
      "step": 146
    },
    {
      "epoch": 0.07869379014989293,
      "grad_norm": 0.0,
      "learning_rate": 1.8436830835117774e-05,
      "loss": 1.4586,
      "step": 147
    },
    {
      "epoch": 0.07922912205567452,
      "grad_norm": 0.0,
      "learning_rate": 1.8426124197002142e-05,
      "loss": 1.7043,
      "step": 148
    },
    {
      "epoch": 0.07976445396145611,
      "grad_norm": 0.0,
      "learning_rate": 1.841541755888651e-05,
      "loss": 1.4618,
      "step": 149
    },
    {
      "epoch": 0.08029978586723768,
      "grad_norm": 0.0,
      "learning_rate": 1.840471092077088e-05,
      "loss": 1.621,
      "step": 150
    },
    {
      "epoch": 0.08083511777301927,
      "grad_norm": 0.0,
      "learning_rate": 1.8394004282655248e-05,
      "loss": 1.4782,
      "step": 151
    },
    {
      "epoch": 0.08137044967880086,
      "grad_norm": 0.0,
      "learning_rate": 1.8383297644539614e-05,
      "loss": 1.7506,
      "step": 152
    },
    {
      "epoch": 0.08190578158458243,
      "grad_norm": 0.0,
      "learning_rate": 1.8372591006423986e-05,
      "loss": 1.6162,
      "step": 153
    },
    {
      "epoch": 0.08244111349036402,
      "grad_norm": 0.0,
      "learning_rate": 1.8361884368308354e-05,
      "loss": 1.5326,
      "step": 154
    },
    {
      "epoch": 0.08297644539614561,
      "grad_norm": 0.0,
      "learning_rate": 1.8351177730192723e-05,
      "loss": 1.4316,
      "step": 155
    },
    {
      "epoch": 0.0835117773019272,
      "grad_norm": 0.0,
      "learning_rate": 1.834047109207709e-05,
      "loss": 1.3787,
      "step": 156
    },
    {
      "epoch": 0.08404710920770878,
      "grad_norm": 0.0,
      "learning_rate": 1.8329764453961457e-05,
      "loss": 1.7515,
      "step": 157
    },
    {
      "epoch": 0.08458244111349036,
      "grad_norm": 0.0,
      "learning_rate": 1.8319057815845826e-05,
      "loss": 1.4528,
      "step": 158
    },
    {
      "epoch": 0.08511777301927195,
      "grad_norm": 0.0,
      "learning_rate": 1.8308351177730194e-05,
      "loss": 1.753,
      "step": 159
    },
    {
      "epoch": 0.08565310492505353,
      "grad_norm": 0.0,
      "learning_rate": 1.8297644539614563e-05,
      "loss": 1.4652,
      "step": 160
    },
    {
      "epoch": 0.08618843683083512,
      "grad_norm": 0.0,
      "learning_rate": 1.828693790149893e-05,
      "loss": 1.364,
      "step": 161
    },
    {
      "epoch": 0.0867237687366167,
      "grad_norm": 0.0,
      "learning_rate": 1.82762312633833e-05,
      "loss": 1.6536,
      "step": 162
    },
    {
      "epoch": 0.0872591006423983,
      "grad_norm": 0.0,
      "learning_rate": 1.826552462526767e-05,
      "loss": 1.6465,
      "step": 163
    },
    {
      "epoch": 0.08779443254817987,
      "grad_norm": 0.0,
      "learning_rate": 1.8254817987152038e-05,
      "loss": 1.7695,
      "step": 164
    },
    {
      "epoch": 0.08832976445396146,
      "grad_norm": 0.0,
      "learning_rate": 1.8244111349036403e-05,
      "loss": 1.5366,
      "step": 165
    },
    {
      "epoch": 0.08886509635974305,
      "grad_norm": 0.0,
      "learning_rate": 1.823340471092077e-05,
      "loss": 1.3066,
      "step": 166
    },
    {
      "epoch": 0.08940042826552462,
      "grad_norm": 0.0,
      "learning_rate": 1.822269807280514e-05,
      "loss": 1.5323,
      "step": 167
    },
    {
      "epoch": 0.08993576017130621,
      "grad_norm": 0.0,
      "learning_rate": 1.821199143468951e-05,
      "loss": 1.6706,
      "step": 168
    },
    {
      "epoch": 0.0904710920770878,
      "grad_norm": 0.0,
      "learning_rate": 1.8201284796573878e-05,
      "loss": 1.364,
      "step": 169
    },
    {
      "epoch": 0.09100642398286937,
      "grad_norm": 0.0,
      "learning_rate": 1.8190578158458246e-05,
      "loss": 1.5616,
      "step": 170
    },
    {
      "epoch": 0.09154175588865096,
      "grad_norm": 0.0,
      "learning_rate": 1.8179871520342615e-05,
      "loss": 1.7082,
      "step": 171
    },
    {
      "epoch": 0.09207708779443255,
      "grad_norm": 0.0,
      "learning_rate": 1.816916488222698e-05,
      "loss": 1.6768,
      "step": 172
    },
    {
      "epoch": 0.09261241970021414,
      "grad_norm": 0.0,
      "learning_rate": 1.815845824411135e-05,
      "loss": 1.4271,
      "step": 173
    },
    {
      "epoch": 0.09314775160599571,
      "grad_norm": 0.0,
      "learning_rate": 1.8147751605995718e-05,
      "loss": 1.4515,
      "step": 174
    },
    {
      "epoch": 0.0936830835117773,
      "grad_norm": 0.0,
      "learning_rate": 1.8137044967880086e-05,
      "loss": 1.5154,
      "step": 175
    },
    {
      "epoch": 0.09421841541755889,
      "grad_norm": 0.0,
      "learning_rate": 1.8126338329764455e-05,
      "loss": 1.4488,
      "step": 176
    },
    {
      "epoch": 0.09475374732334046,
      "grad_norm": 0.0,
      "learning_rate": 1.8115631691648824e-05,
      "loss": 1.586,
      "step": 177
    },
    {
      "epoch": 0.09528907922912205,
      "grad_norm": 0.0,
      "learning_rate": 1.8104925053533192e-05,
      "loss": 1.3638,
      "step": 178
    },
    {
      "epoch": 0.09582441113490364,
      "grad_norm": 0.0,
      "learning_rate": 1.809421841541756e-05,
      "loss": 1.5177,
      "step": 179
    },
    {
      "epoch": 0.09635974304068523,
      "grad_norm": 0.0,
      "learning_rate": 1.808351177730193e-05,
      "loss": 1.7601,
      "step": 180
    },
    {
      "epoch": 0.0968950749464668,
      "grad_norm": 0.0,
      "learning_rate": 1.8072805139186298e-05,
      "loss": 1.2627,
      "step": 181
    },
    {
      "epoch": 0.0974304068522484,
      "grad_norm": 0.0,
      "learning_rate": 1.8062098501070667e-05,
      "loss": 1.6633,
      "step": 182
    },
    {
      "epoch": 0.09796573875802998,
      "grad_norm": 0.0,
      "learning_rate": 1.8051391862955036e-05,
      "loss": 1.7217,
      "step": 183
    },
    {
      "epoch": 0.09850107066381156,
      "grad_norm": 0.0,
      "learning_rate": 1.8040685224839404e-05,
      "loss": 1.6408,
      "step": 184
    },
    {
      "epoch": 0.09903640256959315,
      "grad_norm": 0.0,
      "learning_rate": 1.802997858672377e-05,
      "loss": 1.7098,
      "step": 185
    },
    {
      "epoch": 0.09957173447537473,
      "grad_norm": 0.0,
      "learning_rate": 1.8019271948608138e-05,
      "loss": 1.817,
      "step": 186
    },
    {
      "epoch": 0.10010706638115632,
      "grad_norm": 0.0,
      "learning_rate": 1.8008565310492507e-05,
      "loss": 1.4078,
      "step": 187
    },
    {
      "epoch": 0.1006423982869379,
      "grad_norm": 0.0,
      "learning_rate": 1.7997858672376876e-05,
      "loss": 1.6496,
      "step": 188
    },
    {
      "epoch": 0.10117773019271949,
      "grad_norm": 0.0,
      "learning_rate": 1.7987152034261244e-05,
      "loss": 1.9178,
      "step": 189
    },
    {
      "epoch": 0.10171306209850108,
      "grad_norm": 0.0,
      "learning_rate": 1.7976445396145613e-05,
      "loss": 1.7432,
      "step": 190
    },
    {
      "epoch": 0.10224839400428265,
      "grad_norm": 0.0,
      "learning_rate": 1.796573875802998e-05,
      "loss": 1.7704,
      "step": 191
    },
    {
      "epoch": 0.10278372591006424,
      "grad_norm": 0.0,
      "learning_rate": 1.7955032119914347e-05,
      "loss": 1.9851,
      "step": 192
    },
    {
      "epoch": 0.10331905781584583,
      "grad_norm": 0.0,
      "learning_rate": 1.7944325481798716e-05,
      "loss": 1.6439,
      "step": 193
    },
    {
      "epoch": 0.10385438972162742,
      "grad_norm": 0.0,
      "learning_rate": 1.7933618843683084e-05,
      "loss": 1.5743,
      "step": 194
    },
    {
      "epoch": 0.10438972162740899,
      "grad_norm": 0.0,
      "learning_rate": 1.7922912205567453e-05,
      "loss": 1.5115,
      "step": 195
    },
    {
      "epoch": 0.10492505353319058,
      "grad_norm": 0.0,
      "learning_rate": 1.791220556745182e-05,
      "loss": 1.7026,
      "step": 196
    },
    {
      "epoch": 0.10546038543897217,
      "grad_norm": 0.0,
      "learning_rate": 1.790149892933619e-05,
      "loss": 1.534,
      "step": 197
    },
    {
      "epoch": 0.10599571734475374,
      "grad_norm": 0.0,
      "learning_rate": 1.789079229122056e-05,
      "loss": 1.399,
      "step": 198
    },
    {
      "epoch": 0.10653104925053533,
      "grad_norm": 0.0,
      "learning_rate": 1.7880085653104928e-05,
      "loss": 1.5679,
      "step": 199
    },
    {
      "epoch": 0.10706638115631692,
      "grad_norm": 0.0,
      "learning_rate": 1.7869379014989293e-05,
      "loss": 1.75,
      "step": 200
    },
    {
      "epoch": 0.1076017130620985,
      "grad_norm": 0.0,
      "learning_rate": 1.785867237687366e-05,
      "loss": 1.5753,
      "step": 201
    },
    {
      "epoch": 0.10813704496788008,
      "grad_norm": 0.0,
      "learning_rate": 1.784796573875803e-05,
      "loss": 1.5138,
      "step": 202
    },
    {
      "epoch": 0.10867237687366167,
      "grad_norm": 0.0,
      "learning_rate": 1.78372591006424e-05,
      "loss": 1.4937,
      "step": 203
    },
    {
      "epoch": 0.10920770877944326,
      "grad_norm": 0.0,
      "learning_rate": 1.7826552462526768e-05,
      "loss": 1.817,
      "step": 204
    },
    {
      "epoch": 0.10974304068522484,
      "grad_norm": 0.0,
      "learning_rate": 1.7815845824411136e-05,
      "loss": 1.3989,
      "step": 205
    },
    {
      "epoch": 0.11027837259100642,
      "grad_norm": 0.0,
      "learning_rate": 1.7805139186295505e-05,
      "loss": 1.9481,
      "step": 206
    },
    {
      "epoch": 0.11081370449678801,
      "grad_norm": 0.0,
      "learning_rate": 1.7794432548179874e-05,
      "loss": 1.4127,
      "step": 207
    },
    {
      "epoch": 0.11134903640256959,
      "grad_norm": 0.0,
      "learning_rate": 1.7783725910064242e-05,
      "loss": 1.6739,
      "step": 208
    },
    {
      "epoch": 0.11188436830835118,
      "grad_norm": 0.0,
      "learning_rate": 1.777301927194861e-05,
      "loss": 1.6394,
      "step": 209
    },
    {
      "epoch": 0.11241970021413276,
      "grad_norm": 0.0,
      "learning_rate": 1.776231263383298e-05,
      "loss": 1.4755,
      "step": 210
    },
    {
      "epoch": 0.11295503211991435,
      "grad_norm": 0.0,
      "learning_rate": 1.7751605995717348e-05,
      "loss": 1.7553,
      "step": 211
    },
    {
      "epoch": 0.11349036402569593,
      "grad_norm": 0.0,
      "learning_rate": 1.7740899357601717e-05,
      "loss": 1.4428,
      "step": 212
    },
    {
      "epoch": 0.11402569593147752,
      "grad_norm": 0.0,
      "learning_rate": 1.7730192719486082e-05,
      "loss": 1.3561,
      "step": 213
    },
    {
      "epoch": 0.1145610278372591,
      "grad_norm": 0.0,
      "learning_rate": 1.771948608137045e-05,
      "loss": 1.6654,
      "step": 214
    },
    {
      "epoch": 0.11509635974304068,
      "grad_norm": 0.0,
      "learning_rate": 1.770877944325482e-05,
      "loss": 1.4674,
      "step": 215
    },
    {
      "epoch": 0.11563169164882227,
      "grad_norm": 0.0,
      "learning_rate": 1.7698072805139188e-05,
      "loss": 1.3942,
      "step": 216
    },
    {
      "epoch": 0.11616702355460386,
      "grad_norm": 0.0,
      "learning_rate": 1.7687366167023557e-05,
      "loss": 1.4743,
      "step": 217
    },
    {
      "epoch": 0.11670235546038545,
      "grad_norm": 0.0,
      "learning_rate": 1.7676659528907926e-05,
      "loss": 1.6683,
      "step": 218
    },
    {
      "epoch": 0.11723768736616702,
      "grad_norm": 0.0,
      "learning_rate": 1.7665952890792294e-05,
      "loss": 1.5061,
      "step": 219
    },
    {
      "epoch": 0.11777301927194861,
      "grad_norm": 0.0,
      "learning_rate": 1.765524625267666e-05,
      "loss": 1.3941,
      "step": 220
    },
    {
      "epoch": 0.1183083511777302,
      "grad_norm": 0.0,
      "learning_rate": 1.7644539614561028e-05,
      "loss": 1.5458,
      "step": 221
    },
    {
      "epoch": 0.11884368308351177,
      "grad_norm": 0.0,
      "learning_rate": 1.7633832976445397e-05,
      "loss": 1.475,
      "step": 222
    },
    {
      "epoch": 0.11937901498929336,
      "grad_norm": 0.0,
      "learning_rate": 1.7623126338329766e-05,
      "loss": 1.6466,
      "step": 223
    },
    {
      "epoch": 0.11991434689507495,
      "grad_norm": 0.0,
      "learning_rate": 1.7612419700214134e-05,
      "loss": 1.7878,
      "step": 224
    },
    {
      "epoch": 0.12044967880085652,
      "grad_norm": 0.0,
      "learning_rate": 1.7601713062098503e-05,
      "loss": 1.4703,
      "step": 225
    },
    {
      "epoch": 0.12098501070663811,
      "grad_norm": 0.0,
      "learning_rate": 1.759100642398287e-05,
      "loss": 1.5942,
      "step": 226
    },
    {
      "epoch": 0.1215203426124197,
      "grad_norm": 0.0,
      "learning_rate": 1.758029978586724e-05,
      "loss": 1.565,
      "step": 227
    },
    {
      "epoch": 0.12205567451820129,
      "grad_norm": 0.0,
      "learning_rate": 1.7569593147751605e-05,
      "loss": 1.7435,
      "step": 228
    },
    {
      "epoch": 0.12259100642398287,
      "grad_norm": 0.0,
      "learning_rate": 1.7558886509635974e-05,
      "loss": 1.3542,
      "step": 229
    },
    {
      "epoch": 0.12312633832976445,
      "grad_norm": 0.0,
      "learning_rate": 1.7548179871520343e-05,
      "loss": 1.5419,
      "step": 230
    },
    {
      "epoch": 0.12366167023554604,
      "grad_norm": 0.0,
      "learning_rate": 1.753747323340471e-05,
      "loss": 1.4995,
      "step": 231
    },
    {
      "epoch": 0.12419700214132762,
      "grad_norm": 0.0,
      "learning_rate": 1.752676659528908e-05,
      "loss": 1.5453,
      "step": 232
    },
    {
      "epoch": 0.1247323340471092,
      "grad_norm": 0.0,
      "learning_rate": 1.751605995717345e-05,
      "loss": 1.5428,
      "step": 233
    },
    {
      "epoch": 0.1252676659528908,
      "grad_norm": 0.0,
      "learning_rate": 1.7505353319057818e-05,
      "loss": 1.5699,
      "step": 234
    },
    {
      "epoch": 0.12580299785867238,
      "grad_norm": 0.0,
      "learning_rate": 1.7494646680942186e-05,
      "loss": 1.4482,
      "step": 235
    },
    {
      "epoch": 0.12633832976445397,
      "grad_norm": 0.0,
      "learning_rate": 1.7483940042826555e-05,
      "loss": 1.4707,
      "step": 236
    },
    {
      "epoch": 0.12687366167023553,
      "grad_norm": 0.0,
      "learning_rate": 1.7473233404710924e-05,
      "loss": 1.5861,
      "step": 237
    },
    {
      "epoch": 0.12740899357601712,
      "grad_norm": 0.0,
      "learning_rate": 1.7462526766595292e-05,
      "loss": 1.5819,
      "step": 238
    },
    {
      "epoch": 0.1279443254817987,
      "grad_norm": 0.0,
      "learning_rate": 1.745182012847966e-05,
      "loss": 1.4139,
      "step": 239
    },
    {
      "epoch": 0.1284796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.7441113490364026e-05,
      "loss": 1.4152,
      "step": 240
    },
    {
      "epoch": 0.1290149892933619,
      "grad_norm": 0.0,
      "learning_rate": 1.7430406852248395e-05,
      "loss": 1.4947,
      "step": 241
    },
    {
      "epoch": 0.12955032119914348,
      "grad_norm": 0.0,
      "learning_rate": 1.7419700214132764e-05,
      "loss": 1.3944,
      "step": 242
    },
    {
      "epoch": 0.13008565310492506,
      "grad_norm": 0.0,
      "learning_rate": 1.7408993576017132e-05,
      "loss": 1.5315,
      "step": 243
    },
    {
      "epoch": 0.13062098501070663,
      "grad_norm": 0.0,
      "learning_rate": 1.73982869379015e-05,
      "loss": 1.6775,
      "step": 244
    },
    {
      "epoch": 0.1311563169164882,
      "grad_norm": 0.0,
      "learning_rate": 1.738758029978587e-05,
      "loss": 1.7088,
      "step": 245
    },
    {
      "epoch": 0.1316916488222698,
      "grad_norm": 0.0,
      "learning_rate": 1.7376873661670238e-05,
      "loss": 1.6824,
      "step": 246
    },
    {
      "epoch": 0.1322269807280514,
      "grad_norm": 0.0,
      "learning_rate": 1.7366167023554607e-05,
      "loss": 1.5205,
      "step": 247
    },
    {
      "epoch": 0.13276231263383298,
      "grad_norm": 0.0,
      "learning_rate": 1.7355460385438972e-05,
      "loss": 1.7406,
      "step": 248
    },
    {
      "epoch": 0.13329764453961457,
      "grad_norm": 0.0,
      "learning_rate": 1.734475374732334e-05,
      "loss": 1.8253,
      "step": 249
    },
    {
      "epoch": 0.13383297644539616,
      "grad_norm": 0.0,
      "learning_rate": 1.733404710920771e-05,
      "loss": 1.5531,
      "step": 250
    },
    {
      "epoch": 0.13436830835117772,
      "grad_norm": 0.0,
      "learning_rate": 1.7323340471092078e-05,
      "loss": 1.4859,
      "step": 251
    },
    {
      "epoch": 0.1349036402569593,
      "grad_norm": 0.0,
      "learning_rate": 1.7312633832976447e-05,
      "loss": 1.7594,
      "step": 252
    },
    {
      "epoch": 0.1354389721627409,
      "grad_norm": 0.0,
      "learning_rate": 1.7301927194860816e-05,
      "loss": 1.9124,
      "step": 253
    },
    {
      "epoch": 0.13597430406852248,
      "grad_norm": 0.0,
      "learning_rate": 1.7291220556745184e-05,
      "loss": 1.3815,
      "step": 254
    },
    {
      "epoch": 0.13650963597430407,
      "grad_norm": 0.0,
      "learning_rate": 1.7280513918629553e-05,
      "loss": 1.6484,
      "step": 255
    },
    {
      "epoch": 0.13704496788008566,
      "grad_norm": 0.0,
      "learning_rate": 1.7269807280513918e-05,
      "loss": 1.3344,
      "step": 256
    },
    {
      "epoch": 0.13758029978586725,
      "grad_norm": 0.0,
      "learning_rate": 1.7259100642398287e-05,
      "loss": 1.7331,
      "step": 257
    },
    {
      "epoch": 0.1381156316916488,
      "grad_norm": 0.0,
      "learning_rate": 1.7248394004282655e-05,
      "loss": 1.6189,
      "step": 258
    },
    {
      "epoch": 0.1386509635974304,
      "grad_norm": 0.0,
      "learning_rate": 1.7237687366167024e-05,
      "loss": 1.6782,
      "step": 259
    },
    {
      "epoch": 0.139186295503212,
      "grad_norm": 0.0,
      "learning_rate": 1.7226980728051393e-05,
      "loss": 1.5142,
      "step": 260
    },
    {
      "epoch": 0.13972162740899358,
      "grad_norm": 0.0,
      "learning_rate": 1.721627408993576e-05,
      "loss": 1.6884,
      "step": 261
    },
    {
      "epoch": 0.14025695931477516,
      "grad_norm": 0.0,
      "learning_rate": 1.720556745182013e-05,
      "loss": 1.4976,
      "step": 262
    },
    {
      "epoch": 0.14079229122055675,
      "grad_norm": 0.0,
      "learning_rate": 1.71948608137045e-05,
      "loss": 1.4508,
      "step": 263
    },
    {
      "epoch": 0.14132762312633834,
      "grad_norm": 0.0,
      "learning_rate": 1.7184154175588868e-05,
      "loss": 1.4672,
      "step": 264
    },
    {
      "epoch": 0.1418629550321199,
      "grad_norm": 0.0,
      "learning_rate": 1.7173447537473236e-05,
      "loss": 1.548,
      "step": 265
    },
    {
      "epoch": 0.1423982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.7162740899357605e-05,
      "loss": 1.6091,
      "step": 266
    },
    {
      "epoch": 0.14293361884368308,
      "grad_norm": 0.0,
      "learning_rate": 1.7152034261241974e-05,
      "loss": 1.4661,
      "step": 267
    },
    {
      "epoch": 0.14346895074946467,
      "grad_norm": 0.0,
      "learning_rate": 1.714132762312634e-05,
      "loss": 1.516,
      "step": 268
    },
    {
      "epoch": 0.14400428265524626,
      "grad_norm": 0.0,
      "learning_rate": 1.7130620985010707e-05,
      "loss": 1.7825,
      "step": 269
    },
    {
      "epoch": 0.14453961456102785,
      "grad_norm": 0.0,
      "learning_rate": 1.7119914346895076e-05,
      "loss": 1.6632,
      "step": 270
    },
    {
      "epoch": 0.14507494646680943,
      "grad_norm": 0.0,
      "learning_rate": 1.7109207708779445e-05,
      "loss": 1.8806,
      "step": 271
    },
    {
      "epoch": 0.145610278372591,
      "grad_norm": 0.0,
      "learning_rate": 1.7098501070663814e-05,
      "loss": 1.5147,
      "step": 272
    },
    {
      "epoch": 0.14614561027837258,
      "grad_norm": 0.0,
      "learning_rate": 1.7087794432548182e-05,
      "loss": 1.595,
      "step": 273
    },
    {
      "epoch": 0.14668094218415417,
      "grad_norm": 0.0,
      "learning_rate": 1.707708779443255e-05,
      "loss": 1.5631,
      "step": 274
    },
    {
      "epoch": 0.14721627408993576,
      "grad_norm": 0.0,
      "learning_rate": 1.706638115631692e-05,
      "loss": 1.4998,
      "step": 275
    },
    {
      "epoch": 0.14775160599571735,
      "grad_norm": 0.0,
      "learning_rate": 1.7055674518201285e-05,
      "loss": 1.88,
      "step": 276
    },
    {
      "epoch": 0.14828693790149894,
      "grad_norm": 0.0,
      "learning_rate": 1.7044967880085653e-05,
      "loss": 1.6366,
      "step": 277
    },
    {
      "epoch": 0.14882226980728053,
      "grad_norm": 0.0,
      "learning_rate": 1.7034261241970022e-05,
      "loss": 1.6373,
      "step": 278
    },
    {
      "epoch": 0.1493576017130621,
      "grad_norm": 0.0,
      "learning_rate": 1.702355460385439e-05,
      "loss": 1.6377,
      "step": 279
    },
    {
      "epoch": 0.14989293361884368,
      "grad_norm": 0.0,
      "learning_rate": 1.701284796573876e-05,
      "loss": 1.8916,
      "step": 280
    },
    {
      "epoch": 0.15042826552462527,
      "grad_norm": 0.0,
      "learning_rate": 1.7002141327623128e-05,
      "loss": 1.4392,
      "step": 281
    },
    {
      "epoch": 0.15096359743040685,
      "grad_norm": 0.0,
      "learning_rate": 1.6991434689507497e-05,
      "loss": 1.7008,
      "step": 282
    },
    {
      "epoch": 0.15149892933618844,
      "grad_norm": 0.0,
      "learning_rate": 1.6980728051391862e-05,
      "loss": 1.466,
      "step": 283
    },
    {
      "epoch": 0.15203426124197003,
      "grad_norm": 0.0,
      "learning_rate": 1.697002141327623e-05,
      "loss": 1.6264,
      "step": 284
    },
    {
      "epoch": 0.15256959314775162,
      "grad_norm": 0.0,
      "learning_rate": 1.69593147751606e-05,
      "loss": 1.3773,
      "step": 285
    },
    {
      "epoch": 0.15310492505353318,
      "grad_norm": 0.0,
      "learning_rate": 1.6948608137044968e-05,
      "loss": 1.6396,
      "step": 286
    },
    {
      "epoch": 0.15364025695931477,
      "grad_norm": 0.0,
      "learning_rate": 1.6937901498929337e-05,
      "loss": 1.8771,
      "step": 287
    },
    {
      "epoch": 0.15417558886509636,
      "grad_norm": 0.0,
      "learning_rate": 1.6927194860813705e-05,
      "loss": 1.4236,
      "step": 288
    },
    {
      "epoch": 0.15471092077087795,
      "grad_norm": 0.0,
      "learning_rate": 1.6916488222698074e-05,
      "loss": 1.903,
      "step": 289
    },
    {
      "epoch": 0.15524625267665954,
      "grad_norm": 0.0,
      "learning_rate": 1.6905781584582443e-05,
      "loss": 1.6061,
      "step": 290
    },
    {
      "epoch": 0.15578158458244112,
      "grad_norm": 0.0,
      "learning_rate": 1.689507494646681e-05,
      "loss": 1.6816,
      "step": 291
    },
    {
      "epoch": 0.15631691648822268,
      "grad_norm": 0.0,
      "learning_rate": 1.688436830835118e-05,
      "loss": 1.7413,
      "step": 292
    },
    {
      "epoch": 0.15685224839400427,
      "grad_norm": 0.0,
      "learning_rate": 1.687366167023555e-05,
      "loss": 1.6363,
      "step": 293
    },
    {
      "epoch": 0.15738758029978586,
      "grad_norm": 0.0,
      "learning_rate": 1.6862955032119918e-05,
      "loss": 1.8938,
      "step": 294
    },
    {
      "epoch": 0.15792291220556745,
      "grad_norm": 0.0,
      "learning_rate": 1.6852248394004286e-05,
      "loss": 1.4195,
      "step": 295
    },
    {
      "epoch": 0.15845824411134904,
      "grad_norm": 0.0,
      "learning_rate": 1.684154175588865e-05,
      "loss": 1.4866,
      "step": 296
    },
    {
      "epoch": 0.15899357601713063,
      "grad_norm": 0.0,
      "learning_rate": 1.683083511777302e-05,
      "loss": 2.099,
      "step": 297
    },
    {
      "epoch": 0.15952890792291222,
      "grad_norm": 0.0,
      "learning_rate": 1.682012847965739e-05,
      "loss": 1.5276,
      "step": 298
    },
    {
      "epoch": 0.16006423982869378,
      "grad_norm": 0.0,
      "learning_rate": 1.6809421841541757e-05,
      "loss": 1.7516,
      "step": 299
    },
    {
      "epoch": 0.16059957173447537,
      "grad_norm": 0.0,
      "learning_rate": 1.6798715203426126e-05,
      "loss": 1.4088,
      "step": 300
    },
    {
      "epoch": 0.16113490364025695,
      "grad_norm": 0.0,
      "learning_rate": 1.6788008565310495e-05,
      "loss": 1.7525,
      "step": 301
    },
    {
      "epoch": 0.16167023554603854,
      "grad_norm": 0.0,
      "learning_rate": 1.6777301927194864e-05,
      "loss": 1.6854,
      "step": 302
    },
    {
      "epoch": 0.16220556745182013,
      "grad_norm": 0.0,
      "learning_rate": 1.6766595289079232e-05,
      "loss": 1.4649,
      "step": 303
    },
    {
      "epoch": 0.16274089935760172,
      "grad_norm": 0.0,
      "learning_rate": 1.6755888650963597e-05,
      "loss": 1.829,
      "step": 304
    },
    {
      "epoch": 0.1632762312633833,
      "grad_norm": 0.0,
      "learning_rate": 1.6745182012847966e-05,
      "loss": 1.7196,
      "step": 305
    },
    {
      "epoch": 0.16381156316916487,
      "grad_norm": 0.0,
      "learning_rate": 1.6734475374732335e-05,
      "loss": 1.6046,
      "step": 306
    },
    {
      "epoch": 0.16434689507494646,
      "grad_norm": 0.0,
      "learning_rate": 1.6723768736616703e-05,
      "loss": 1.482,
      "step": 307
    },
    {
      "epoch": 0.16488222698072805,
      "grad_norm": 0.0,
      "learning_rate": 1.6713062098501072e-05,
      "loss": 1.8289,
      "step": 308
    },
    {
      "epoch": 0.16541755888650964,
      "grad_norm": 0.0,
      "learning_rate": 1.670235546038544e-05,
      "loss": 1.6102,
      "step": 309
    },
    {
      "epoch": 0.16595289079229122,
      "grad_norm": 0.0,
      "learning_rate": 1.669164882226981e-05,
      "loss": 1.5344,
      "step": 310
    },
    {
      "epoch": 0.1664882226980728,
      "grad_norm": 0.0,
      "learning_rate": 1.6680942184154175e-05,
      "loss": 1.5399,
      "step": 311
    },
    {
      "epoch": 0.1670235546038544,
      "grad_norm": 0.0,
      "learning_rate": 1.6670235546038543e-05,
      "loss": 1.6436,
      "step": 312
    },
    {
      "epoch": 0.16755888650963596,
      "grad_norm": 0.0,
      "learning_rate": 1.6659528907922912e-05,
      "loss": 1.6258,
      "step": 313
    },
    {
      "epoch": 0.16809421841541755,
      "grad_norm": 0.0,
      "learning_rate": 1.664882226980728e-05,
      "loss": 1.5275,
      "step": 314
    },
    {
      "epoch": 0.16862955032119914,
      "grad_norm": 0.0,
      "learning_rate": 1.663811563169165e-05,
      "loss": 1.5145,
      "step": 315
    },
    {
      "epoch": 0.16916488222698073,
      "grad_norm": 0.0,
      "learning_rate": 1.6627408993576018e-05,
      "loss": 1.5156,
      "step": 316
    },
    {
      "epoch": 0.16970021413276232,
      "grad_norm": 0.0,
      "learning_rate": 1.6616702355460387e-05,
      "loss": 1.6611,
      "step": 317
    },
    {
      "epoch": 0.1702355460385439,
      "grad_norm": 0.0,
      "learning_rate": 1.6605995717344755e-05,
      "loss": 1.4857,
      "step": 318
    },
    {
      "epoch": 0.1707708779443255,
      "grad_norm": 0.0,
      "learning_rate": 1.6595289079229124e-05,
      "loss": 1.7085,
      "step": 319
    },
    {
      "epoch": 0.17130620985010706,
      "grad_norm": 0.0,
      "learning_rate": 1.6584582441113493e-05,
      "loss": 1.7817,
      "step": 320
    },
    {
      "epoch": 0.17184154175588864,
      "grad_norm": 0.0,
      "learning_rate": 1.657387580299786e-05,
      "loss": 1.6279,
      "step": 321
    },
    {
      "epoch": 0.17237687366167023,
      "grad_norm": 0.0,
      "learning_rate": 1.656316916488223e-05,
      "loss": 1.4848,
      "step": 322
    },
    {
      "epoch": 0.17291220556745182,
      "grad_norm": 0.0,
      "learning_rate": 1.65524625267666e-05,
      "loss": 1.4685,
      "step": 323
    },
    {
      "epoch": 0.1734475374732334,
      "grad_norm": 0.0,
      "learning_rate": 1.6541755888650964e-05,
      "loss": 1.7269,
      "step": 324
    },
    {
      "epoch": 0.173982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.6531049250535333e-05,
      "loss": 1.5956,
      "step": 325
    },
    {
      "epoch": 0.1745182012847966,
      "grad_norm": 0.0,
      "learning_rate": 1.65203426124197e-05,
      "loss": 1.6978,
      "step": 326
    },
    {
      "epoch": 0.17505353319057815,
      "grad_norm": 0.0,
      "learning_rate": 1.650963597430407e-05,
      "loss": 1.7593,
      "step": 327
    },
    {
      "epoch": 0.17558886509635974,
      "grad_norm": 0.0,
      "learning_rate": 1.649892933618844e-05,
      "loss": 1.4007,
      "step": 328
    },
    {
      "epoch": 0.17612419700214133,
      "grad_norm": 0.0,
      "learning_rate": 1.6488222698072807e-05,
      "loss": 1.734,
      "step": 329
    },
    {
      "epoch": 0.1766595289079229,
      "grad_norm": 0.0,
      "learning_rate": 1.6477516059957176e-05,
      "loss": 1.5193,
      "step": 330
    },
    {
      "epoch": 0.1771948608137045,
      "grad_norm": 0.0,
      "learning_rate": 1.646680942184154e-05,
      "loss": 1.6191,
      "step": 331
    },
    {
      "epoch": 0.1777301927194861,
      "grad_norm": 0.0,
      "learning_rate": 1.645610278372591e-05,
      "loss": 1.4719,
      "step": 332
    },
    {
      "epoch": 0.17826552462526768,
      "grad_norm": 0.0,
      "learning_rate": 1.644539614561028e-05,
      "loss": 1.4347,
      "step": 333
    },
    {
      "epoch": 0.17880085653104924,
      "grad_norm": 0.0,
      "learning_rate": 1.6434689507494647e-05,
      "loss": 1.5593,
      "step": 334
    },
    {
      "epoch": 0.17933618843683083,
      "grad_norm": 0.0,
      "learning_rate": 1.6423982869379016e-05,
      "loss": 1.8666,
      "step": 335
    },
    {
      "epoch": 0.17987152034261242,
      "grad_norm": 0.0,
      "learning_rate": 1.6413276231263385e-05,
      "loss": 1.4644,
      "step": 336
    },
    {
      "epoch": 0.180406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.6402569593147753e-05,
      "loss": 1.687,
      "step": 337
    },
    {
      "epoch": 0.1809421841541756,
      "grad_norm": 0.0,
      "learning_rate": 1.6391862955032122e-05,
      "loss": 1.775,
      "step": 338
    },
    {
      "epoch": 0.18147751605995718,
      "grad_norm": 0.0,
      "learning_rate": 1.6381156316916487e-05,
      "loss": 1.8361,
      "step": 339
    },
    {
      "epoch": 0.18201284796573874,
      "grad_norm": 0.0,
      "learning_rate": 1.6370449678800856e-05,
      "loss": 1.5627,
      "step": 340
    },
    {
      "epoch": 0.18254817987152033,
      "grad_norm": 0.0,
      "learning_rate": 1.6359743040685225e-05,
      "loss": 1.6799,
      "step": 341
    },
    {
      "epoch": 0.18308351177730192,
      "grad_norm": 0.0,
      "learning_rate": 1.6349036402569593e-05,
      "loss": 1.508,
      "step": 342
    },
    {
      "epoch": 0.1836188436830835,
      "grad_norm": 0.0,
      "learning_rate": 1.6338329764453962e-05,
      "loss": 1.4803,
      "step": 343
    },
    {
      "epoch": 0.1841541755888651,
      "grad_norm": 0.0,
      "learning_rate": 1.632762312633833e-05,
      "loss": 1.5266,
      "step": 344
    },
    {
      "epoch": 0.1846895074946467,
      "grad_norm": 0.0,
      "learning_rate": 1.63169164882227e-05,
      "loss": 1.526,
      "step": 345
    },
    {
      "epoch": 0.18522483940042828,
      "grad_norm": 0.0,
      "learning_rate": 1.6306209850107068e-05,
      "loss": 1.6689,
      "step": 346
    },
    {
      "epoch": 0.18576017130620984,
      "grad_norm": 0.0,
      "learning_rate": 1.6295503211991437e-05,
      "loss": 1.4089,
      "step": 347
    },
    {
      "epoch": 0.18629550321199143,
      "grad_norm": 0.0,
      "learning_rate": 1.6284796573875805e-05,
      "loss": 1.4778,
      "step": 348
    },
    {
      "epoch": 0.18683083511777301,
      "grad_norm": 0.0,
      "learning_rate": 1.6274089935760174e-05,
      "loss": 1.4858,
      "step": 349
    },
    {
      "epoch": 0.1873661670235546,
      "grad_norm": 0.0,
      "learning_rate": 1.6263383297644543e-05,
      "loss": 1.6624,
      "step": 350
    },
    {
      "epoch": 0.1879014989293362,
      "grad_norm": 0.0,
      "learning_rate": 1.625267665952891e-05,
      "loss": 1.8012,
      "step": 351
    },
    {
      "epoch": 0.18843683083511778,
      "grad_norm": 0.0,
      "learning_rate": 1.6241970021413277e-05,
      "loss": 1.5166,
      "step": 352
    },
    {
      "epoch": 0.18897216274089937,
      "grad_norm": 0.0,
      "learning_rate": 1.6231263383297645e-05,
      "loss": 1.2608,
      "step": 353
    },
    {
      "epoch": 0.18950749464668093,
      "grad_norm": 0.0,
      "learning_rate": 1.6220556745182014e-05,
      "loss": 1.5215,
      "step": 354
    },
    {
      "epoch": 0.19004282655246252,
      "grad_norm": 0.0,
      "learning_rate": 1.6209850107066383e-05,
      "loss": 1.6299,
      "step": 355
    },
    {
      "epoch": 0.1905781584582441,
      "grad_norm": 0.0,
      "learning_rate": 1.619914346895075e-05,
      "loss": 1.4475,
      "step": 356
    },
    {
      "epoch": 0.1911134903640257,
      "grad_norm": 0.0,
      "learning_rate": 1.618843683083512e-05,
      "loss": 1.5485,
      "step": 357
    },
    {
      "epoch": 0.19164882226980728,
      "grad_norm": 0.0,
      "learning_rate": 1.617773019271949e-05,
      "loss": 1.4575,
      "step": 358
    },
    {
      "epoch": 0.19218415417558887,
      "grad_norm": 0.0,
      "learning_rate": 1.6167023554603854e-05,
      "loss": 1.6399,
      "step": 359
    },
    {
      "epoch": 0.19271948608137046,
      "grad_norm": 0.0,
      "learning_rate": 1.6156316916488223e-05,
      "loss": 1.5605,
      "step": 360
    },
    {
      "epoch": 0.19325481798715202,
      "grad_norm": 0.0,
      "learning_rate": 1.614561027837259e-05,
      "loss": 1.381,
      "step": 361
    },
    {
      "epoch": 0.1937901498929336,
      "grad_norm": 0.0,
      "learning_rate": 1.613490364025696e-05,
      "loss": 1.4831,
      "step": 362
    },
    {
      "epoch": 0.1943254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.612419700214133e-05,
      "loss": 1.7584,
      "step": 363
    },
    {
      "epoch": 0.1948608137044968,
      "grad_norm": 0.0,
      "learning_rate": 1.6113490364025697e-05,
      "loss": 1.7558,
      "step": 364
    },
    {
      "epoch": 0.19539614561027838,
      "grad_norm": 0.0,
      "learning_rate": 1.6102783725910066e-05,
      "loss": 1.3996,
      "step": 365
    },
    {
      "epoch": 0.19593147751605997,
      "grad_norm": 0.0,
      "learning_rate": 1.6092077087794435e-05,
      "loss": 1.566,
      "step": 366
    },
    {
      "epoch": 0.19646680942184155,
      "grad_norm": 0.0,
      "learning_rate": 1.60813704496788e-05,
      "loss": 1.5772,
      "step": 367
    },
    {
      "epoch": 0.19700214132762311,
      "grad_norm": 0.0,
      "learning_rate": 1.607066381156317e-05,
      "loss": 1.4356,
      "step": 368
    },
    {
      "epoch": 0.1975374732334047,
      "grad_norm": 0.0,
      "learning_rate": 1.6059957173447537e-05,
      "loss": 1.5064,
      "step": 369
    },
    {
      "epoch": 0.1980728051391863,
      "grad_norm": 0.0,
      "learning_rate": 1.6049250535331906e-05,
      "loss": 1.6165,
      "step": 370
    },
    {
      "epoch": 0.19860813704496788,
      "grad_norm": 0.0,
      "learning_rate": 1.6038543897216275e-05,
      "loss": 1.6696,
      "step": 371
    },
    {
      "epoch": 0.19914346895074947,
      "grad_norm": 0.0,
      "learning_rate": 1.6027837259100643e-05,
      "loss": 1.3258,
      "step": 372
    },
    {
      "epoch": 0.19967880085653106,
      "grad_norm": 0.0,
      "learning_rate": 1.6017130620985012e-05,
      "loss": 1.4606,
      "step": 373
    },
    {
      "epoch": 0.20021413276231265,
      "grad_norm": 0.0,
      "learning_rate": 1.600642398286938e-05,
      "loss": 1.3726,
      "step": 374
    },
    {
      "epoch": 0.2007494646680942,
      "grad_norm": 0.0,
      "learning_rate": 1.599571734475375e-05,
      "loss": 1.5618,
      "step": 375
    },
    {
      "epoch": 0.2012847965738758,
      "grad_norm": 0.0,
      "learning_rate": 1.5985010706638118e-05,
      "loss": 1.5654,
      "step": 376
    },
    {
      "epoch": 0.20182012847965738,
      "grad_norm": 0.0,
      "learning_rate": 1.5974304068522487e-05,
      "loss": 2.1024,
      "step": 377
    },
    {
      "epoch": 0.20235546038543897,
      "grad_norm": 0.0,
      "learning_rate": 1.5963597430406855e-05,
      "loss": 1.5735,
      "step": 378
    },
    {
      "epoch": 0.20289079229122056,
      "grad_norm": 0.0,
      "learning_rate": 1.595289079229122e-05,
      "loss": 1.557,
      "step": 379
    },
    {
      "epoch": 0.20342612419700215,
      "grad_norm": 0.0,
      "learning_rate": 1.594218415417559e-05,
      "loss": 1.3792,
      "step": 380
    },
    {
      "epoch": 0.20396145610278374,
      "grad_norm": 0.0,
      "learning_rate": 1.5931477516059958e-05,
      "loss": 1.5578,
      "step": 381
    },
    {
      "epoch": 0.2044967880085653,
      "grad_norm": 0.0,
      "learning_rate": 1.5920770877944327e-05,
      "loss": 1.7536,
      "step": 382
    },
    {
      "epoch": 0.2050321199143469,
      "grad_norm": 0.0,
      "learning_rate": 1.5910064239828695e-05,
      "loss": 1.6186,
      "step": 383
    },
    {
      "epoch": 0.20556745182012848,
      "grad_norm": 0.0,
      "learning_rate": 1.5899357601713064e-05,
      "loss": 1.6597,
      "step": 384
    },
    {
      "epoch": 0.20610278372591007,
      "grad_norm": 0.0,
      "learning_rate": 1.5888650963597433e-05,
      "loss": 1.4421,
      "step": 385
    },
    {
      "epoch": 0.20663811563169165,
      "grad_norm": 0.0,
      "learning_rate": 1.58779443254818e-05,
      "loss": 1.6974,
      "step": 386
    },
    {
      "epoch": 0.20717344753747324,
      "grad_norm": 0.0,
      "learning_rate": 1.5867237687366167e-05,
      "loss": 1.6904,
      "step": 387
    },
    {
      "epoch": 0.20770877944325483,
      "grad_norm": 0.0,
      "learning_rate": 1.5856531049250535e-05,
      "loss": 1.7618,
      "step": 388
    },
    {
      "epoch": 0.2082441113490364,
      "grad_norm": 0.0,
      "learning_rate": 1.5845824411134904e-05,
      "loss": 1.703,
      "step": 389
    },
    {
      "epoch": 0.20877944325481798,
      "grad_norm": 0.0,
      "learning_rate": 1.5835117773019273e-05,
      "loss": 1.9268,
      "step": 390
    },
    {
      "epoch": 0.20931477516059957,
      "grad_norm": 0.0,
      "learning_rate": 1.582441113490364e-05,
      "loss": 1.6374,
      "step": 391
    },
    {
      "epoch": 0.20985010706638116,
      "grad_norm": 0.0,
      "learning_rate": 1.581370449678801e-05,
      "loss": 1.6419,
      "step": 392
    },
    {
      "epoch": 0.21038543897216275,
      "grad_norm": 0.0,
      "learning_rate": 1.580299785867238e-05,
      "loss": 1.7966,
      "step": 393
    },
    {
      "epoch": 0.21092077087794434,
      "grad_norm": 0.0,
      "learning_rate": 1.5792291220556747e-05,
      "loss": 1.6055,
      "step": 394
    },
    {
      "epoch": 0.2114561027837259,
      "grad_norm": 0.0,
      "learning_rate": 1.5781584582441113e-05,
      "loss": 1.5963,
      "step": 395
    },
    {
      "epoch": 0.21199143468950749,
      "grad_norm": 0.0,
      "learning_rate": 1.577087794432548e-05,
      "loss": 1.728,
      "step": 396
    },
    {
      "epoch": 0.21252676659528907,
      "grad_norm": 0.0,
      "learning_rate": 1.576017130620985e-05,
      "loss": 1.5326,
      "step": 397
    },
    {
      "epoch": 0.21306209850107066,
      "grad_norm": 0.0,
      "learning_rate": 1.574946466809422e-05,
      "loss": 1.7133,
      "step": 398
    },
    {
      "epoch": 0.21359743040685225,
      "grad_norm": 0.0,
      "learning_rate": 1.5738758029978587e-05,
      "loss": 1.565,
      "step": 399
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 0.0,
      "learning_rate": 1.5728051391862956e-05,
      "loss": 1.5632,
      "step": 400
    },
    {
      "epoch": 0.21466809421841543,
      "grad_norm": 0.0,
      "learning_rate": 1.5717344753747325e-05,
      "loss": 1.8976,
      "step": 401
    },
    {
      "epoch": 0.215203426124197,
      "grad_norm": 0.0,
      "learning_rate": 1.5706638115631693e-05,
      "loss": 1.5386,
      "step": 402
    },
    {
      "epoch": 0.21573875802997858,
      "grad_norm": 0.0,
      "learning_rate": 1.5695931477516062e-05,
      "loss": 1.5382,
      "step": 403
    },
    {
      "epoch": 0.21627408993576017,
      "grad_norm": 0.0,
      "learning_rate": 1.568522483940043e-05,
      "loss": 1.8347,
      "step": 404
    },
    {
      "epoch": 0.21680942184154176,
      "grad_norm": 0.0,
      "learning_rate": 1.56745182012848e-05,
      "loss": 1.6139,
      "step": 405
    },
    {
      "epoch": 0.21734475374732334,
      "grad_norm": 0.0,
      "learning_rate": 1.5663811563169168e-05,
      "loss": 1.797,
      "step": 406
    },
    {
      "epoch": 0.21788008565310493,
      "grad_norm": 0.0,
      "learning_rate": 1.5653104925053533e-05,
      "loss": 1.6496,
      "step": 407
    },
    {
      "epoch": 0.21841541755888652,
      "grad_norm": 0.0,
      "learning_rate": 1.5642398286937902e-05,
      "loss": 1.6182,
      "step": 408
    },
    {
      "epoch": 0.21895074946466808,
      "grad_norm": 0.0,
      "learning_rate": 1.563169164882227e-05,
      "loss": 1.7129,
      "step": 409
    },
    {
      "epoch": 0.21948608137044967,
      "grad_norm": 0.0,
      "learning_rate": 1.562098501070664e-05,
      "loss": 1.7275,
      "step": 410
    },
    {
      "epoch": 0.22002141327623126,
      "grad_norm": 0.0,
      "learning_rate": 1.5610278372591008e-05,
      "loss": 1.5731,
      "step": 411
    },
    {
      "epoch": 0.22055674518201285,
      "grad_norm": 0.0,
      "learning_rate": 1.5599571734475377e-05,
      "loss": 1.5925,
      "step": 412
    },
    {
      "epoch": 0.22109207708779444,
      "grad_norm": 0.0,
      "learning_rate": 1.5588865096359745e-05,
      "loss": 1.5901,
      "step": 413
    },
    {
      "epoch": 0.22162740899357602,
      "grad_norm": 0.0,
      "learning_rate": 1.5578158458244114e-05,
      "loss": 1.5382,
      "step": 414
    },
    {
      "epoch": 0.2221627408993576,
      "grad_norm": 0.0,
      "learning_rate": 1.556745182012848e-05,
      "loss": 1.5506,
      "step": 415
    },
    {
      "epoch": 0.22269807280513917,
      "grad_norm": 0.0,
      "learning_rate": 1.5556745182012848e-05,
      "loss": 1.3878,
      "step": 416
    },
    {
      "epoch": 0.22323340471092076,
      "grad_norm": 0.0,
      "learning_rate": 1.5546038543897217e-05,
      "loss": 1.6352,
      "step": 417
    },
    {
      "epoch": 0.22376873661670235,
      "grad_norm": 0.0,
      "learning_rate": 1.5535331905781585e-05,
      "loss": 1.5891,
      "step": 418
    },
    {
      "epoch": 0.22430406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.5524625267665954e-05,
      "loss": 1.8758,
      "step": 419
    },
    {
      "epoch": 0.22483940042826553,
      "grad_norm": 0.0,
      "learning_rate": 1.5513918629550323e-05,
      "loss": 1.7728,
      "step": 420
    },
    {
      "epoch": 0.22537473233404712,
      "grad_norm": 0.0,
      "learning_rate": 1.550321199143469e-05,
      "loss": 1.4761,
      "step": 421
    },
    {
      "epoch": 0.2259100642398287,
      "grad_norm": 0.0,
      "learning_rate": 1.5492505353319057e-05,
      "loss": 1.6193,
      "step": 422
    },
    {
      "epoch": 0.22644539614561027,
      "grad_norm": 0.0,
      "learning_rate": 1.5481798715203425e-05,
      "loss": 1.4554,
      "step": 423
    },
    {
      "epoch": 0.22698072805139186,
      "grad_norm": 0.0,
      "learning_rate": 1.5471092077087794e-05,
      "loss": 1.6518,
      "step": 424
    },
    {
      "epoch": 0.22751605995717344,
      "grad_norm": 0.0,
      "learning_rate": 1.5460385438972163e-05,
      "loss": 1.857,
      "step": 425
    },
    {
      "epoch": 0.22805139186295503,
      "grad_norm": 0.0,
      "learning_rate": 1.544967880085653e-05,
      "loss": 1.5657,
      "step": 426
    },
    {
      "epoch": 0.22858672376873662,
      "grad_norm": 0.0,
      "learning_rate": 1.54389721627409e-05,
      "loss": 1.4544,
      "step": 427
    },
    {
      "epoch": 0.2291220556745182,
      "grad_norm": 0.0,
      "learning_rate": 1.542826552462527e-05,
      "loss": 1.4851,
      "step": 428
    },
    {
      "epoch": 0.2296573875802998,
      "grad_norm": 0.0,
      "learning_rate": 1.5417558886509637e-05,
      "loss": 1.9546,
      "step": 429
    },
    {
      "epoch": 0.23019271948608136,
      "grad_norm": 0.0,
      "learning_rate": 1.5406852248394006e-05,
      "loss": 1.683,
      "step": 430
    },
    {
      "epoch": 0.23072805139186295,
      "grad_norm": 0.0,
      "learning_rate": 1.5396145610278375e-05,
      "loss": 1.6028,
      "step": 431
    },
    {
      "epoch": 0.23126338329764454,
      "grad_norm": 0.0,
      "learning_rate": 1.5385438972162743e-05,
      "loss": 1.8822,
      "step": 432
    },
    {
      "epoch": 0.23179871520342613,
      "grad_norm": 0.0,
      "learning_rate": 1.5374732334047112e-05,
      "loss": 1.778,
      "step": 433
    },
    {
      "epoch": 0.23233404710920771,
      "grad_norm": 0.0,
      "learning_rate": 1.536402569593148e-05,
      "loss": 1.6181,
      "step": 434
    },
    {
      "epoch": 0.2328693790149893,
      "grad_norm": 0.0,
      "learning_rate": 1.5353319057815846e-05,
      "loss": 1.6118,
      "step": 435
    },
    {
      "epoch": 0.2334047109207709,
      "grad_norm": 0.0,
      "learning_rate": 1.5342612419700215e-05,
      "loss": 1.8217,
      "step": 436
    },
    {
      "epoch": 0.23394004282655245,
      "grad_norm": 0.0,
      "learning_rate": 1.5331905781584583e-05,
      "loss": 1.4545,
      "step": 437
    },
    {
      "epoch": 0.23447537473233404,
      "grad_norm": 0.0,
      "learning_rate": 1.5321199143468952e-05,
      "loss": 1.6519,
      "step": 438
    },
    {
      "epoch": 0.23501070663811563,
      "grad_norm": 0.0,
      "learning_rate": 1.531049250535332e-05,
      "loss": 1.737,
      "step": 439
    },
    {
      "epoch": 0.23554603854389722,
      "grad_norm": 0.0,
      "learning_rate": 1.529978586723769e-05,
      "loss": 1.5572,
      "step": 440
    },
    {
      "epoch": 0.2360813704496788,
      "grad_norm": 0.0,
      "learning_rate": 1.5289079229122058e-05,
      "loss": 1.4672,
      "step": 441
    },
    {
      "epoch": 0.2366167023554604,
      "grad_norm": 0.0,
      "learning_rate": 1.5278372591006427e-05,
      "loss": 1.6854,
      "step": 442
    },
    {
      "epoch": 0.23715203426124196,
      "grad_norm": 0.0,
      "learning_rate": 1.5267665952890792e-05,
      "loss": 1.3716,
      "step": 443
    },
    {
      "epoch": 0.23768736616702354,
      "grad_norm": 0.0,
      "learning_rate": 1.525695931477516e-05,
      "loss": 1.5655,
      "step": 444
    },
    {
      "epoch": 0.23822269807280513,
      "grad_norm": 0.0,
      "learning_rate": 1.524625267665953e-05,
      "loss": 1.556,
      "step": 445
    },
    {
      "epoch": 0.23875802997858672,
      "grad_norm": 0.0,
      "learning_rate": 1.5235546038543898e-05,
      "loss": 1.8337,
      "step": 446
    },
    {
      "epoch": 0.2392933618843683,
      "grad_norm": 0.0,
      "learning_rate": 1.5224839400428267e-05,
      "loss": 1.6804,
      "step": 447
    },
    {
      "epoch": 0.2398286937901499,
      "grad_norm": 0.0,
      "learning_rate": 1.5214132762312634e-05,
      "loss": 1.686,
      "step": 448
    },
    {
      "epoch": 0.2403640256959315,
      "grad_norm": 0.0,
      "learning_rate": 1.5203426124197002e-05,
      "loss": 1.8367,
      "step": 449
    },
    {
      "epoch": 0.24089935760171305,
      "grad_norm": 0.0,
      "learning_rate": 1.5192719486081371e-05,
      "loss": 1.6772,
      "step": 450
    },
    {
      "epoch": 0.24143468950749464,
      "grad_norm": 0.0,
      "learning_rate": 1.518201284796574e-05,
      "loss": 1.4853,
      "step": 451
    },
    {
      "epoch": 0.24197002141327623,
      "grad_norm": 0.0,
      "learning_rate": 1.5171306209850107e-05,
      "loss": 1.5171,
      "step": 452
    },
    {
      "epoch": 0.24250535331905781,
      "grad_norm": 0.0,
      "learning_rate": 1.5160599571734475e-05,
      "loss": 1.6232,
      "step": 453
    },
    {
      "epoch": 0.2430406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.5149892933618844e-05,
      "loss": 1.8811,
      "step": 454
    },
    {
      "epoch": 0.243576017130621,
      "grad_norm": 0.0,
      "learning_rate": 1.5139186295503214e-05,
      "loss": 1.4666,
      "step": 455
    },
    {
      "epoch": 0.24411134903640258,
      "grad_norm": 0.0,
      "learning_rate": 1.5128479657387583e-05,
      "loss": 1.4356,
      "step": 456
    },
    {
      "epoch": 0.24464668094218414,
      "grad_norm": 0.0,
      "learning_rate": 1.511777301927195e-05,
      "loss": 1.6265,
      "step": 457
    },
    {
      "epoch": 0.24518201284796573,
      "grad_norm": 0.0,
      "learning_rate": 1.5107066381156319e-05,
      "loss": 1.496,
      "step": 458
    },
    {
      "epoch": 0.24571734475374732,
      "grad_norm": 0.0,
      "learning_rate": 1.5096359743040687e-05,
      "loss": 1.4705,
      "step": 459
    },
    {
      "epoch": 0.2462526766595289,
      "grad_norm": 0.0,
      "learning_rate": 1.5085653104925056e-05,
      "loss": 1.7471,
      "step": 460
    },
    {
      "epoch": 0.2467880085653105,
      "grad_norm": 0.0,
      "learning_rate": 1.5074946466809423e-05,
      "loss": 1.7883,
      "step": 461
    },
    {
      "epoch": 0.24732334047109208,
      "grad_norm": 0.0,
      "learning_rate": 1.5064239828693792e-05,
      "loss": 1.5252,
      "step": 462
    },
    {
      "epoch": 0.24785867237687367,
      "grad_norm": 0.0,
      "learning_rate": 1.505353319057816e-05,
      "loss": 1.5631,
      "step": 463
    },
    {
      "epoch": 0.24839400428265523,
      "grad_norm": 0.0,
      "learning_rate": 1.5042826552462529e-05,
      "loss": 1.5129,
      "step": 464
    },
    {
      "epoch": 0.24892933618843682,
      "grad_norm": 0.0,
      "learning_rate": 1.5032119914346896e-05,
      "loss": 1.4959,
      "step": 465
    },
    {
      "epoch": 0.2494646680942184,
      "grad_norm": 0.0,
      "learning_rate": 1.5021413276231265e-05,
      "loss": 1.6222,
      "step": 466
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0,
      "learning_rate": 1.5010706638115633e-05,
      "loss": 1.6016,
      "step": 467
    },
    {
      "epoch": 0.2505353319057816,
      "grad_norm": 0.0,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 1.5679,
      "step": 468
    },
    {
      "epoch": 0.2510706638115632,
      "grad_norm": 0.0,
      "learning_rate": 1.4989293361884369e-05,
      "loss": 1.7416,
      "step": 469
    },
    {
      "epoch": 0.25160599571734477,
      "grad_norm": 0.0,
      "learning_rate": 1.4978586723768738e-05,
      "loss": 1.5341,
      "step": 470
    },
    {
      "epoch": 0.25214132762312635,
      "grad_norm": 0.0,
      "learning_rate": 1.4967880085653106e-05,
      "loss": 1.4333,
      "step": 471
    },
    {
      "epoch": 0.25267665952890794,
      "grad_norm": 0.0,
      "learning_rate": 1.4957173447537473e-05,
      "loss": 1.6059,
      "step": 472
    },
    {
      "epoch": 0.25321199143468953,
      "grad_norm": 0.0,
      "learning_rate": 1.4946466809421842e-05,
      "loss": 1.5181,
      "step": 473
    },
    {
      "epoch": 0.25374732334047106,
      "grad_norm": 0.0,
      "learning_rate": 1.493576017130621e-05,
      "loss": 1.8224,
      "step": 474
    },
    {
      "epoch": 0.25428265524625265,
      "grad_norm": 0.0,
      "learning_rate": 1.492505353319058e-05,
      "loss": 1.6916,
      "step": 475
    },
    {
      "epoch": 0.25481798715203424,
      "grad_norm": 0.0,
      "learning_rate": 1.4914346895074946e-05,
      "loss": 1.6631,
      "step": 476
    },
    {
      "epoch": 0.25535331905781583,
      "grad_norm": 0.0,
      "learning_rate": 1.4903640256959315e-05,
      "loss": 1.5794,
      "step": 477
    },
    {
      "epoch": 0.2558886509635974,
      "grad_norm": 0.0,
      "learning_rate": 1.4892933618843684e-05,
      "loss": 1.6302,
      "step": 478
    },
    {
      "epoch": 0.256423982869379,
      "grad_norm": 0.0,
      "learning_rate": 1.4882226980728052e-05,
      "loss": 1.4485,
      "step": 479
    },
    {
      "epoch": 0.2569593147751606,
      "grad_norm": 0.0,
      "learning_rate": 1.487152034261242e-05,
      "loss": 1.5453,
      "step": 480
    },
    {
      "epoch": 0.2574946466809422,
      "grad_norm": 0.0,
      "learning_rate": 1.4860813704496788e-05,
      "loss": 1.5093,
      "step": 481
    },
    {
      "epoch": 0.2580299785867238,
      "grad_norm": 0.0,
      "learning_rate": 1.4850107066381158e-05,
      "loss": 1.6572,
      "step": 482
    },
    {
      "epoch": 0.25856531049250536,
      "grad_norm": 0.0,
      "learning_rate": 1.4839400428265527e-05,
      "loss": 1.4688,
      "step": 483
    },
    {
      "epoch": 0.25910064239828695,
      "grad_norm": 0.0,
      "learning_rate": 1.4828693790149896e-05,
      "loss": 1.5744,
      "step": 484
    },
    {
      "epoch": 0.25963597430406854,
      "grad_norm": 0.0,
      "learning_rate": 1.4817987152034263e-05,
      "loss": 1.7582,
      "step": 485
    },
    {
      "epoch": 0.26017130620985013,
      "grad_norm": 0.0,
      "learning_rate": 1.4807280513918631e-05,
      "loss": 1.7436,
      "step": 486
    },
    {
      "epoch": 0.2607066381156317,
      "grad_norm": 0.0,
      "learning_rate": 1.4796573875803e-05,
      "loss": 1.6583,
      "step": 487
    },
    {
      "epoch": 0.26124197002141325,
      "grad_norm": 0.0,
      "learning_rate": 1.4785867237687369e-05,
      "loss": 1.7453,
      "step": 488
    },
    {
      "epoch": 0.26177730192719484,
      "grad_norm": 0.0,
      "learning_rate": 1.4775160599571736e-05,
      "loss": 1.7833,
      "step": 489
    },
    {
      "epoch": 0.2623126338329764,
      "grad_norm": 0.0,
      "learning_rate": 1.4764453961456104e-05,
      "loss": 1.4187,
      "step": 490
    },
    {
      "epoch": 0.262847965738758,
      "grad_norm": 0.0,
      "learning_rate": 1.4753747323340473e-05,
      "loss": 1.3995,
      "step": 491
    },
    {
      "epoch": 0.2633832976445396,
      "grad_norm": 0.0,
      "learning_rate": 1.4743040685224842e-05,
      "loss": 1.6234,
      "step": 492
    },
    {
      "epoch": 0.2639186295503212,
      "grad_norm": 0.0,
      "learning_rate": 1.4732334047109209e-05,
      "loss": 1.7036,
      "step": 493
    },
    {
      "epoch": 0.2644539614561028,
      "grad_norm": 0.0,
      "learning_rate": 1.4721627408993577e-05,
      "loss": 1.4893,
      "step": 494
    },
    {
      "epoch": 0.26498929336188437,
      "grad_norm": 0.0,
      "learning_rate": 1.4710920770877946e-05,
      "loss": 1.5664,
      "step": 495
    },
    {
      "epoch": 0.26552462526766596,
      "grad_norm": 0.0,
      "learning_rate": 1.4700214132762313e-05,
      "loss": 1.638,
      "step": 496
    },
    {
      "epoch": 0.26605995717344755,
      "grad_norm": 0.0,
      "learning_rate": 1.4689507494646682e-05,
      "loss": 1.5496,
      "step": 497
    },
    {
      "epoch": 0.26659528907922914,
      "grad_norm": 0.0,
      "learning_rate": 1.467880085653105e-05,
      "loss": 1.5405,
      "step": 498
    },
    {
      "epoch": 0.2671306209850107,
      "grad_norm": 0.0,
      "learning_rate": 1.4668094218415419e-05,
      "loss": 1.5171,
      "step": 499
    },
    {
      "epoch": 0.2676659528907923,
      "grad_norm": 0.0,
      "learning_rate": 1.4657387580299786e-05,
      "loss": 1.4978,
      "step": 500
    },
    {
      "epoch": 0.2682012847965739,
      "grad_norm": 0.0,
      "learning_rate": 1.4646680942184155e-05,
      "loss": 1.8123,
      "step": 501
    },
    {
      "epoch": 0.26873661670235544,
      "grad_norm": 0.0,
      "learning_rate": 1.4635974304068523e-05,
      "loss": 1.5387,
      "step": 502
    },
    {
      "epoch": 0.269271948608137,
      "grad_norm": 0.0,
      "learning_rate": 1.4625267665952892e-05,
      "loss": 1.4509,
      "step": 503
    },
    {
      "epoch": 0.2698072805139186,
      "grad_norm": 0.0,
      "learning_rate": 1.4614561027837259e-05,
      "loss": 1.5663,
      "step": 504
    },
    {
      "epoch": 0.2703426124197002,
      "grad_norm": 0.0,
      "learning_rate": 1.4603854389721628e-05,
      "loss": 1.5389,
      "step": 505
    },
    {
      "epoch": 0.2708779443254818,
      "grad_norm": 0.0,
      "learning_rate": 1.4593147751605996e-05,
      "loss": 1.5251,
      "step": 506
    },
    {
      "epoch": 0.2714132762312634,
      "grad_norm": 0.0,
      "learning_rate": 1.4582441113490365e-05,
      "loss": 1.7611,
      "step": 507
    },
    {
      "epoch": 0.27194860813704497,
      "grad_norm": 0.0,
      "learning_rate": 1.4571734475374732e-05,
      "loss": 1.6553,
      "step": 508
    },
    {
      "epoch": 0.27248394004282656,
      "grad_norm": 0.0,
      "learning_rate": 1.45610278372591e-05,
      "loss": 1.424,
      "step": 509
    },
    {
      "epoch": 0.27301927194860814,
      "grad_norm": 0.0,
      "learning_rate": 1.4550321199143471e-05,
      "loss": 1.545,
      "step": 510
    },
    {
      "epoch": 0.27355460385438973,
      "grad_norm": 0.0,
      "learning_rate": 1.453961456102784e-05,
      "loss": 1.7176,
      "step": 511
    },
    {
      "epoch": 0.2740899357601713,
      "grad_norm": 0.0,
      "learning_rate": 1.4528907922912208e-05,
      "loss": 1.9128,
      "step": 512
    },
    {
      "epoch": 0.2746252676659529,
      "grad_norm": 0.0,
      "learning_rate": 1.4518201284796575e-05,
      "loss": 1.4615,
      "step": 513
    },
    {
      "epoch": 0.2751605995717345,
      "grad_norm": 0.0,
      "learning_rate": 1.4507494646680944e-05,
      "loss": 1.4185,
      "step": 514
    },
    {
      "epoch": 0.2756959314775161,
      "grad_norm": 0.0,
      "learning_rate": 1.4496788008565313e-05,
      "loss": 1.6741,
      "step": 515
    },
    {
      "epoch": 0.2762312633832976,
      "grad_norm": 0.0,
      "learning_rate": 1.4486081370449681e-05,
      "loss": 1.484,
      "step": 516
    },
    {
      "epoch": 0.2767665952890792,
      "grad_norm": 0.0,
      "learning_rate": 1.4475374732334048e-05,
      "loss": 1.3236,
      "step": 517
    },
    {
      "epoch": 0.2773019271948608,
      "grad_norm": 0.0,
      "learning_rate": 1.4464668094218417e-05,
      "loss": 1.538,
      "step": 518
    },
    {
      "epoch": 0.2778372591006424,
      "grad_norm": 0.0,
      "learning_rate": 1.4453961456102786e-05,
      "loss": 1.4571,
      "step": 519
    },
    {
      "epoch": 0.278372591006424,
      "grad_norm": 0.0,
      "learning_rate": 1.4443254817987153e-05,
      "loss": 1.5881,
      "step": 520
    },
    {
      "epoch": 0.27890792291220556,
      "grad_norm": 0.0,
      "learning_rate": 1.4432548179871521e-05,
      "loss": 1.7086,
      "step": 521
    },
    {
      "epoch": 0.27944325481798715,
      "grad_norm": 0.0,
      "learning_rate": 1.442184154175589e-05,
      "loss": 1.905,
      "step": 522
    },
    {
      "epoch": 0.27997858672376874,
      "grad_norm": 0.0,
      "learning_rate": 1.4411134903640259e-05,
      "loss": 1.3585,
      "step": 523
    },
    {
      "epoch": 0.28051391862955033,
      "grad_norm": 0.0,
      "learning_rate": 1.4400428265524626e-05,
      "loss": 1.574,
      "step": 524
    },
    {
      "epoch": 0.2810492505353319,
      "grad_norm": 0.0,
      "learning_rate": 1.4389721627408994e-05,
      "loss": 1.5906,
      "step": 525
    },
    {
      "epoch": 0.2815845824411135,
      "grad_norm": 0.0,
      "learning_rate": 1.4379014989293363e-05,
      "loss": 1.5151,
      "step": 526
    },
    {
      "epoch": 0.2821199143468951,
      "grad_norm": 0.0,
      "learning_rate": 1.4368308351177732e-05,
      "loss": 1.4657,
      "step": 527
    },
    {
      "epoch": 0.2826552462526767,
      "grad_norm": 0.0,
      "learning_rate": 1.4357601713062099e-05,
      "loss": 1.7918,
      "step": 528
    },
    {
      "epoch": 0.2831905781584582,
      "grad_norm": 0.0,
      "learning_rate": 1.4346895074946467e-05,
      "loss": 1.4425,
      "step": 529
    },
    {
      "epoch": 0.2837259100642398,
      "grad_norm": 0.0,
      "learning_rate": 1.4336188436830836e-05,
      "loss": 1.8762,
      "step": 530
    },
    {
      "epoch": 0.2842612419700214,
      "grad_norm": 0.0,
      "learning_rate": 1.4325481798715205e-05,
      "loss": 1.9354,
      "step": 531
    },
    {
      "epoch": 0.284796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.4314775160599572e-05,
      "loss": 1.852,
      "step": 532
    },
    {
      "epoch": 0.28533190578158457,
      "grad_norm": 0.0,
      "learning_rate": 1.430406852248394e-05,
      "loss": 1.5164,
      "step": 533
    },
    {
      "epoch": 0.28586723768736616,
      "grad_norm": 0.0,
      "learning_rate": 1.4293361884368309e-05,
      "loss": 1.6276,
      "step": 534
    },
    {
      "epoch": 0.28640256959314775,
      "grad_norm": 0.0,
      "learning_rate": 1.4282655246252678e-05,
      "loss": 1.397,
      "step": 535
    },
    {
      "epoch": 0.28693790149892934,
      "grad_norm": 0.0,
      "learning_rate": 1.4271948608137045e-05,
      "loss": 1.4606,
      "step": 536
    },
    {
      "epoch": 0.2874732334047109,
      "grad_norm": 0.0,
      "learning_rate": 1.4261241970021415e-05,
      "loss": 1.5672,
      "step": 537
    },
    {
      "epoch": 0.2880085653104925,
      "grad_norm": 0.0,
      "learning_rate": 1.4250535331905784e-05,
      "loss": 1.3949,
      "step": 538
    },
    {
      "epoch": 0.2885438972162741,
      "grad_norm": 0.0,
      "learning_rate": 1.4239828693790152e-05,
      "loss": 1.6268,
      "step": 539
    },
    {
      "epoch": 0.2890792291220557,
      "grad_norm": 0.0,
      "learning_rate": 1.4229122055674521e-05,
      "loss": 1.5197,
      "step": 540
    },
    {
      "epoch": 0.2896145610278373,
      "grad_norm": 0.0,
      "learning_rate": 1.4218415417558888e-05,
      "loss": 1.536,
      "step": 541
    },
    {
      "epoch": 0.29014989293361887,
      "grad_norm": 0.0,
      "learning_rate": 1.4207708779443257e-05,
      "loss": 1.4124,
      "step": 542
    },
    {
      "epoch": 0.2906852248394004,
      "grad_norm": 0.0,
      "learning_rate": 1.4197002141327625e-05,
      "loss": 1.4986,
      "step": 543
    },
    {
      "epoch": 0.291220556745182,
      "grad_norm": 0.0,
      "learning_rate": 1.4186295503211992e-05,
      "loss": 1.2798,
      "step": 544
    },
    {
      "epoch": 0.2917558886509636,
      "grad_norm": 0.0,
      "learning_rate": 1.4175588865096361e-05,
      "loss": 1.6619,
      "step": 545
    },
    {
      "epoch": 0.29229122055674517,
      "grad_norm": 0.0,
      "learning_rate": 1.416488222698073e-05,
      "loss": 1.5824,
      "step": 546
    },
    {
      "epoch": 0.29282655246252676,
      "grad_norm": 0.0,
      "learning_rate": 1.4154175588865098e-05,
      "loss": 1.5913,
      "step": 547
    },
    {
      "epoch": 0.29336188436830835,
      "grad_norm": 0.0,
      "learning_rate": 1.4143468950749465e-05,
      "loss": 1.5081,
      "step": 548
    },
    {
      "epoch": 0.29389721627408993,
      "grad_norm": 0.0,
      "learning_rate": 1.4132762312633834e-05,
      "loss": 1.6588,
      "step": 549
    },
    {
      "epoch": 0.2944325481798715,
      "grad_norm": 0.0,
      "learning_rate": 1.4122055674518203e-05,
      "loss": 1.5996,
      "step": 550
    },
    {
      "epoch": 0.2949678800856531,
      "grad_norm": 0.0,
      "learning_rate": 1.4111349036402571e-05,
      "loss": 1.6676,
      "step": 551
    },
    {
      "epoch": 0.2955032119914347,
      "grad_norm": 0.0,
      "learning_rate": 1.4100642398286938e-05,
      "loss": 1.5472,
      "step": 552
    },
    {
      "epoch": 0.2960385438972163,
      "grad_norm": 0.0,
      "learning_rate": 1.4089935760171307e-05,
      "loss": 1.6857,
      "step": 553
    },
    {
      "epoch": 0.2965738758029979,
      "grad_norm": 0.0,
      "learning_rate": 1.4079229122055676e-05,
      "loss": 1.6185,
      "step": 554
    },
    {
      "epoch": 0.29710920770877947,
      "grad_norm": 0.0,
      "learning_rate": 1.4068522483940044e-05,
      "loss": 1.4986,
      "step": 555
    },
    {
      "epoch": 0.29764453961456105,
      "grad_norm": 0.0,
      "learning_rate": 1.4057815845824411e-05,
      "loss": 1.5259,
      "step": 556
    },
    {
      "epoch": 0.2981798715203426,
      "grad_norm": 0.0,
      "learning_rate": 1.404710920770878e-05,
      "loss": 1.7163,
      "step": 557
    },
    {
      "epoch": 0.2987152034261242,
      "grad_norm": 0.0,
      "learning_rate": 1.4036402569593149e-05,
      "loss": 1.5799,
      "step": 558
    },
    {
      "epoch": 0.29925053533190576,
      "grad_norm": 0.0,
      "learning_rate": 1.4025695931477517e-05,
      "loss": 1.6528,
      "step": 559
    },
    {
      "epoch": 0.29978586723768735,
      "grad_norm": 0.0,
      "learning_rate": 1.4014989293361884e-05,
      "loss": 1.5588,
      "step": 560
    },
    {
      "epoch": 0.30032119914346894,
      "grad_norm": 0.0,
      "learning_rate": 1.4004282655246253e-05,
      "loss": 1.9074,
      "step": 561
    },
    {
      "epoch": 0.30085653104925053,
      "grad_norm": 0.0,
      "learning_rate": 1.3993576017130622e-05,
      "loss": 1.93,
      "step": 562
    },
    {
      "epoch": 0.3013918629550321,
      "grad_norm": 0.0,
      "learning_rate": 1.3982869379014989e-05,
      "loss": 1.5387,
      "step": 563
    },
    {
      "epoch": 0.3019271948608137,
      "grad_norm": 0.0,
      "learning_rate": 1.3972162740899357e-05,
      "loss": 1.7452,
      "step": 564
    },
    {
      "epoch": 0.3024625267665953,
      "grad_norm": 0.0,
      "learning_rate": 1.3961456102783728e-05,
      "loss": 1.6295,
      "step": 565
    },
    {
      "epoch": 0.3029978586723769,
      "grad_norm": 0.0,
      "learning_rate": 1.3950749464668096e-05,
      "loss": 1.5645,
      "step": 566
    },
    {
      "epoch": 0.3035331905781585,
      "grad_norm": 0.0,
      "learning_rate": 1.3940042826552465e-05,
      "loss": 1.7093,
      "step": 567
    },
    {
      "epoch": 0.30406852248394006,
      "grad_norm": 0.0,
      "learning_rate": 1.3929336188436832e-05,
      "loss": 1.607,
      "step": 568
    },
    {
      "epoch": 0.30460385438972165,
      "grad_norm": 0.0,
      "learning_rate": 1.39186295503212e-05,
      "loss": 1.8259,
      "step": 569
    },
    {
      "epoch": 0.30513918629550324,
      "grad_norm": 0.0,
      "learning_rate": 1.390792291220557e-05,
      "loss": 1.4352,
      "step": 570
    },
    {
      "epoch": 0.3056745182012848,
      "grad_norm": 0.0,
      "learning_rate": 1.3897216274089938e-05,
      "loss": 1.6901,
      "step": 571
    },
    {
      "epoch": 0.30620985010706636,
      "grad_norm": 0.0,
      "learning_rate": 1.3886509635974305e-05,
      "loss": 1.6272,
      "step": 572
    },
    {
      "epoch": 0.30674518201284795,
      "grad_norm": 0.0,
      "learning_rate": 1.3875802997858674e-05,
      "loss": 1.5947,
      "step": 573
    },
    {
      "epoch": 0.30728051391862954,
      "grad_norm": 0.0,
      "learning_rate": 1.3865096359743042e-05,
      "loss": 1.6025,
      "step": 574
    },
    {
      "epoch": 0.3078158458244111,
      "grad_norm": 0.0,
      "learning_rate": 1.3854389721627411e-05,
      "loss": 1.676,
      "step": 575
    },
    {
      "epoch": 0.3083511777301927,
      "grad_norm": 0.0,
      "learning_rate": 1.3843683083511778e-05,
      "loss": 1.5127,
      "step": 576
    },
    {
      "epoch": 0.3088865096359743,
      "grad_norm": 0.0,
      "learning_rate": 1.3832976445396147e-05,
      "loss": 1.4282,
      "step": 577
    },
    {
      "epoch": 0.3094218415417559,
      "grad_norm": 0.0,
      "learning_rate": 1.3822269807280515e-05,
      "loss": 1.3319,
      "step": 578
    },
    {
      "epoch": 0.3099571734475375,
      "grad_norm": 0.0,
      "learning_rate": 1.3811563169164884e-05,
      "loss": 2.2043,
      "step": 579
    },
    {
      "epoch": 0.31049250535331907,
      "grad_norm": 0.0,
      "learning_rate": 1.3800856531049251e-05,
      "loss": 1.5829,
      "step": 580
    },
    {
      "epoch": 0.31102783725910066,
      "grad_norm": 0.0,
      "learning_rate": 1.379014989293362e-05,
      "loss": 1.8554,
      "step": 581
    },
    {
      "epoch": 0.31156316916488225,
      "grad_norm": 0.0,
      "learning_rate": 1.3779443254817988e-05,
      "loss": 1.3015,
      "step": 582
    },
    {
      "epoch": 0.31209850107066384,
      "grad_norm": 0.0,
      "learning_rate": 1.3768736616702357e-05,
      "loss": 1.6927,
      "step": 583
    },
    {
      "epoch": 0.31263383297644537,
      "grad_norm": 0.0,
      "learning_rate": 1.3758029978586724e-05,
      "loss": 1.5524,
      "step": 584
    },
    {
      "epoch": 0.31316916488222696,
      "grad_norm": 0.0,
      "learning_rate": 1.3747323340471093e-05,
      "loss": 1.5596,
      "step": 585
    },
    {
      "epoch": 0.31370449678800855,
      "grad_norm": 0.0,
      "learning_rate": 1.3736616702355461e-05,
      "loss": 1.5677,
      "step": 586
    },
    {
      "epoch": 0.31423982869379014,
      "grad_norm": 0.0,
      "learning_rate": 1.3725910064239828e-05,
      "loss": 1.3519,
      "step": 587
    },
    {
      "epoch": 0.3147751605995717,
      "grad_norm": 0.0,
      "learning_rate": 1.3715203426124197e-05,
      "loss": 1.4545,
      "step": 588
    },
    {
      "epoch": 0.3153104925053533,
      "grad_norm": 0.0,
      "learning_rate": 1.3704496788008566e-05,
      "loss": 1.5195,
      "step": 589
    },
    {
      "epoch": 0.3158458244111349,
      "grad_norm": 0.0,
      "learning_rate": 1.3693790149892934e-05,
      "loss": 1.5116,
      "step": 590
    },
    {
      "epoch": 0.3163811563169165,
      "grad_norm": 0.0,
      "learning_rate": 1.3683083511777301e-05,
      "loss": 1.4467,
      "step": 591
    },
    {
      "epoch": 0.3169164882226981,
      "grad_norm": 0.0,
      "learning_rate": 1.3672376873661672e-05,
      "loss": 2.053,
      "step": 592
    },
    {
      "epoch": 0.31745182012847967,
      "grad_norm": 0.0,
      "learning_rate": 1.366167023554604e-05,
      "loss": 1.5156,
      "step": 593
    },
    {
      "epoch": 0.31798715203426126,
      "grad_norm": 0.0,
      "learning_rate": 1.3650963597430409e-05,
      "loss": 1.3907,
      "step": 594
    },
    {
      "epoch": 0.31852248394004284,
      "grad_norm": 0.0,
      "learning_rate": 1.3640256959314778e-05,
      "loss": 1.6384,
      "step": 595
    },
    {
      "epoch": 0.31905781584582443,
      "grad_norm": 0.0,
      "learning_rate": 1.3629550321199145e-05,
      "loss": 1.663,
      "step": 596
    },
    {
      "epoch": 0.319593147751606,
      "grad_norm": 0.0,
      "learning_rate": 1.3618843683083513e-05,
      "loss": 1.3544,
      "step": 597
    },
    {
      "epoch": 0.32012847965738755,
      "grad_norm": 0.0,
      "learning_rate": 1.3608137044967882e-05,
      "loss": 1.6744,
      "step": 598
    },
    {
      "epoch": 0.32066381156316914,
      "grad_norm": 0.0,
      "learning_rate": 1.359743040685225e-05,
      "loss": 1.5567,
      "step": 599
    },
    {
      "epoch": 0.32119914346895073,
      "grad_norm": 0.0,
      "learning_rate": 1.3586723768736618e-05,
      "loss": 1.4866,
      "step": 600
    },
    {
      "epoch": 0.3217344753747323,
      "grad_norm": 0.0,
      "learning_rate": 1.3576017130620986e-05,
      "loss": 1.6573,
      "step": 601
    },
    {
      "epoch": 0.3222698072805139,
      "grad_norm": 0.0,
      "learning_rate": 1.3565310492505355e-05,
      "loss": 1.244,
      "step": 602
    },
    {
      "epoch": 0.3228051391862955,
      "grad_norm": 0.0,
      "learning_rate": 1.3554603854389724e-05,
      "loss": 1.5138,
      "step": 603
    },
    {
      "epoch": 0.3233404710920771,
      "grad_norm": 0.0,
      "learning_rate": 1.354389721627409e-05,
      "loss": 1.433,
      "step": 604
    },
    {
      "epoch": 0.3238758029978587,
      "grad_norm": 0.0,
      "learning_rate": 1.353319057815846e-05,
      "loss": 1.5969,
      "step": 605
    },
    {
      "epoch": 0.32441113490364026,
      "grad_norm": 0.0,
      "learning_rate": 1.3522483940042828e-05,
      "loss": 1.8682,
      "step": 606
    },
    {
      "epoch": 0.32494646680942185,
      "grad_norm": 0.0,
      "learning_rate": 1.3511777301927197e-05,
      "loss": 1.8124,
      "step": 607
    },
    {
      "epoch": 0.32548179871520344,
      "grad_norm": 0.0,
      "learning_rate": 1.3501070663811564e-05,
      "loss": 2.0427,
      "step": 608
    },
    {
      "epoch": 0.32601713062098503,
      "grad_norm": 0.0,
      "learning_rate": 1.3490364025695932e-05,
      "loss": 1.4958,
      "step": 609
    },
    {
      "epoch": 0.3265524625267666,
      "grad_norm": 0.0,
      "learning_rate": 1.3479657387580301e-05,
      "loss": 1.5567,
      "step": 610
    },
    {
      "epoch": 0.3270877944325482,
      "grad_norm": 0.0,
      "learning_rate": 1.3468950749464668e-05,
      "loss": 1.4296,
      "step": 611
    },
    {
      "epoch": 0.32762312633832974,
      "grad_norm": 0.0,
      "learning_rate": 1.3458244111349037e-05,
      "loss": 1.651,
      "step": 612
    },
    {
      "epoch": 0.32815845824411133,
      "grad_norm": 0.0,
      "learning_rate": 1.3447537473233405e-05,
      "loss": 1.4084,
      "step": 613
    },
    {
      "epoch": 0.3286937901498929,
      "grad_norm": 0.0,
      "learning_rate": 1.3436830835117774e-05,
      "loss": 1.5477,
      "step": 614
    },
    {
      "epoch": 0.3292291220556745,
      "grad_norm": 0.0,
      "learning_rate": 1.3426124197002141e-05,
      "loss": 1.5447,
      "step": 615
    },
    {
      "epoch": 0.3297644539614561,
      "grad_norm": 0.0,
      "learning_rate": 1.341541755888651e-05,
      "loss": 1.6327,
      "step": 616
    },
    {
      "epoch": 0.3302997858672377,
      "grad_norm": 0.0,
      "learning_rate": 1.3404710920770878e-05,
      "loss": 2.0164,
      "step": 617
    },
    {
      "epoch": 0.33083511777301927,
      "grad_norm": 0.0,
      "learning_rate": 1.3394004282655247e-05,
      "loss": 1.3701,
      "step": 618
    },
    {
      "epoch": 0.33137044967880086,
      "grad_norm": 0.0,
      "learning_rate": 1.3383297644539614e-05,
      "loss": 1.7301,
      "step": 619
    },
    {
      "epoch": 0.33190578158458245,
      "grad_norm": 0.0,
      "learning_rate": 1.3372591006423984e-05,
      "loss": 1.6572,
      "step": 620
    },
    {
      "epoch": 0.33244111349036404,
      "grad_norm": 0.0,
      "learning_rate": 1.3361884368308353e-05,
      "loss": 1.4831,
      "step": 621
    },
    {
      "epoch": 0.3329764453961456,
      "grad_norm": 0.0,
      "learning_rate": 1.3351177730192722e-05,
      "loss": 1.3956,
      "step": 622
    },
    {
      "epoch": 0.3335117773019272,
      "grad_norm": 0.0,
      "learning_rate": 1.334047109207709e-05,
      "loss": 1.4306,
      "step": 623
    },
    {
      "epoch": 0.3340471092077088,
      "grad_norm": 0.0,
      "learning_rate": 1.3329764453961457e-05,
      "loss": 1.5429,
      "step": 624
    },
    {
      "epoch": 0.33458244111349034,
      "grad_norm": 0.0,
      "learning_rate": 1.3319057815845826e-05,
      "loss": 1.7224,
      "step": 625
    },
    {
      "epoch": 0.3351177730192719,
      "grad_norm": 0.0,
      "learning_rate": 1.3308351177730195e-05,
      "loss": 1.5283,
      "step": 626
    },
    {
      "epoch": 0.3356531049250535,
      "grad_norm": 0.0,
      "learning_rate": 1.3297644539614563e-05,
      "loss": 1.968,
      "step": 627
    },
    {
      "epoch": 0.3361884368308351,
      "grad_norm": 0.0,
      "learning_rate": 1.328693790149893e-05,
      "loss": 1.5884,
      "step": 628
    },
    {
      "epoch": 0.3367237687366167,
      "grad_norm": 0.0,
      "learning_rate": 1.3276231263383299e-05,
      "loss": 1.6139,
      "step": 629
    },
    {
      "epoch": 0.3372591006423983,
      "grad_norm": 0.0,
      "learning_rate": 1.3265524625267668e-05,
      "loss": 1.8925,
      "step": 630
    },
    {
      "epoch": 0.33779443254817987,
      "grad_norm": 0.0,
      "learning_rate": 1.3254817987152036e-05,
      "loss": 1.5451,
      "step": 631
    },
    {
      "epoch": 0.33832976445396146,
      "grad_norm": 0.0,
      "learning_rate": 1.3244111349036403e-05,
      "loss": 1.3975,
      "step": 632
    },
    {
      "epoch": 0.33886509635974305,
      "grad_norm": 0.0,
      "learning_rate": 1.3233404710920772e-05,
      "loss": 1.4955,
      "step": 633
    },
    {
      "epoch": 0.33940042826552463,
      "grad_norm": 0.0,
      "learning_rate": 1.322269807280514e-05,
      "loss": 1.4001,
      "step": 634
    },
    {
      "epoch": 0.3399357601713062,
      "grad_norm": 0.0,
      "learning_rate": 1.3211991434689508e-05,
      "loss": 1.8497,
      "step": 635
    },
    {
      "epoch": 0.3404710920770878,
      "grad_norm": 0.0,
      "learning_rate": 1.3201284796573876e-05,
      "loss": 1.3479,
      "step": 636
    },
    {
      "epoch": 0.3410064239828694,
      "grad_norm": 0.0,
      "learning_rate": 1.3190578158458245e-05,
      "loss": 1.4395,
      "step": 637
    },
    {
      "epoch": 0.341541755888651,
      "grad_norm": 0.0,
      "learning_rate": 1.3179871520342614e-05,
      "loss": 1.603,
      "step": 638
    },
    {
      "epoch": 0.3420770877944325,
      "grad_norm": 0.0,
      "learning_rate": 1.316916488222698e-05,
      "loss": 1.6425,
      "step": 639
    },
    {
      "epoch": 0.3426124197002141,
      "grad_norm": 0.0,
      "learning_rate": 1.315845824411135e-05,
      "loss": 1.4592,
      "step": 640
    },
    {
      "epoch": 0.3431477516059957,
      "grad_norm": 0.0,
      "learning_rate": 1.3147751605995718e-05,
      "loss": 1.8531,
      "step": 641
    },
    {
      "epoch": 0.3436830835117773,
      "grad_norm": 0.0,
      "learning_rate": 1.3137044967880087e-05,
      "loss": 1.4615,
      "step": 642
    },
    {
      "epoch": 0.3442184154175589,
      "grad_norm": 0.0,
      "learning_rate": 1.3126338329764454e-05,
      "loss": 1.8434,
      "step": 643
    },
    {
      "epoch": 0.34475374732334046,
      "grad_norm": 0.0,
      "learning_rate": 1.3115631691648822e-05,
      "loss": 1.8018,
      "step": 644
    },
    {
      "epoch": 0.34528907922912205,
      "grad_norm": 0.0,
      "learning_rate": 1.3104925053533191e-05,
      "loss": 1.4317,
      "step": 645
    },
    {
      "epoch": 0.34582441113490364,
      "grad_norm": 0.0,
      "learning_rate": 1.309421841541756e-05,
      "loss": 1.6168,
      "step": 646
    },
    {
      "epoch": 0.34635974304068523,
      "grad_norm": 0.0,
      "learning_rate": 1.308351177730193e-05,
      "loss": 1.6888,
      "step": 647
    },
    {
      "epoch": 0.3468950749464668,
      "grad_norm": 0.0,
      "learning_rate": 1.3072805139186297e-05,
      "loss": 1.794,
      "step": 648
    },
    {
      "epoch": 0.3474304068522484,
      "grad_norm": 0.0,
      "learning_rate": 1.3062098501070666e-05,
      "loss": 1.7063,
      "step": 649
    },
    {
      "epoch": 0.34796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.3051391862955034e-05,
      "loss": 1.4385,
      "step": 650
    },
    {
      "epoch": 0.3485010706638116,
      "grad_norm": 0.0,
      "learning_rate": 1.3040685224839403e-05,
      "loss": 1.4401,
      "step": 651
    },
    {
      "epoch": 0.3490364025695932,
      "grad_norm": 0.0,
      "learning_rate": 1.302997858672377e-05,
      "loss": 1.4484,
      "step": 652
    },
    {
      "epoch": 0.3495717344753747,
      "grad_norm": 0.0,
      "learning_rate": 1.3019271948608139e-05,
      "loss": 1.3961,
      "step": 653
    },
    {
      "epoch": 0.3501070663811563,
      "grad_norm": 0.0,
      "learning_rate": 1.3008565310492507e-05,
      "loss": 1.8393,
      "step": 654
    },
    {
      "epoch": 0.3506423982869379,
      "grad_norm": 0.0,
      "learning_rate": 1.2997858672376876e-05,
      "loss": 1.6868,
      "step": 655
    },
    {
      "epoch": 0.3511777301927195,
      "grad_norm": 0.0,
      "learning_rate": 1.2987152034261243e-05,
      "loss": 1.3385,
      "step": 656
    },
    {
      "epoch": 0.35171306209850106,
      "grad_norm": 0.0,
      "learning_rate": 1.2976445396145612e-05,
      "loss": 1.6929,
      "step": 657
    },
    {
      "epoch": 0.35224839400428265,
      "grad_norm": 0.0,
      "learning_rate": 1.296573875802998e-05,
      "loss": 1.493,
      "step": 658
    },
    {
      "epoch": 0.35278372591006424,
      "grad_norm": 0.0,
      "learning_rate": 1.2955032119914347e-05,
      "loss": 1.5214,
      "step": 659
    },
    {
      "epoch": 0.3533190578158458,
      "grad_norm": 0.0,
      "learning_rate": 1.2944325481798716e-05,
      "loss": 1.5809,
      "step": 660
    },
    {
      "epoch": 0.3538543897216274,
      "grad_norm": 0.0,
      "learning_rate": 1.2933618843683085e-05,
      "loss": 1.4349,
      "step": 661
    },
    {
      "epoch": 0.354389721627409,
      "grad_norm": 0.0,
      "learning_rate": 1.2922912205567453e-05,
      "loss": 1.6021,
      "step": 662
    },
    {
      "epoch": 0.3549250535331906,
      "grad_norm": 0.0,
      "learning_rate": 1.291220556745182e-05,
      "loss": 1.5417,
      "step": 663
    },
    {
      "epoch": 0.3554603854389722,
      "grad_norm": 0.0,
      "learning_rate": 1.2901498929336189e-05,
      "loss": 1.8829,
      "step": 664
    },
    {
      "epoch": 0.35599571734475377,
      "grad_norm": 0.0,
      "learning_rate": 1.2890792291220558e-05,
      "loss": 1.5727,
      "step": 665
    },
    {
      "epoch": 0.35653104925053536,
      "grad_norm": 0.0,
      "learning_rate": 1.2880085653104926e-05,
      "loss": 1.6488,
      "step": 666
    },
    {
      "epoch": 0.3570663811563169,
      "grad_norm": 0.0,
      "learning_rate": 1.2869379014989293e-05,
      "loss": 1.475,
      "step": 667
    },
    {
      "epoch": 0.3576017130620985,
      "grad_norm": 0.0,
      "learning_rate": 1.2858672376873662e-05,
      "loss": 1.6069,
      "step": 668
    },
    {
      "epoch": 0.35813704496788007,
      "grad_norm": 0.0,
      "learning_rate": 1.284796573875803e-05,
      "loss": 1.5961,
      "step": 669
    },
    {
      "epoch": 0.35867237687366166,
      "grad_norm": 0.0,
      "learning_rate": 1.28372591006424e-05,
      "loss": 1.5344,
      "step": 670
    },
    {
      "epoch": 0.35920770877944325,
      "grad_norm": 0.0,
      "learning_rate": 1.2826552462526766e-05,
      "loss": 1.4805,
      "step": 671
    },
    {
      "epoch": 0.35974304068522484,
      "grad_norm": 0.0,
      "learning_rate": 1.2815845824411135e-05,
      "loss": 1.5566,
      "step": 672
    },
    {
      "epoch": 0.3602783725910064,
      "grad_norm": 0.0,
      "learning_rate": 1.2805139186295504e-05,
      "loss": 1.5058,
      "step": 673
    },
    {
      "epoch": 0.360813704496788,
      "grad_norm": 0.0,
      "learning_rate": 1.2794432548179872e-05,
      "loss": 1.4391,
      "step": 674
    },
    {
      "epoch": 0.3613490364025696,
      "grad_norm": 0.0,
      "learning_rate": 1.2783725910064243e-05,
      "loss": 1.4542,
      "step": 675
    },
    {
      "epoch": 0.3618843683083512,
      "grad_norm": 0.0,
      "learning_rate": 1.277301927194861e-05,
      "loss": 1.55,
      "step": 676
    },
    {
      "epoch": 0.3624197002141328,
      "grad_norm": 0.0,
      "learning_rate": 1.2762312633832978e-05,
      "loss": 1.593,
      "step": 677
    },
    {
      "epoch": 0.36295503211991437,
      "grad_norm": 0.0,
      "learning_rate": 1.2751605995717347e-05,
      "loss": 1.7575,
      "step": 678
    },
    {
      "epoch": 0.36349036402569596,
      "grad_norm": 0.0,
      "learning_rate": 1.2740899357601716e-05,
      "loss": 1.348,
      "step": 679
    },
    {
      "epoch": 0.3640256959314775,
      "grad_norm": 0.0,
      "learning_rate": 1.2730192719486083e-05,
      "loss": 1.5185,
      "step": 680
    },
    {
      "epoch": 0.3645610278372591,
      "grad_norm": 0.0,
      "learning_rate": 1.2719486081370451e-05,
      "loss": 1.4327,
      "step": 681
    },
    {
      "epoch": 0.36509635974304067,
      "grad_norm": 0.0,
      "learning_rate": 1.270877944325482e-05,
      "loss": 1.4222,
      "step": 682
    },
    {
      "epoch": 0.36563169164882225,
      "grad_norm": 0.0,
      "learning_rate": 1.2698072805139187e-05,
      "loss": 1.4864,
      "step": 683
    },
    {
      "epoch": 0.36616702355460384,
      "grad_norm": 0.0,
      "learning_rate": 1.2687366167023556e-05,
      "loss": 1.4136,
      "step": 684
    },
    {
      "epoch": 0.36670235546038543,
      "grad_norm": 0.0,
      "learning_rate": 1.2676659528907924e-05,
      "loss": 1.6616,
      "step": 685
    },
    {
      "epoch": 0.367237687366167,
      "grad_norm": 0.0,
      "learning_rate": 1.2665952890792293e-05,
      "loss": 1.4534,
      "step": 686
    },
    {
      "epoch": 0.3677730192719486,
      "grad_norm": 0.0,
      "learning_rate": 1.265524625267666e-05,
      "loss": 1.6174,
      "step": 687
    },
    {
      "epoch": 0.3683083511777302,
      "grad_norm": 0.0,
      "learning_rate": 1.2644539614561029e-05,
      "loss": 1.4645,
      "step": 688
    },
    {
      "epoch": 0.3688436830835118,
      "grad_norm": 0.0,
      "learning_rate": 1.2633832976445397e-05,
      "loss": 1.4159,
      "step": 689
    },
    {
      "epoch": 0.3693790149892934,
      "grad_norm": 0.0,
      "learning_rate": 1.2623126338329766e-05,
      "loss": 1.5735,
      "step": 690
    },
    {
      "epoch": 0.36991434689507496,
      "grad_norm": 0.0,
      "learning_rate": 1.2612419700214133e-05,
      "loss": 1.7357,
      "step": 691
    },
    {
      "epoch": 0.37044967880085655,
      "grad_norm": 0.0,
      "learning_rate": 1.2601713062098502e-05,
      "loss": 1.7632,
      "step": 692
    },
    {
      "epoch": 0.37098501070663814,
      "grad_norm": 0.0,
      "learning_rate": 1.259100642398287e-05,
      "loss": 1.6528,
      "step": 693
    },
    {
      "epoch": 0.3715203426124197,
      "grad_norm": 0.0,
      "learning_rate": 1.2580299785867239e-05,
      "loss": 1.872,
      "step": 694
    },
    {
      "epoch": 0.37205567451820126,
      "grad_norm": 0.0,
      "learning_rate": 1.2569593147751606e-05,
      "loss": 1.6637,
      "step": 695
    },
    {
      "epoch": 0.37259100642398285,
      "grad_norm": 0.0,
      "learning_rate": 1.2558886509635975e-05,
      "loss": 1.7693,
      "step": 696
    },
    {
      "epoch": 0.37312633832976444,
      "grad_norm": 0.0,
      "learning_rate": 1.2548179871520343e-05,
      "loss": 1.5142,
      "step": 697
    },
    {
      "epoch": 0.37366167023554603,
      "grad_norm": 0.0,
      "learning_rate": 1.2537473233404712e-05,
      "loss": 1.4415,
      "step": 698
    },
    {
      "epoch": 0.3741970021413276,
      "grad_norm": 0.0,
      "learning_rate": 1.2526766595289079e-05,
      "loss": 1.355,
      "step": 699
    },
    {
      "epoch": 0.3747323340471092,
      "grad_norm": 0.0,
      "learning_rate": 1.2516059957173448e-05,
      "loss": 1.7553,
      "step": 700
    },
    {
      "epoch": 0.3752676659528908,
      "grad_norm": 0.0,
      "learning_rate": 1.2505353319057816e-05,
      "loss": 1.5935,
      "step": 701
    },
    {
      "epoch": 0.3758029978586724,
      "grad_norm": 0.0,
      "learning_rate": 1.2494646680942187e-05,
      "loss": 1.4457,
      "step": 702
    },
    {
      "epoch": 0.37633832976445397,
      "grad_norm": 0.0,
      "learning_rate": 1.2483940042826555e-05,
      "loss": 1.6993,
      "step": 703
    },
    {
      "epoch": 0.37687366167023556,
      "grad_norm": 0.0,
      "learning_rate": 1.2473233404710922e-05,
      "loss": 1.5471,
      "step": 704
    },
    {
      "epoch": 0.37740899357601715,
      "grad_norm": 0.0,
      "learning_rate": 1.2462526766595291e-05,
      "loss": 1.7982,
      "step": 705
    },
    {
      "epoch": 0.37794432548179874,
      "grad_norm": 0.0,
      "learning_rate": 1.245182012847966e-05,
      "loss": 1.4648,
      "step": 706
    },
    {
      "epoch": 0.3784796573875803,
      "grad_norm": 0.0,
      "learning_rate": 1.2441113490364027e-05,
      "loss": 1.5797,
      "step": 707
    },
    {
      "epoch": 0.37901498929336186,
      "grad_norm": 0.0,
      "learning_rate": 1.2430406852248395e-05,
      "loss": 1.3652,
      "step": 708
    },
    {
      "epoch": 0.37955032119914345,
      "grad_norm": 0.0,
      "learning_rate": 1.2419700214132764e-05,
      "loss": 1.3771,
      "step": 709
    },
    {
      "epoch": 0.38008565310492504,
      "grad_norm": 0.0,
      "learning_rate": 1.2408993576017133e-05,
      "loss": 1.409,
      "step": 710
    },
    {
      "epoch": 0.3806209850107066,
      "grad_norm": 0.0,
      "learning_rate": 1.23982869379015e-05,
      "loss": 1.5697,
      "step": 711
    },
    {
      "epoch": 0.3811563169164882,
      "grad_norm": 0.0,
      "learning_rate": 1.2387580299785868e-05,
      "loss": 1.5075,
      "step": 712
    },
    {
      "epoch": 0.3816916488222698,
      "grad_norm": 0.0,
      "learning_rate": 1.2376873661670237e-05,
      "loss": 1.394,
      "step": 713
    },
    {
      "epoch": 0.3822269807280514,
      "grad_norm": 0.0,
      "learning_rate": 1.2366167023554606e-05,
      "loss": 1.7887,
      "step": 714
    },
    {
      "epoch": 0.382762312633833,
      "grad_norm": 0.0,
      "learning_rate": 1.2355460385438973e-05,
      "loss": 1.5921,
      "step": 715
    },
    {
      "epoch": 0.38329764453961457,
      "grad_norm": 0.0,
      "learning_rate": 1.2344753747323341e-05,
      "loss": 1.3576,
      "step": 716
    },
    {
      "epoch": 0.38383297644539616,
      "grad_norm": 0.0,
      "learning_rate": 1.233404710920771e-05,
      "loss": 1.4551,
      "step": 717
    },
    {
      "epoch": 0.38436830835117775,
      "grad_norm": 0.0,
      "learning_rate": 1.2323340471092079e-05,
      "loss": 1.5269,
      "step": 718
    },
    {
      "epoch": 0.38490364025695933,
      "grad_norm": 0.0,
      "learning_rate": 1.2312633832976446e-05,
      "loss": 1.5284,
      "step": 719
    },
    {
      "epoch": 0.3854389721627409,
      "grad_norm": 0.0,
      "learning_rate": 1.2301927194860814e-05,
      "loss": 1.8778,
      "step": 720
    },
    {
      "epoch": 0.3859743040685225,
      "grad_norm": 0.0,
      "learning_rate": 1.2291220556745183e-05,
      "loss": 1.6316,
      "step": 721
    },
    {
      "epoch": 0.38650963597430404,
      "grad_norm": 0.0,
      "learning_rate": 1.2280513918629552e-05,
      "loss": 1.5883,
      "step": 722
    },
    {
      "epoch": 0.38704496788008563,
      "grad_norm": 0.0,
      "learning_rate": 1.2269807280513919e-05,
      "loss": 1.4983,
      "step": 723
    },
    {
      "epoch": 0.3875802997858672,
      "grad_norm": 0.0,
      "learning_rate": 1.2259100642398287e-05,
      "loss": 1.3253,
      "step": 724
    },
    {
      "epoch": 0.3881156316916488,
      "grad_norm": 0.0,
      "learning_rate": 1.2248394004282656e-05,
      "loss": 1.5989,
      "step": 725
    },
    {
      "epoch": 0.3886509635974304,
      "grad_norm": 0.0,
      "learning_rate": 1.2237687366167023e-05,
      "loss": 1.4927,
      "step": 726
    },
    {
      "epoch": 0.389186295503212,
      "grad_norm": 0.0,
      "learning_rate": 1.2226980728051392e-05,
      "loss": 1.8165,
      "step": 727
    },
    {
      "epoch": 0.3897216274089936,
      "grad_norm": 0.0,
      "learning_rate": 1.221627408993576e-05,
      "loss": 1.8202,
      "step": 728
    },
    {
      "epoch": 0.39025695931477516,
      "grad_norm": 0.0,
      "learning_rate": 1.220556745182013e-05,
      "loss": 1.6476,
      "step": 729
    },
    {
      "epoch": 0.39079229122055675,
      "grad_norm": 0.0,
      "learning_rate": 1.21948608137045e-05,
      "loss": 1.7894,
      "step": 730
    },
    {
      "epoch": 0.39132762312633834,
      "grad_norm": 0.0,
      "learning_rate": 1.2184154175588866e-05,
      "loss": 1.4216,
      "step": 731
    },
    {
      "epoch": 0.39186295503211993,
      "grad_norm": 0.0,
      "learning_rate": 1.2173447537473235e-05,
      "loss": 1.4916,
      "step": 732
    },
    {
      "epoch": 0.3923982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.2162740899357604e-05,
      "loss": 1.4696,
      "step": 733
    },
    {
      "epoch": 0.3929336188436831,
      "grad_norm": 0.0,
      "learning_rate": 1.2152034261241972e-05,
      "loss": 1.7914,
      "step": 734
    },
    {
      "epoch": 0.39346895074946464,
      "grad_norm": 0.0,
      "learning_rate": 1.214132762312634e-05,
      "loss": 1.9227,
      "step": 735
    },
    {
      "epoch": 0.39400428265524623,
      "grad_norm": 0.0,
      "learning_rate": 1.2130620985010708e-05,
      "loss": 1.7634,
      "step": 736
    },
    {
      "epoch": 0.3945396145610278,
      "grad_norm": 0.0,
      "learning_rate": 1.2119914346895077e-05,
      "loss": 1.4678,
      "step": 737
    },
    {
      "epoch": 0.3950749464668094,
      "grad_norm": 0.0,
      "learning_rate": 1.2109207708779445e-05,
      "loss": 1.7492,
      "step": 738
    },
    {
      "epoch": 0.395610278372591,
      "grad_norm": 0.0,
      "learning_rate": 1.2098501070663812e-05,
      "loss": 1.5315,
      "step": 739
    },
    {
      "epoch": 0.3961456102783726,
      "grad_norm": 0.0,
      "learning_rate": 1.2087794432548181e-05,
      "loss": 1.5746,
      "step": 740
    },
    {
      "epoch": 0.3966809421841542,
      "grad_norm": 0.0,
      "learning_rate": 1.207708779443255e-05,
      "loss": 1.6186,
      "step": 741
    },
    {
      "epoch": 0.39721627408993576,
      "grad_norm": 0.0,
      "learning_rate": 1.2066381156316918e-05,
      "loss": 1.8719,
      "step": 742
    },
    {
      "epoch": 0.39775160599571735,
      "grad_norm": 0.0,
      "learning_rate": 1.2055674518201285e-05,
      "loss": 1.5006,
      "step": 743
    },
    {
      "epoch": 0.39828693790149894,
      "grad_norm": 0.0,
      "learning_rate": 1.2044967880085654e-05,
      "loss": 1.4275,
      "step": 744
    },
    {
      "epoch": 0.3988222698072805,
      "grad_norm": 0.0,
      "learning_rate": 1.2034261241970023e-05,
      "loss": 1.5535,
      "step": 745
    },
    {
      "epoch": 0.3993576017130621,
      "grad_norm": 0.0,
      "learning_rate": 1.2023554603854391e-05,
      "loss": 1.5829,
      "step": 746
    },
    {
      "epoch": 0.3998929336188437,
      "grad_norm": 0.0,
      "learning_rate": 1.2012847965738758e-05,
      "loss": 1.8938,
      "step": 747
    },
    {
      "epoch": 0.4004282655246253,
      "grad_norm": 0.0,
      "learning_rate": 1.2002141327623127e-05,
      "loss": 1.7871,
      "step": 748
    },
    {
      "epoch": 0.4009635974304068,
      "grad_norm": 0.0,
      "learning_rate": 1.1991434689507496e-05,
      "loss": 1.5101,
      "step": 749
    },
    {
      "epoch": 0.4014989293361884,
      "grad_norm": 0.0,
      "learning_rate": 1.1980728051391863e-05,
      "loss": 1.5394,
      "step": 750
    },
    {
      "epoch": 0.40203426124197,
      "grad_norm": 0.0,
      "learning_rate": 1.1970021413276231e-05,
      "loss": 1.7482,
      "step": 751
    },
    {
      "epoch": 0.4025695931477516,
      "grad_norm": 0.0,
      "learning_rate": 1.19593147751606e-05,
      "loss": 1.4722,
      "step": 752
    },
    {
      "epoch": 0.4031049250535332,
      "grad_norm": 0.0,
      "learning_rate": 1.1948608137044969e-05,
      "loss": 1.4246,
      "step": 753
    },
    {
      "epoch": 0.40364025695931477,
      "grad_norm": 0.0,
      "learning_rate": 1.1937901498929336e-05,
      "loss": 1.6282,
      "step": 754
    },
    {
      "epoch": 0.40417558886509636,
      "grad_norm": 0.0,
      "learning_rate": 1.1927194860813704e-05,
      "loss": 1.6602,
      "step": 755
    },
    {
      "epoch": 0.40471092077087795,
      "grad_norm": 0.0,
      "learning_rate": 1.1916488222698073e-05,
      "loss": 1.7031,
      "step": 756
    },
    {
      "epoch": 0.40524625267665954,
      "grad_norm": 0.0,
      "learning_rate": 1.1905781584582443e-05,
      "loss": 1.6707,
      "step": 757
    },
    {
      "epoch": 0.4057815845824411,
      "grad_norm": 0.0,
      "learning_rate": 1.1895074946466812e-05,
      "loss": 1.6092,
      "step": 758
    },
    {
      "epoch": 0.4063169164882227,
      "grad_norm": 0.0,
      "learning_rate": 1.1884368308351179e-05,
      "loss": 1.6925,
      "step": 759
    },
    {
      "epoch": 0.4068522483940043,
      "grad_norm": 0.0,
      "learning_rate": 1.1873661670235548e-05,
      "loss": 1.7837,
      "step": 760
    },
    {
      "epoch": 0.4073875802997859,
      "grad_norm": 0.0,
      "learning_rate": 1.1862955032119916e-05,
      "loss": 1.356,
      "step": 761
    },
    {
      "epoch": 0.4079229122055675,
      "grad_norm": 0.0,
      "learning_rate": 1.1852248394004285e-05,
      "loss": 1.7324,
      "step": 762
    },
    {
      "epoch": 0.408458244111349,
      "grad_norm": 0.0,
      "learning_rate": 1.1841541755888652e-05,
      "loss": 1.7864,
      "step": 763
    },
    {
      "epoch": 0.4089935760171306,
      "grad_norm": 0.0,
      "learning_rate": 1.183083511777302e-05,
      "loss": 1.6529,
      "step": 764
    },
    {
      "epoch": 0.4095289079229122,
      "grad_norm": 0.0,
      "learning_rate": 1.182012847965739e-05,
      "loss": 1.4487,
      "step": 765
    },
    {
      "epoch": 0.4100642398286938,
      "grad_norm": 0.0,
      "learning_rate": 1.1809421841541758e-05,
      "loss": 1.5908,
      "step": 766
    },
    {
      "epoch": 0.41059957173447537,
      "grad_norm": 0.0,
      "learning_rate": 1.1798715203426125e-05,
      "loss": 1.5685,
      "step": 767
    },
    {
      "epoch": 0.41113490364025695,
      "grad_norm": 0.0,
      "learning_rate": 1.1788008565310494e-05,
      "loss": 1.522,
      "step": 768
    },
    {
      "epoch": 0.41167023554603854,
      "grad_norm": 0.0,
      "learning_rate": 1.1777301927194862e-05,
      "loss": 1.6907,
      "step": 769
    },
    {
      "epoch": 0.41220556745182013,
      "grad_norm": 0.0,
      "learning_rate": 1.1766595289079231e-05,
      "loss": 1.6148,
      "step": 770
    },
    {
      "epoch": 0.4127408993576017,
      "grad_norm": 0.0,
      "learning_rate": 1.1755888650963598e-05,
      "loss": 1.8629,
      "step": 771
    },
    {
      "epoch": 0.4132762312633833,
      "grad_norm": 0.0,
      "learning_rate": 1.1745182012847967e-05,
      "loss": 1.5897,
      "step": 772
    },
    {
      "epoch": 0.4138115631691649,
      "grad_norm": 0.0,
      "learning_rate": 1.1734475374732335e-05,
      "loss": 1.612,
      "step": 773
    },
    {
      "epoch": 0.4143468950749465,
      "grad_norm": 0.0,
      "learning_rate": 1.1723768736616702e-05,
      "loss": 1.9789,
      "step": 774
    },
    {
      "epoch": 0.4148822269807281,
      "grad_norm": 0.0,
      "learning_rate": 1.1713062098501071e-05,
      "loss": 1.6723,
      "step": 775
    },
    {
      "epoch": 0.41541755888650966,
      "grad_norm": 0.0,
      "learning_rate": 1.170235546038544e-05,
      "loss": 1.6466,
      "step": 776
    },
    {
      "epoch": 0.4159528907922912,
      "grad_norm": 0.0,
      "learning_rate": 1.1691648822269808e-05,
      "loss": 1.7833,
      "step": 777
    },
    {
      "epoch": 0.4164882226980728,
      "grad_norm": 0.0,
      "learning_rate": 1.1680942184154175e-05,
      "loss": 1.7427,
      "step": 778
    },
    {
      "epoch": 0.4170235546038544,
      "grad_norm": 0.0,
      "learning_rate": 1.1670235546038544e-05,
      "loss": 1.8225,
      "step": 779
    },
    {
      "epoch": 0.41755888650963596,
      "grad_norm": 0.0,
      "learning_rate": 1.1659528907922913e-05,
      "loss": 1.5748,
      "step": 780
    },
    {
      "epoch": 0.41809421841541755,
      "grad_norm": 0.0,
      "learning_rate": 1.1648822269807281e-05,
      "loss": 1.7525,
      "step": 781
    },
    {
      "epoch": 0.41862955032119914,
      "grad_norm": 0.0,
      "learning_rate": 1.1638115631691648e-05,
      "loss": 1.469,
      "step": 782
    },
    {
      "epoch": 0.41916488222698073,
      "grad_norm": 0.0,
      "learning_rate": 1.1627408993576017e-05,
      "loss": 1.5462,
      "step": 783
    },
    {
      "epoch": 0.4197002141327623,
      "grad_norm": 0.0,
      "learning_rate": 1.1616702355460387e-05,
      "loss": 1.7137,
      "step": 784
    },
    {
      "epoch": 0.4202355460385439,
      "grad_norm": 0.0,
      "learning_rate": 1.1605995717344756e-05,
      "loss": 1.5412,
      "step": 785
    },
    {
      "epoch": 0.4207708779443255,
      "grad_norm": 0.0,
      "learning_rate": 1.1595289079229125e-05,
      "loss": 1.442,
      "step": 786
    },
    {
      "epoch": 0.4213062098501071,
      "grad_norm": 0.0,
      "learning_rate": 1.1584582441113492e-05,
      "loss": 1.5357,
      "step": 787
    },
    {
      "epoch": 0.42184154175588867,
      "grad_norm": 0.0,
      "learning_rate": 1.157387580299786e-05,
      "loss": 1.719,
      "step": 788
    },
    {
      "epoch": 0.42237687366167026,
      "grad_norm": 0.0,
      "learning_rate": 1.1563169164882229e-05,
      "loss": 2.3323,
      "step": 789
    },
    {
      "epoch": 0.4229122055674518,
      "grad_norm": 0.0,
      "learning_rate": 1.1552462526766598e-05,
      "loss": 1.7193,
      "step": 790
    },
    {
      "epoch": 0.4234475374732334,
      "grad_norm": 0.0,
      "learning_rate": 1.1541755888650965e-05,
      "loss": 1.4185,
      "step": 791
    },
    {
      "epoch": 0.42398286937901497,
      "grad_norm": 0.0,
      "learning_rate": 1.1531049250535333e-05,
      "loss": 1.5112,
      "step": 792
    },
    {
      "epoch": 0.42451820128479656,
      "grad_norm": 0.0,
      "learning_rate": 1.1520342612419702e-05,
      "loss": 1.4734,
      "step": 793
    },
    {
      "epoch": 0.42505353319057815,
      "grad_norm": 0.0,
      "learning_rate": 1.150963597430407e-05,
      "loss": 1.6898,
      "step": 794
    },
    {
      "epoch": 0.42558886509635974,
      "grad_norm": 0.0,
      "learning_rate": 1.1498929336188438e-05,
      "loss": 1.4313,
      "step": 795
    },
    {
      "epoch": 0.4261241970021413,
      "grad_norm": 0.0,
      "learning_rate": 1.1488222698072806e-05,
      "loss": 1.5765,
      "step": 796
    },
    {
      "epoch": 0.4266595289079229,
      "grad_norm": 0.0,
      "learning_rate": 1.1477516059957175e-05,
      "loss": 1.6614,
      "step": 797
    },
    {
      "epoch": 0.4271948608137045,
      "grad_norm": 0.0,
      "learning_rate": 1.1466809421841542e-05,
      "loss": 1.5283,
      "step": 798
    },
    {
      "epoch": 0.4277301927194861,
      "grad_norm": 0.0,
      "learning_rate": 1.145610278372591e-05,
      "loss": 1.5,
      "step": 799
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 0.0,
      "learning_rate": 1.144539614561028e-05,
      "loss": 1.6872,
      "step": 800
    },
    {
      "epoch": 0.42880085653104927,
      "grad_norm": 0.0,
      "learning_rate": 1.1434689507494648e-05,
      "loss": 1.3975,
      "step": 801
    },
    {
      "epoch": 0.42933618843683086,
      "grad_norm": 0.0,
      "learning_rate": 1.1423982869379015e-05,
      "loss": 1.4534,
      "step": 802
    },
    {
      "epoch": 0.42987152034261245,
      "grad_norm": 0.0,
      "learning_rate": 1.1413276231263384e-05,
      "loss": 1.687,
      "step": 803
    },
    {
      "epoch": 0.430406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.1402569593147752e-05,
      "loss": 1.3417,
      "step": 804
    },
    {
      "epoch": 0.43094218415417557,
      "grad_norm": 0.0,
      "learning_rate": 1.1391862955032121e-05,
      "loss": 1.6137,
      "step": 805
    },
    {
      "epoch": 0.43147751605995716,
      "grad_norm": 0.0,
      "learning_rate": 1.1381156316916488e-05,
      "loss": 1.4456,
      "step": 806
    },
    {
      "epoch": 0.43201284796573874,
      "grad_norm": 0.0,
      "learning_rate": 1.1370449678800857e-05,
      "loss": 1.6507,
      "step": 807
    },
    {
      "epoch": 0.43254817987152033,
      "grad_norm": 0.0,
      "learning_rate": 1.1359743040685225e-05,
      "loss": 1.5801,
      "step": 808
    },
    {
      "epoch": 0.4330835117773019,
      "grad_norm": 0.0,
      "learning_rate": 1.1349036402569594e-05,
      "loss": 1.5312,
      "step": 809
    },
    {
      "epoch": 0.4336188436830835,
      "grad_norm": 0.0,
      "learning_rate": 1.1338329764453961e-05,
      "loss": 1.2869,
      "step": 810
    },
    {
      "epoch": 0.4341541755888651,
      "grad_norm": 0.0,
      "learning_rate": 1.132762312633833e-05,
      "loss": 1.4211,
      "step": 811
    },
    {
      "epoch": 0.4346895074946467,
      "grad_norm": 0.0,
      "learning_rate": 1.13169164882227e-05,
      "loss": 1.4868,
      "step": 812
    },
    {
      "epoch": 0.4352248394004283,
      "grad_norm": 0.0,
      "learning_rate": 1.1306209850107069e-05,
      "loss": 1.7423,
      "step": 813
    },
    {
      "epoch": 0.43576017130620986,
      "grad_norm": 0.0,
      "learning_rate": 1.1295503211991437e-05,
      "loss": 1.6438,
      "step": 814
    },
    {
      "epoch": 0.43629550321199145,
      "grad_norm": 0.0,
      "learning_rate": 1.1284796573875804e-05,
      "loss": 1.5741,
      "step": 815
    },
    {
      "epoch": 0.43683083511777304,
      "grad_norm": 0.0,
      "learning_rate": 1.1274089935760173e-05,
      "loss": 1.7878,
      "step": 816
    },
    {
      "epoch": 0.43736616702355463,
      "grad_norm": 0.0,
      "learning_rate": 1.1263383297644542e-05,
      "loss": 1.55,
      "step": 817
    },
    {
      "epoch": 0.43790149892933616,
      "grad_norm": 0.0,
      "learning_rate": 1.125267665952891e-05,
      "loss": 1.5922,
      "step": 818
    },
    {
      "epoch": 0.43843683083511775,
      "grad_norm": 0.0,
      "learning_rate": 1.1241970021413277e-05,
      "loss": 1.7222,
      "step": 819
    },
    {
      "epoch": 0.43897216274089934,
      "grad_norm": 0.0,
      "learning_rate": 1.1231263383297646e-05,
      "loss": 1.4695,
      "step": 820
    },
    {
      "epoch": 0.43950749464668093,
      "grad_norm": 0.0,
      "learning_rate": 1.1220556745182015e-05,
      "loss": 1.8177,
      "step": 821
    },
    {
      "epoch": 0.4400428265524625,
      "grad_norm": 0.0,
      "learning_rate": 1.1209850107066382e-05,
      "loss": 1.8042,
      "step": 822
    },
    {
      "epoch": 0.4405781584582441,
      "grad_norm": 0.0,
      "learning_rate": 1.119914346895075e-05,
      "loss": 1.5947,
      "step": 823
    },
    {
      "epoch": 0.4411134903640257,
      "grad_norm": 0.0,
      "learning_rate": 1.1188436830835119e-05,
      "loss": 1.7252,
      "step": 824
    },
    {
      "epoch": 0.4416488222698073,
      "grad_norm": 0.0,
      "learning_rate": 1.1177730192719488e-05,
      "loss": 1.4169,
      "step": 825
    },
    {
      "epoch": 0.4421841541755889,
      "grad_norm": 0.0,
      "learning_rate": 1.1167023554603855e-05,
      "loss": 1.6727,
      "step": 826
    },
    {
      "epoch": 0.44271948608137046,
      "grad_norm": 0.0,
      "learning_rate": 1.1156316916488223e-05,
      "loss": 1.5896,
      "step": 827
    },
    {
      "epoch": 0.44325481798715205,
      "grad_norm": 0.0,
      "learning_rate": 1.1145610278372592e-05,
      "loss": 1.4571,
      "step": 828
    },
    {
      "epoch": 0.44379014989293364,
      "grad_norm": 0.0,
      "learning_rate": 1.113490364025696e-05,
      "loss": 1.9422,
      "step": 829
    },
    {
      "epoch": 0.4443254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.1124197002141328e-05,
      "loss": 1.8355,
      "step": 830
    },
    {
      "epoch": 0.44486081370449676,
      "grad_norm": 0.0,
      "learning_rate": 1.1113490364025696e-05,
      "loss": 1.6315,
      "step": 831
    },
    {
      "epoch": 0.44539614561027835,
      "grad_norm": 0.0,
      "learning_rate": 1.1102783725910065e-05,
      "loss": 1.4616,
      "step": 832
    },
    {
      "epoch": 0.44593147751605994,
      "grad_norm": 0.0,
      "learning_rate": 1.1092077087794434e-05,
      "loss": 1.7993,
      "step": 833
    },
    {
      "epoch": 0.4464668094218415,
      "grad_norm": 0.0,
      "learning_rate": 1.10813704496788e-05,
      "loss": 1.6591,
      "step": 834
    },
    {
      "epoch": 0.4470021413276231,
      "grad_norm": 0.0,
      "learning_rate": 1.107066381156317e-05,
      "loss": 1.5917,
      "step": 835
    },
    {
      "epoch": 0.4475374732334047,
      "grad_norm": 0.0,
      "learning_rate": 1.1059957173447538e-05,
      "loss": 1.7454,
      "step": 836
    },
    {
      "epoch": 0.4480728051391863,
      "grad_norm": 0.0,
      "learning_rate": 1.1049250535331907e-05,
      "loss": 1.962,
      "step": 837
    },
    {
      "epoch": 0.4486081370449679,
      "grad_norm": 0.0,
      "learning_rate": 1.1038543897216274e-05,
      "loss": 1.5713,
      "step": 838
    },
    {
      "epoch": 0.44914346895074947,
      "grad_norm": 0.0,
      "learning_rate": 1.1027837259100644e-05,
      "loss": 1.7067,
      "step": 839
    },
    {
      "epoch": 0.44967880085653106,
      "grad_norm": 0.0,
      "learning_rate": 1.1017130620985013e-05,
      "loss": 1.5829,
      "step": 840
    },
    {
      "epoch": 0.45021413276231265,
      "grad_norm": 0.0,
      "learning_rate": 1.1006423982869381e-05,
      "loss": 1.6506,
      "step": 841
    },
    {
      "epoch": 0.45074946466809424,
      "grad_norm": 0.0,
      "learning_rate": 1.099571734475375e-05,
      "loss": 1.5593,
      "step": 842
    },
    {
      "epoch": 0.4512847965738758,
      "grad_norm": 0.0,
      "learning_rate": 1.0985010706638117e-05,
      "loss": 1.6673,
      "step": 843
    },
    {
      "epoch": 0.4518201284796574,
      "grad_norm": 0.0,
      "learning_rate": 1.0974304068522486e-05,
      "loss": 1.6416,
      "step": 844
    },
    {
      "epoch": 0.45235546038543895,
      "grad_norm": 0.0,
      "learning_rate": 1.0963597430406854e-05,
      "loss": 1.6445,
      "step": 845
    },
    {
      "epoch": 0.45289079229122053,
      "grad_norm": 0.0,
      "learning_rate": 1.0952890792291221e-05,
      "loss": 1.5818,
      "step": 846
    },
    {
      "epoch": 0.4534261241970021,
      "grad_norm": 0.0,
      "learning_rate": 1.094218415417559e-05,
      "loss": 1.6852,
      "step": 847
    },
    {
      "epoch": 0.4539614561027837,
      "grad_norm": 0.0,
      "learning_rate": 1.0931477516059959e-05,
      "loss": 1.4655,
      "step": 848
    },
    {
      "epoch": 0.4544967880085653,
      "grad_norm": 0.0,
      "learning_rate": 1.0920770877944327e-05,
      "loss": 1.6492,
      "step": 849
    },
    {
      "epoch": 0.4550321199143469,
      "grad_norm": 0.0,
      "learning_rate": 1.0910064239828694e-05,
      "loss": 1.9131,
      "step": 850
    },
    {
      "epoch": 0.4555674518201285,
      "grad_norm": 0.0,
      "learning_rate": 1.0899357601713063e-05,
      "loss": 1.454,
      "step": 851
    },
    {
      "epoch": 0.45610278372591007,
      "grad_norm": 0.0,
      "learning_rate": 1.0888650963597432e-05,
      "loss": 1.4781,
      "step": 852
    },
    {
      "epoch": 0.45663811563169165,
      "grad_norm": 0.0,
      "learning_rate": 1.08779443254818e-05,
      "loss": 1.5518,
      "step": 853
    },
    {
      "epoch": 0.45717344753747324,
      "grad_norm": 0.0,
      "learning_rate": 1.0867237687366167e-05,
      "loss": 1.6605,
      "step": 854
    },
    {
      "epoch": 0.45770877944325483,
      "grad_norm": 0.0,
      "learning_rate": 1.0856531049250536e-05,
      "loss": 1.5285,
      "step": 855
    },
    {
      "epoch": 0.4582441113490364,
      "grad_norm": 0.0,
      "learning_rate": 1.0845824411134905e-05,
      "loss": 1.6586,
      "step": 856
    },
    {
      "epoch": 0.458779443254818,
      "grad_norm": 0.0,
      "learning_rate": 1.0835117773019273e-05,
      "loss": 1.5421,
      "step": 857
    },
    {
      "epoch": 0.4593147751605996,
      "grad_norm": 0.0,
      "learning_rate": 1.082441113490364e-05,
      "loss": 1.7562,
      "step": 858
    },
    {
      "epoch": 0.45985010706638113,
      "grad_norm": 0.0,
      "learning_rate": 1.0813704496788009e-05,
      "loss": 2.0916,
      "step": 859
    },
    {
      "epoch": 0.4603854389721627,
      "grad_norm": 0.0,
      "learning_rate": 1.0802997858672378e-05,
      "loss": 1.5595,
      "step": 860
    },
    {
      "epoch": 0.4609207708779443,
      "grad_norm": 0.0,
      "learning_rate": 1.0792291220556746e-05,
      "loss": 1.6356,
      "step": 861
    },
    {
      "epoch": 0.4614561027837259,
      "grad_norm": 0.0,
      "learning_rate": 1.0781584582441113e-05,
      "loss": 1.5697,
      "step": 862
    },
    {
      "epoch": 0.4619914346895075,
      "grad_norm": 0.0,
      "learning_rate": 1.0770877944325482e-05,
      "loss": 1.6507,
      "step": 863
    },
    {
      "epoch": 0.4625267665952891,
      "grad_norm": 0.0,
      "learning_rate": 1.076017130620985e-05,
      "loss": 1.6142,
      "step": 864
    },
    {
      "epoch": 0.46306209850107066,
      "grad_norm": 0.0,
      "learning_rate": 1.0749464668094217e-05,
      "loss": 1.8088,
      "step": 865
    },
    {
      "epoch": 0.46359743040685225,
      "grad_norm": 0.0,
      "learning_rate": 1.0738758029978586e-05,
      "loss": 1.7795,
      "step": 866
    },
    {
      "epoch": 0.46413276231263384,
      "grad_norm": 0.0,
      "learning_rate": 1.0728051391862957e-05,
      "loss": 1.6409,
      "step": 867
    },
    {
      "epoch": 0.46466809421841543,
      "grad_norm": 0.0,
      "learning_rate": 1.0717344753747325e-05,
      "loss": 1.7834,
      "step": 868
    },
    {
      "epoch": 0.465203426124197,
      "grad_norm": 0.0,
      "learning_rate": 1.0706638115631694e-05,
      "loss": 1.463,
      "step": 869
    },
    {
      "epoch": 0.4657387580299786,
      "grad_norm": 0.0,
      "learning_rate": 1.0695931477516061e-05,
      "loss": 1.6938,
      "step": 870
    },
    {
      "epoch": 0.4662740899357602,
      "grad_norm": 0.0,
      "learning_rate": 1.068522483940043e-05,
      "loss": 1.9815,
      "step": 871
    },
    {
      "epoch": 0.4668094218415418,
      "grad_norm": 0.0,
      "learning_rate": 1.0674518201284798e-05,
      "loss": 1.5574,
      "step": 872
    },
    {
      "epoch": 0.4673447537473233,
      "grad_norm": 0.0,
      "learning_rate": 1.0663811563169167e-05,
      "loss": 1.6716,
      "step": 873
    },
    {
      "epoch": 0.4678800856531049,
      "grad_norm": 0.0,
      "learning_rate": 1.0653104925053534e-05,
      "loss": 1.6374,
      "step": 874
    },
    {
      "epoch": 0.4684154175588865,
      "grad_norm": 0.0,
      "learning_rate": 1.0642398286937903e-05,
      "loss": 1.5007,
      "step": 875
    },
    {
      "epoch": 0.4689507494646681,
      "grad_norm": 0.0,
      "learning_rate": 1.0631691648822271e-05,
      "loss": 1.4806,
      "step": 876
    },
    {
      "epoch": 0.46948608137044967,
      "grad_norm": 0.0,
      "learning_rate": 1.062098501070664e-05,
      "loss": 1.6403,
      "step": 877
    },
    {
      "epoch": 0.47002141327623126,
      "grad_norm": 0.0,
      "learning_rate": 1.0610278372591007e-05,
      "loss": 2.0862,
      "step": 878
    },
    {
      "epoch": 0.47055674518201285,
      "grad_norm": 0.0,
      "learning_rate": 1.0599571734475376e-05,
      "loss": 1.4285,
      "step": 879
    },
    {
      "epoch": 0.47109207708779444,
      "grad_norm": 0.0,
      "learning_rate": 1.0588865096359744e-05,
      "loss": 1.6598,
      "step": 880
    },
    {
      "epoch": 0.471627408993576,
      "grad_norm": 0.0,
      "learning_rate": 1.0578158458244113e-05,
      "loss": 1.7167,
      "step": 881
    },
    {
      "epoch": 0.4721627408993576,
      "grad_norm": 0.0,
      "learning_rate": 1.056745182012848e-05,
      "loss": 1.4105,
      "step": 882
    },
    {
      "epoch": 0.4726980728051392,
      "grad_norm": 0.0,
      "learning_rate": 1.0556745182012849e-05,
      "loss": 1.7556,
      "step": 883
    },
    {
      "epoch": 0.4732334047109208,
      "grad_norm": 0.0,
      "learning_rate": 1.0546038543897217e-05,
      "loss": 1.5693,
      "step": 884
    },
    {
      "epoch": 0.4737687366167024,
      "grad_norm": 0.0,
      "learning_rate": 1.0535331905781586e-05,
      "loss": 1.3625,
      "step": 885
    },
    {
      "epoch": 0.4743040685224839,
      "grad_norm": 0.0,
      "learning_rate": 1.0524625267665953e-05,
      "loss": 1.4641,
      "step": 886
    },
    {
      "epoch": 0.4748394004282655,
      "grad_norm": 0.0,
      "learning_rate": 1.0513918629550322e-05,
      "loss": 1.6461,
      "step": 887
    },
    {
      "epoch": 0.4753747323340471,
      "grad_norm": 0.0,
      "learning_rate": 1.050321199143469e-05,
      "loss": 1.3911,
      "step": 888
    },
    {
      "epoch": 0.4759100642398287,
      "grad_norm": 0.0,
      "learning_rate": 1.0492505353319057e-05,
      "loss": 1.5767,
      "step": 889
    },
    {
      "epoch": 0.47644539614561027,
      "grad_norm": 0.0,
      "learning_rate": 1.0481798715203426e-05,
      "loss": 1.6106,
      "step": 890
    },
    {
      "epoch": 0.47698072805139186,
      "grad_norm": 0.0,
      "learning_rate": 1.0471092077087794e-05,
      "loss": 1.5884,
      "step": 891
    },
    {
      "epoch": 0.47751605995717344,
      "grad_norm": 0.0,
      "learning_rate": 1.0460385438972163e-05,
      "loss": 1.4635,
      "step": 892
    },
    {
      "epoch": 0.47805139186295503,
      "grad_norm": 0.0,
      "learning_rate": 1.044967880085653e-05,
      "loss": 1.5132,
      "step": 893
    },
    {
      "epoch": 0.4785867237687366,
      "grad_norm": 0.0,
      "learning_rate": 1.04389721627409e-05,
      "loss": 1.7199,
      "step": 894
    },
    {
      "epoch": 0.4791220556745182,
      "grad_norm": 0.0,
      "learning_rate": 1.042826552462527e-05,
      "loss": 1.6961,
      "step": 895
    },
    {
      "epoch": 0.4796573875802998,
      "grad_norm": 0.0,
      "learning_rate": 1.0417558886509638e-05,
      "loss": 1.3737,
      "step": 896
    },
    {
      "epoch": 0.4801927194860814,
      "grad_norm": 0.0,
      "learning_rate": 1.0406852248394007e-05,
      "loss": 1.5914,
      "step": 897
    },
    {
      "epoch": 0.480728051391863,
      "grad_norm": 0.0,
      "learning_rate": 1.0396145610278374e-05,
      "loss": 1.4891,
      "step": 898
    },
    {
      "epoch": 0.48126338329764456,
      "grad_norm": 0.0,
      "learning_rate": 1.0385438972162742e-05,
      "loss": 1.5778,
      "step": 899
    },
    {
      "epoch": 0.4817987152034261,
      "grad_norm": 0.0,
      "learning_rate": 1.0374732334047111e-05,
      "loss": 1.4593,
      "step": 900
    },
    {
      "epoch": 0.4823340471092077,
      "grad_norm": 0.0,
      "learning_rate": 1.036402569593148e-05,
      "loss": 1.6077,
      "step": 901
    },
    {
      "epoch": 0.4828693790149893,
      "grad_norm": 0.0,
      "learning_rate": 1.0353319057815846e-05,
      "loss": 1.4492,
      "step": 902
    },
    {
      "epoch": 0.48340471092077086,
      "grad_norm": 0.0,
      "learning_rate": 1.0342612419700215e-05,
      "loss": 1.7331,
      "step": 903
    },
    {
      "epoch": 0.48394004282655245,
      "grad_norm": 0.0,
      "learning_rate": 1.0331905781584584e-05,
      "loss": 1.6145,
      "step": 904
    },
    {
      "epoch": 0.48447537473233404,
      "grad_norm": 0.0,
      "learning_rate": 1.0321199143468953e-05,
      "loss": 1.4177,
      "step": 905
    },
    {
      "epoch": 0.48501070663811563,
      "grad_norm": 0.0,
      "learning_rate": 1.031049250535332e-05,
      "loss": 1.5866,
      "step": 906
    },
    {
      "epoch": 0.4855460385438972,
      "grad_norm": 0.0,
      "learning_rate": 1.0299785867237688e-05,
      "loss": 1.5771,
      "step": 907
    },
    {
      "epoch": 0.4860813704496788,
      "grad_norm": 0.0,
      "learning_rate": 1.0289079229122057e-05,
      "loss": 1.345,
      "step": 908
    },
    {
      "epoch": 0.4866167023554604,
      "grad_norm": 0.0,
      "learning_rate": 1.0278372591006426e-05,
      "loss": 1.4794,
      "step": 909
    },
    {
      "epoch": 0.487152034261242,
      "grad_norm": 0.0,
      "learning_rate": 1.0267665952890792e-05,
      "loss": 1.6406,
      "step": 910
    },
    {
      "epoch": 0.4876873661670236,
      "grad_norm": 0.0,
      "learning_rate": 1.0256959314775161e-05,
      "loss": 1.3688,
      "step": 911
    },
    {
      "epoch": 0.48822269807280516,
      "grad_norm": 0.0,
      "learning_rate": 1.024625267665953e-05,
      "loss": 1.6609,
      "step": 912
    },
    {
      "epoch": 0.48875802997858675,
      "grad_norm": 0.0,
      "learning_rate": 1.0235546038543897e-05,
      "loss": 1.6633,
      "step": 913
    },
    {
      "epoch": 0.4892933618843683,
      "grad_norm": 0.0,
      "learning_rate": 1.0224839400428265e-05,
      "loss": 1.5071,
      "step": 914
    },
    {
      "epoch": 0.48982869379014987,
      "grad_norm": 0.0,
      "learning_rate": 1.0214132762312634e-05,
      "loss": 1.4674,
      "step": 915
    },
    {
      "epoch": 0.49036402569593146,
      "grad_norm": 0.0,
      "learning_rate": 1.0203426124197003e-05,
      "loss": 1.6469,
      "step": 916
    },
    {
      "epoch": 0.49089935760171305,
      "grad_norm": 0.0,
      "learning_rate": 1.019271948608137e-05,
      "loss": 1.6997,
      "step": 917
    },
    {
      "epoch": 0.49143468950749464,
      "grad_norm": 0.0,
      "learning_rate": 1.0182012847965738e-05,
      "loss": 1.541,
      "step": 918
    },
    {
      "epoch": 0.4919700214132762,
      "grad_norm": 0.0,
      "learning_rate": 1.0171306209850107e-05,
      "loss": 1.4857,
      "step": 919
    },
    {
      "epoch": 0.4925053533190578,
      "grad_norm": 0.0,
      "learning_rate": 1.0160599571734476e-05,
      "loss": 1.5329,
      "step": 920
    },
    {
      "epoch": 0.4930406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.0149892933618843e-05,
      "loss": 1.8132,
      "step": 921
    },
    {
      "epoch": 0.493576017130621,
      "grad_norm": 0.0,
      "learning_rate": 1.0139186295503213e-05,
      "loss": 1.3857,
      "step": 922
    },
    {
      "epoch": 0.4941113490364026,
      "grad_norm": 0.0,
      "learning_rate": 1.0128479657387582e-05,
      "loss": 1.4131,
      "step": 923
    },
    {
      "epoch": 0.49464668094218417,
      "grad_norm": 0.0,
      "learning_rate": 1.011777301927195e-05,
      "loss": 1.6714,
      "step": 924
    },
    {
      "epoch": 0.49518201284796576,
      "grad_norm": 0.0,
      "learning_rate": 1.010706638115632e-05,
      "loss": 1.5876,
      "step": 925
    },
    {
      "epoch": 0.49571734475374735,
      "grad_norm": 0.0,
      "learning_rate": 1.0096359743040686e-05,
      "loss": 1.4354,
      "step": 926
    },
    {
      "epoch": 0.49625267665952894,
      "grad_norm": 0.0,
      "learning_rate": 1.0085653104925055e-05,
      "loss": 1.3149,
      "step": 927
    },
    {
      "epoch": 0.49678800856531047,
      "grad_norm": 0.0,
      "learning_rate": 1.0074946466809424e-05,
      "loss": 1.6517,
      "step": 928
    },
    {
      "epoch": 0.49732334047109206,
      "grad_norm": 0.0,
      "learning_rate": 1.0064239828693792e-05,
      "loss": 1.7736,
      "step": 929
    },
    {
      "epoch": 0.49785867237687365,
      "grad_norm": 0.0,
      "learning_rate": 1.0053533190578159e-05,
      "loss": 1.691,
      "step": 930
    },
    {
      "epoch": 0.49839400428265523,
      "grad_norm": 0.0,
      "learning_rate": 1.0042826552462528e-05,
      "loss": 1.7125,
      "step": 931
    },
    {
      "epoch": 0.4989293361884368,
      "grad_norm": 0.0,
      "learning_rate": 1.0032119914346896e-05,
      "loss": 1.6078,
      "step": 932
    },
    {
      "epoch": 0.4994646680942184,
      "grad_norm": 0.0,
      "learning_rate": 1.0021413276231265e-05,
      "loss": 1.5463,
      "step": 933
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.0,
      "learning_rate": 1.0010706638115632e-05,
      "loss": 1.6491,
      "step": 934
    },
    {
      "epoch": 0.5005353319057816,
      "grad_norm": 0.0,
      "learning_rate": 1e-05,
      "loss": 1.5218,
      "step": 935
    },
    {
      "epoch": 0.5010706638115632,
      "grad_norm": 0.0,
      "learning_rate": 9.98929336188437e-06,
      "loss": 1.4847,
      "step": 936
    },
    {
      "epoch": 0.5016059957173448,
      "grad_norm": 0.0,
      "learning_rate": 9.978586723768736e-06,
      "loss": 1.4998,
      "step": 937
    },
    {
      "epoch": 0.5021413276231264,
      "grad_norm": 0.0,
      "learning_rate": 9.967880085653105e-06,
      "loss": 1.6857,
      "step": 938
    },
    {
      "epoch": 0.5026766595289079,
      "grad_norm": 0.0,
      "learning_rate": 9.957173447537474e-06,
      "loss": 1.5733,
      "step": 939
    },
    {
      "epoch": 0.5032119914346895,
      "grad_norm": 0.0,
      "learning_rate": 9.946466809421842e-06,
      "loss": 1.6708,
      "step": 940
    },
    {
      "epoch": 0.5037473233404711,
      "grad_norm": 0.0,
      "learning_rate": 9.93576017130621e-06,
      "loss": 1.8011,
      "step": 941
    },
    {
      "epoch": 0.5042826552462527,
      "grad_norm": 0.0,
      "learning_rate": 9.92505353319058e-06,
      "loss": 1.4262,
      "step": 942
    },
    {
      "epoch": 0.5048179871520343,
      "grad_norm": 0.0,
      "learning_rate": 9.914346895074949e-06,
      "loss": 1.5495,
      "step": 943
    },
    {
      "epoch": 0.5053533190578159,
      "grad_norm": 0.0,
      "learning_rate": 9.903640256959315e-06,
      "loss": 1.7227,
      "step": 944
    },
    {
      "epoch": 0.5058886509635975,
      "grad_norm": 0.0,
      "learning_rate": 9.892933618843684e-06,
      "loss": 1.4665,
      "step": 945
    },
    {
      "epoch": 0.5064239828693791,
      "grad_norm": 0.0,
      "learning_rate": 9.882226980728053e-06,
      "loss": 1.4234,
      "step": 946
    },
    {
      "epoch": 0.5069593147751607,
      "grad_norm": 0.0,
      "learning_rate": 9.871520342612421e-06,
      "loss": 1.7861,
      "step": 947
    },
    {
      "epoch": 0.5074946466809421,
      "grad_norm": 0.0,
      "learning_rate": 9.860813704496788e-06,
      "loss": 1.5338,
      "step": 948
    },
    {
      "epoch": 0.5080299785867237,
      "grad_norm": 0.0,
      "learning_rate": 9.850107066381157e-06,
      "loss": 1.5664,
      "step": 949
    },
    {
      "epoch": 0.5085653104925053,
      "grad_norm": 0.0,
      "learning_rate": 9.839400428265526e-06,
      "loss": 1.6941,
      "step": 950
    },
    {
      "epoch": 0.5091006423982869,
      "grad_norm": 0.0,
      "learning_rate": 9.828693790149893e-06,
      "loss": 1.6582,
      "step": 951
    },
    {
      "epoch": 0.5096359743040685,
      "grad_norm": 0.0,
      "learning_rate": 9.817987152034261e-06,
      "loss": 1.3154,
      "step": 952
    },
    {
      "epoch": 0.5101713062098501,
      "grad_norm": 0.0,
      "learning_rate": 9.80728051391863e-06,
      "loss": 1.7649,
      "step": 953
    },
    {
      "epoch": 0.5107066381156317,
      "grad_norm": 0.0,
      "learning_rate": 9.796573875802999e-06,
      "loss": 1.8972,
      "step": 954
    },
    {
      "epoch": 0.5112419700214133,
      "grad_norm": 0.0,
      "learning_rate": 9.785867237687366e-06,
      "loss": 1.7344,
      "step": 955
    },
    {
      "epoch": 0.5117773019271948,
      "grad_norm": 0.0,
      "learning_rate": 9.775160599571736e-06,
      "loss": 1.3447,
      "step": 956
    },
    {
      "epoch": 0.5123126338329764,
      "grad_norm": 0.0,
      "learning_rate": 9.764453961456105e-06,
      "loss": 1.7061,
      "step": 957
    },
    {
      "epoch": 0.512847965738758,
      "grad_norm": 0.0,
      "learning_rate": 9.753747323340472e-06,
      "loss": 1.5827,
      "step": 958
    },
    {
      "epoch": 0.5133832976445396,
      "grad_norm": 0.0,
      "learning_rate": 9.74304068522484e-06,
      "loss": 1.6146,
      "step": 959
    },
    {
      "epoch": 0.5139186295503212,
      "grad_norm": 0.0,
      "learning_rate": 9.732334047109209e-06,
      "loss": 1.7785,
      "step": 960
    },
    {
      "epoch": 0.5144539614561028,
      "grad_norm": 0.0,
      "learning_rate": 9.721627408993576e-06,
      "loss": 1.3938,
      "step": 961
    },
    {
      "epoch": 0.5149892933618844,
      "grad_norm": 0.0,
      "learning_rate": 9.710920770877945e-06,
      "loss": 1.4184,
      "step": 962
    },
    {
      "epoch": 0.515524625267666,
      "grad_norm": 0.0,
      "learning_rate": 9.700214132762313e-06,
      "loss": 1.6415,
      "step": 963
    },
    {
      "epoch": 0.5160599571734475,
      "grad_norm": 0.0,
      "learning_rate": 9.689507494646682e-06,
      "loss": 1.5521,
      "step": 964
    },
    {
      "epoch": 0.5165952890792291,
      "grad_norm": 0.0,
      "learning_rate": 9.678800856531049e-06,
      "loss": 1.5326,
      "step": 965
    },
    {
      "epoch": 0.5171306209850107,
      "grad_norm": 0.0,
      "learning_rate": 9.668094218415418e-06,
      "loss": 1.4883,
      "step": 966
    },
    {
      "epoch": 0.5176659528907923,
      "grad_norm": 0.0,
      "learning_rate": 9.657387580299786e-06,
      "loss": 1.4464,
      "step": 967
    },
    {
      "epoch": 0.5182012847965739,
      "grad_norm": 0.0,
      "learning_rate": 9.646680942184155e-06,
      "loss": 1.597,
      "step": 968
    },
    {
      "epoch": 0.5187366167023555,
      "grad_norm": 0.0,
      "learning_rate": 9.635974304068522e-06,
      "loss": 1.5495,
      "step": 969
    },
    {
      "epoch": 0.5192719486081371,
      "grad_norm": 0.0,
      "learning_rate": 9.625267665952892e-06,
      "loss": 1.6289,
      "step": 970
    },
    {
      "epoch": 0.5198072805139187,
      "grad_norm": 0.0,
      "learning_rate": 9.614561027837261e-06,
      "loss": 1.7346,
      "step": 971
    },
    {
      "epoch": 0.5203426124197003,
      "grad_norm": 0.0,
      "learning_rate": 9.603854389721628e-06,
      "loss": 1.8141,
      "step": 972
    },
    {
      "epoch": 0.5208779443254818,
      "grad_norm": 0.0,
      "learning_rate": 9.593147751605997e-06,
      "loss": 1.3398,
      "step": 973
    },
    {
      "epoch": 0.5214132762312634,
      "grad_norm": 0.0,
      "learning_rate": 9.582441113490365e-06,
      "loss": 1.6966,
      "step": 974
    },
    {
      "epoch": 0.521948608137045,
      "grad_norm": 0.0,
      "learning_rate": 9.571734475374732e-06,
      "loss": 1.5339,
      "step": 975
    },
    {
      "epoch": 0.5224839400428265,
      "grad_norm": 0.0,
      "learning_rate": 9.561027837259101e-06,
      "loss": 1.4384,
      "step": 976
    },
    {
      "epoch": 0.5230192719486081,
      "grad_norm": 0.0,
      "learning_rate": 9.55032119914347e-06,
      "loss": 1.6505,
      "step": 977
    },
    {
      "epoch": 0.5235546038543897,
      "grad_norm": 0.0,
      "learning_rate": 9.539614561027838e-06,
      "loss": 1.4518,
      "step": 978
    },
    {
      "epoch": 0.5240899357601713,
      "grad_norm": 0.0,
      "learning_rate": 9.528907922912205e-06,
      "loss": 1.5744,
      "step": 979
    },
    {
      "epoch": 0.5246252676659529,
      "grad_norm": 0.0,
      "learning_rate": 9.518201284796574e-06,
      "loss": 1.4906,
      "step": 980
    },
    {
      "epoch": 0.5251605995717344,
      "grad_norm": 0.0,
      "learning_rate": 9.507494646680943e-06,
      "loss": 1.5554,
      "step": 981
    },
    {
      "epoch": 0.525695931477516,
      "grad_norm": 0.0,
      "learning_rate": 9.496788008565311e-06,
      "loss": 1.9383,
      "step": 982
    },
    {
      "epoch": 0.5262312633832976,
      "grad_norm": 0.0,
      "learning_rate": 9.486081370449678e-06,
      "loss": 1.5015,
      "step": 983
    },
    {
      "epoch": 0.5267665952890792,
      "grad_norm": 0.0,
      "learning_rate": 9.475374732334049e-06,
      "loss": 1.3598,
      "step": 984
    },
    {
      "epoch": 0.5273019271948608,
      "grad_norm": 0.0,
      "learning_rate": 9.464668094218416e-06,
      "loss": 1.6407,
      "step": 985
    },
    {
      "epoch": 0.5278372591006424,
      "grad_norm": 0.0,
      "learning_rate": 9.453961456102784e-06,
      "loss": 1.6001,
      "step": 986
    },
    {
      "epoch": 0.528372591006424,
      "grad_norm": 0.0,
      "learning_rate": 9.443254817987153e-06,
      "loss": 1.6839,
      "step": 987
    },
    {
      "epoch": 0.5289079229122056,
      "grad_norm": 0.0,
      "learning_rate": 9.432548179871522e-06,
      "loss": 1.4258,
      "step": 988
    },
    {
      "epoch": 0.5294432548179872,
      "grad_norm": 0.0,
      "learning_rate": 9.421841541755889e-06,
      "loss": 1.679,
      "step": 989
    },
    {
      "epoch": 0.5299785867237687,
      "grad_norm": 0.0,
      "learning_rate": 9.411134903640257e-06,
      "loss": 1.4592,
      "step": 990
    },
    {
      "epoch": 0.5305139186295503,
      "grad_norm": 0.0,
      "learning_rate": 9.400428265524626e-06,
      "loss": 1.7231,
      "step": 991
    },
    {
      "epoch": 0.5310492505353319,
      "grad_norm": 0.0,
      "learning_rate": 9.389721627408995e-06,
      "loss": 1.5499,
      "step": 992
    },
    {
      "epoch": 0.5315845824411135,
      "grad_norm": 0.0,
      "learning_rate": 9.379014989293362e-06,
      "loss": 1.6379,
      "step": 993
    },
    {
      "epoch": 0.5321199143468951,
      "grad_norm": 0.0,
      "learning_rate": 9.36830835117773e-06,
      "loss": 1.618,
      "step": 994
    },
    {
      "epoch": 0.5326552462526767,
      "grad_norm": 0.0,
      "learning_rate": 9.357601713062099e-06,
      "loss": 1.7994,
      "step": 995
    },
    {
      "epoch": 0.5331905781584583,
      "grad_norm": 0.0,
      "learning_rate": 9.346895074946468e-06,
      "loss": 1.7764,
      "step": 996
    },
    {
      "epoch": 0.5337259100642399,
      "grad_norm": 0.0,
      "learning_rate": 9.336188436830836e-06,
      "loss": 1.4213,
      "step": 997
    },
    {
      "epoch": 0.5342612419700214,
      "grad_norm": 0.0,
      "learning_rate": 9.325481798715205e-06,
      "loss": 1.5646,
      "step": 998
    },
    {
      "epoch": 0.534796573875803,
      "grad_norm": 0.0,
      "learning_rate": 9.314775160599572e-06,
      "loss": 1.8132,
      "step": 999
    },
    {
      "epoch": 0.5353319057815846,
      "grad_norm": 0.0,
      "learning_rate": 9.30406852248394e-06,
      "loss": 1.542,
      "step": 1000
    },
    {
      "epoch": 0.5358672376873662,
      "grad_norm": 0.0,
      "learning_rate": 9.29336188436831e-06,
      "loss": 2.0765,
      "step": 1001
    },
    {
      "epoch": 0.5364025695931478,
      "grad_norm": 0.0,
      "learning_rate": 9.282655246252678e-06,
      "loss": 1.7239,
      "step": 1002
    },
    {
      "epoch": 0.5369379014989293,
      "grad_norm": 0.0,
      "learning_rate": 9.271948608137045e-06,
      "loss": 1.7047,
      "step": 1003
    },
    {
      "epoch": 0.5374732334047109,
      "grad_norm": 0.0,
      "learning_rate": 9.261241970021414e-06,
      "loss": 1.5864,
      "step": 1004
    },
    {
      "epoch": 0.5380085653104925,
      "grad_norm": 0.0,
      "learning_rate": 9.250535331905782e-06,
      "loss": 1.8977,
      "step": 1005
    },
    {
      "epoch": 0.538543897216274,
      "grad_norm": 0.0,
      "learning_rate": 9.239828693790151e-06,
      "loss": 1.5456,
      "step": 1006
    },
    {
      "epoch": 0.5390792291220556,
      "grad_norm": 0.0,
      "learning_rate": 9.229122055674518e-06,
      "loss": 1.7739,
      "step": 1007
    },
    {
      "epoch": 0.5396145610278372,
      "grad_norm": 0.0,
      "learning_rate": 9.218415417558887e-06,
      "loss": 1.7427,
      "step": 1008
    },
    {
      "epoch": 0.5401498929336188,
      "grad_norm": 0.0,
      "learning_rate": 9.207708779443255e-06,
      "loss": 1.6236,
      "step": 1009
    },
    {
      "epoch": 0.5406852248394004,
      "grad_norm": 0.0,
      "learning_rate": 9.197002141327624e-06,
      "loss": 1.5372,
      "step": 1010
    },
    {
      "epoch": 0.541220556745182,
      "grad_norm": 0.0,
      "learning_rate": 9.186295503211993e-06,
      "loss": 1.3978,
      "step": 1011
    },
    {
      "epoch": 0.5417558886509636,
      "grad_norm": 0.0,
      "learning_rate": 9.175588865096361e-06,
      "loss": 1.7619,
      "step": 1012
    },
    {
      "epoch": 0.5422912205567452,
      "grad_norm": 0.0,
      "learning_rate": 9.164882226980728e-06,
      "loss": 1.4183,
      "step": 1013
    },
    {
      "epoch": 0.5428265524625268,
      "grad_norm": 0.0,
      "learning_rate": 9.154175588865097e-06,
      "loss": 1.6149,
      "step": 1014
    },
    {
      "epoch": 0.5433618843683083,
      "grad_norm": 0.0,
      "learning_rate": 9.143468950749466e-06,
      "loss": 1.8369,
      "step": 1015
    },
    {
      "epoch": 0.5438972162740899,
      "grad_norm": 0.0,
      "learning_rate": 9.132762312633834e-06,
      "loss": 2.0436,
      "step": 1016
    },
    {
      "epoch": 0.5444325481798715,
      "grad_norm": 0.0,
      "learning_rate": 9.122055674518201e-06,
      "loss": 1.4665,
      "step": 1017
    },
    {
      "epoch": 0.5449678800856531,
      "grad_norm": 0.0,
      "learning_rate": 9.11134903640257e-06,
      "loss": 1.4078,
      "step": 1018
    },
    {
      "epoch": 0.5455032119914347,
      "grad_norm": 0.0,
      "learning_rate": 9.100642398286939e-06,
      "loss": 1.5758,
      "step": 1019
    },
    {
      "epoch": 0.5460385438972163,
      "grad_norm": 0.0,
      "learning_rate": 9.089935760171307e-06,
      "loss": 1.5545,
      "step": 1020
    },
    {
      "epoch": 0.5465738758029979,
      "grad_norm": 0.0,
      "learning_rate": 9.079229122055674e-06,
      "loss": 2.2052,
      "step": 1021
    },
    {
      "epoch": 0.5471092077087795,
      "grad_norm": 0.0,
      "learning_rate": 9.068522483940043e-06,
      "loss": 1.4087,
      "step": 1022
    },
    {
      "epoch": 0.547644539614561,
      "grad_norm": 0.0,
      "learning_rate": 9.057815845824412e-06,
      "loss": 1.7154,
      "step": 1023
    },
    {
      "epoch": 0.5481798715203426,
      "grad_norm": 0.0,
      "learning_rate": 9.04710920770878e-06,
      "loss": 1.9607,
      "step": 1024
    },
    {
      "epoch": 0.5487152034261242,
      "grad_norm": 0.0,
      "learning_rate": 9.036402569593149e-06,
      "loss": 1.4892,
      "step": 1025
    },
    {
      "epoch": 0.5492505353319058,
      "grad_norm": 0.0,
      "learning_rate": 9.025695931477518e-06,
      "loss": 1.6,
      "step": 1026
    },
    {
      "epoch": 0.5497858672376874,
      "grad_norm": 0.0,
      "learning_rate": 9.014989293361885e-06,
      "loss": 1.428,
      "step": 1027
    },
    {
      "epoch": 0.550321199143469,
      "grad_norm": 0.0,
      "learning_rate": 9.004282655246253e-06,
      "loss": 1.7059,
      "step": 1028
    },
    {
      "epoch": 0.5508565310492506,
      "grad_norm": 0.0,
      "learning_rate": 8.993576017130622e-06,
      "loss": 1.642,
      "step": 1029
    },
    {
      "epoch": 0.5513918629550322,
      "grad_norm": 0.0,
      "learning_rate": 8.98286937901499e-06,
      "loss": 1.5119,
      "step": 1030
    },
    {
      "epoch": 0.5519271948608137,
      "grad_norm": 0.0,
      "learning_rate": 8.972162740899358e-06,
      "loss": 1.7653,
      "step": 1031
    },
    {
      "epoch": 0.5524625267665952,
      "grad_norm": 0.0,
      "learning_rate": 8.961456102783726e-06,
      "loss": 1.6568,
      "step": 1032
    },
    {
      "epoch": 0.5529978586723768,
      "grad_norm": 0.0,
      "learning_rate": 8.950749464668095e-06,
      "loss": 1.4331,
      "step": 1033
    },
    {
      "epoch": 0.5535331905781584,
      "grad_norm": 0.0,
      "learning_rate": 8.940042826552464e-06,
      "loss": 1.6258,
      "step": 1034
    },
    {
      "epoch": 0.55406852248394,
      "grad_norm": 0.0,
      "learning_rate": 8.92933618843683e-06,
      "loss": 1.4886,
      "step": 1035
    },
    {
      "epoch": 0.5546038543897216,
      "grad_norm": 0.0,
      "learning_rate": 8.9186295503212e-06,
      "loss": 1.5125,
      "step": 1036
    },
    {
      "epoch": 0.5551391862955032,
      "grad_norm": 0.0,
      "learning_rate": 8.907922912205568e-06,
      "loss": 1.4788,
      "step": 1037
    },
    {
      "epoch": 0.5556745182012848,
      "grad_norm": 0.0,
      "learning_rate": 8.897216274089937e-06,
      "loss": 1.6591,
      "step": 1038
    },
    {
      "epoch": 0.5562098501070664,
      "grad_norm": 0.0,
      "learning_rate": 8.886509635974305e-06,
      "loss": 1.8788,
      "step": 1039
    },
    {
      "epoch": 0.556745182012848,
      "grad_norm": 0.0,
      "learning_rate": 8.875802997858674e-06,
      "loss": 1.6807,
      "step": 1040
    },
    {
      "epoch": 0.5572805139186295,
      "grad_norm": 0.0,
      "learning_rate": 8.865096359743041e-06,
      "loss": 1.562,
      "step": 1041
    },
    {
      "epoch": 0.5578158458244111,
      "grad_norm": 0.0,
      "learning_rate": 8.85438972162741e-06,
      "loss": 1.4317,
      "step": 1042
    },
    {
      "epoch": 0.5583511777301927,
      "grad_norm": 0.0,
      "learning_rate": 8.843683083511778e-06,
      "loss": 1.6157,
      "step": 1043
    },
    {
      "epoch": 0.5588865096359743,
      "grad_norm": 0.0,
      "learning_rate": 8.832976445396147e-06,
      "loss": 1.6123,
      "step": 1044
    },
    {
      "epoch": 0.5594218415417559,
      "grad_norm": 0.0,
      "learning_rate": 8.822269807280514e-06,
      "loss": 1.6277,
      "step": 1045
    },
    {
      "epoch": 0.5599571734475375,
      "grad_norm": 0.0,
      "learning_rate": 8.811563169164883e-06,
      "loss": 1.4136,
      "step": 1046
    },
    {
      "epoch": 0.5604925053533191,
      "grad_norm": 0.0,
      "learning_rate": 8.800856531049251e-06,
      "loss": 1.6818,
      "step": 1047
    },
    {
      "epoch": 0.5610278372591007,
      "grad_norm": 0.0,
      "learning_rate": 8.79014989293362e-06,
      "loss": 1.4944,
      "step": 1048
    },
    {
      "epoch": 0.5615631691648822,
      "grad_norm": 0.0,
      "learning_rate": 8.779443254817987e-06,
      "loss": 1.533,
      "step": 1049
    },
    {
      "epoch": 0.5620985010706638,
      "grad_norm": 0.0,
      "learning_rate": 8.768736616702356e-06,
      "loss": 1.696,
      "step": 1050
    },
    {
      "epoch": 0.5626338329764454,
      "grad_norm": 0.0,
      "learning_rate": 8.758029978586724e-06,
      "loss": 1.4873,
      "step": 1051
    },
    {
      "epoch": 0.563169164882227,
      "grad_norm": 0.0,
      "learning_rate": 8.747323340471093e-06,
      "loss": 1.8972,
      "step": 1052
    },
    {
      "epoch": 0.5637044967880086,
      "grad_norm": 0.0,
      "learning_rate": 8.736616702355462e-06,
      "loss": 1.5439,
      "step": 1053
    },
    {
      "epoch": 0.5642398286937902,
      "grad_norm": 0.0,
      "learning_rate": 8.72591006423983e-06,
      "loss": 1.6108,
      "step": 1054
    },
    {
      "epoch": 0.5647751605995718,
      "grad_norm": 0.0,
      "learning_rate": 8.715203426124197e-06,
      "loss": 1.6383,
      "step": 1055
    },
    {
      "epoch": 0.5653104925053534,
      "grad_norm": 0.0,
      "learning_rate": 8.704496788008566e-06,
      "loss": 1.5645,
      "step": 1056
    },
    {
      "epoch": 0.565845824411135,
      "grad_norm": 0.0,
      "learning_rate": 8.693790149892935e-06,
      "loss": 1.4701,
      "step": 1057
    },
    {
      "epoch": 0.5663811563169164,
      "grad_norm": 0.0,
      "learning_rate": 8.683083511777303e-06,
      "loss": 1.5008,
      "step": 1058
    },
    {
      "epoch": 0.566916488222698,
      "grad_norm": 0.0,
      "learning_rate": 8.67237687366167e-06,
      "loss": 1.4526,
      "step": 1059
    },
    {
      "epoch": 0.5674518201284796,
      "grad_norm": 0.0,
      "learning_rate": 8.661670235546039e-06,
      "loss": 1.4347,
      "step": 1060
    },
    {
      "epoch": 0.5679871520342612,
      "grad_norm": 0.0,
      "learning_rate": 8.650963597430408e-06,
      "loss": 1.4381,
      "step": 1061
    },
    {
      "epoch": 0.5685224839400428,
      "grad_norm": 0.0,
      "learning_rate": 8.640256959314776e-06,
      "loss": 1.5784,
      "step": 1062
    },
    {
      "epoch": 0.5690578158458244,
      "grad_norm": 0.0,
      "learning_rate": 8.629550321199143e-06,
      "loss": 1.6555,
      "step": 1063
    },
    {
      "epoch": 0.569593147751606,
      "grad_norm": 0.0,
      "learning_rate": 8.618843683083512e-06,
      "loss": 1.3669,
      "step": 1064
    },
    {
      "epoch": 0.5701284796573876,
      "grad_norm": 0.0,
      "learning_rate": 8.60813704496788e-06,
      "loss": 1.3951,
      "step": 1065
    },
    {
      "epoch": 0.5706638115631691,
      "grad_norm": 0.0,
      "learning_rate": 8.59743040685225e-06,
      "loss": 1.3721,
      "step": 1066
    },
    {
      "epoch": 0.5711991434689507,
      "grad_norm": 0.0,
      "learning_rate": 8.586723768736618e-06,
      "loss": 1.5291,
      "step": 1067
    },
    {
      "epoch": 0.5717344753747323,
      "grad_norm": 0.0,
      "learning_rate": 8.576017130620987e-06,
      "loss": 1.4911,
      "step": 1068
    },
    {
      "epoch": 0.5722698072805139,
      "grad_norm": 0.0,
      "learning_rate": 8.565310492505354e-06,
      "loss": 1.6945,
      "step": 1069
    },
    {
      "epoch": 0.5728051391862955,
      "grad_norm": 0.0,
      "learning_rate": 8.554603854389722e-06,
      "loss": 1.6458,
      "step": 1070
    },
    {
      "epoch": 0.5733404710920771,
      "grad_norm": 0.0,
      "learning_rate": 8.543897216274091e-06,
      "loss": 1.4674,
      "step": 1071
    },
    {
      "epoch": 0.5738758029978587,
      "grad_norm": 0.0,
      "learning_rate": 8.53319057815846e-06,
      "loss": 1.6927,
      "step": 1072
    },
    {
      "epoch": 0.5744111349036403,
      "grad_norm": 0.0,
      "learning_rate": 8.522483940042827e-06,
      "loss": 1.5174,
      "step": 1073
    },
    {
      "epoch": 0.5749464668094219,
      "grad_norm": 0.0,
      "learning_rate": 8.511777301927195e-06,
      "loss": 1.6792,
      "step": 1074
    },
    {
      "epoch": 0.5754817987152034,
      "grad_norm": 0.0,
      "learning_rate": 8.501070663811564e-06,
      "loss": 1.948,
      "step": 1075
    },
    {
      "epoch": 0.576017130620985,
      "grad_norm": 0.0,
      "learning_rate": 8.490364025695931e-06,
      "loss": 1.427,
      "step": 1076
    },
    {
      "epoch": 0.5765524625267666,
      "grad_norm": 0.0,
      "learning_rate": 8.4796573875803e-06,
      "loss": 1.5658,
      "step": 1077
    },
    {
      "epoch": 0.5770877944325482,
      "grad_norm": 0.0,
      "learning_rate": 8.468950749464668e-06,
      "loss": 1.7389,
      "step": 1078
    },
    {
      "epoch": 0.5776231263383298,
      "grad_norm": 0.0,
      "learning_rate": 8.458244111349037e-06,
      "loss": 1.3821,
      "step": 1079
    },
    {
      "epoch": 0.5781584582441114,
      "grad_norm": 0.0,
      "learning_rate": 8.447537473233406e-06,
      "loss": 1.6328,
      "step": 1080
    },
    {
      "epoch": 0.578693790149893,
      "grad_norm": 0.0,
      "learning_rate": 8.436830835117774e-06,
      "loss": 1.7506,
      "step": 1081
    },
    {
      "epoch": 0.5792291220556746,
      "grad_norm": 0.0,
      "learning_rate": 8.426124197002143e-06,
      "loss": 1.6022,
      "step": 1082
    },
    {
      "epoch": 0.5797644539614561,
      "grad_norm": 0.0,
      "learning_rate": 8.41541755888651e-06,
      "loss": 1.9627,
      "step": 1083
    },
    {
      "epoch": 0.5802997858672377,
      "grad_norm": 0.0,
      "learning_rate": 8.404710920770879e-06,
      "loss": 1.5827,
      "step": 1084
    },
    {
      "epoch": 0.5808351177730193,
      "grad_norm": 0.0,
      "learning_rate": 8.394004282655247e-06,
      "loss": 1.469,
      "step": 1085
    },
    {
      "epoch": 0.5813704496788008,
      "grad_norm": 0.0,
      "learning_rate": 8.383297644539616e-06,
      "loss": 1.3906,
      "step": 1086
    },
    {
      "epoch": 0.5819057815845824,
      "grad_norm": 0.0,
      "learning_rate": 8.372591006423983e-06,
      "loss": 1.3084,
      "step": 1087
    },
    {
      "epoch": 0.582441113490364,
      "grad_norm": 0.0,
      "learning_rate": 8.361884368308352e-06,
      "loss": 1.3878,
      "step": 1088
    },
    {
      "epoch": 0.5829764453961456,
      "grad_norm": 0.0,
      "learning_rate": 8.35117773019272e-06,
      "loss": 1.5569,
      "step": 1089
    },
    {
      "epoch": 0.5835117773019272,
      "grad_norm": 0.0,
      "learning_rate": 8.340471092077087e-06,
      "loss": 1.5094,
      "step": 1090
    },
    {
      "epoch": 0.5840471092077087,
      "grad_norm": 0.0,
      "learning_rate": 8.329764453961456e-06,
      "loss": 1.7762,
      "step": 1091
    },
    {
      "epoch": 0.5845824411134903,
      "grad_norm": 0.0,
      "learning_rate": 8.319057815845825e-06,
      "loss": 1.5203,
      "step": 1092
    },
    {
      "epoch": 0.5851177730192719,
      "grad_norm": 0.0,
      "learning_rate": 8.308351177730193e-06,
      "loss": 1.7615,
      "step": 1093
    },
    {
      "epoch": 0.5856531049250535,
      "grad_norm": 0.0,
      "learning_rate": 8.297644539614562e-06,
      "loss": 1.6203,
      "step": 1094
    },
    {
      "epoch": 0.5861884368308351,
      "grad_norm": 0.0,
      "learning_rate": 8.28693790149893e-06,
      "loss": 1.2811,
      "step": 1095
    },
    {
      "epoch": 0.5867237687366167,
      "grad_norm": 0.0,
      "learning_rate": 8.2762312633833e-06,
      "loss": 1.6743,
      "step": 1096
    },
    {
      "epoch": 0.5872591006423983,
      "grad_norm": 0.0,
      "learning_rate": 8.265524625267666e-06,
      "loss": 1.545,
      "step": 1097
    },
    {
      "epoch": 0.5877944325481799,
      "grad_norm": 0.0,
      "learning_rate": 8.254817987152035e-06,
      "loss": 1.5895,
      "step": 1098
    },
    {
      "epoch": 0.5883297644539615,
      "grad_norm": 0.0,
      "learning_rate": 8.244111349036404e-06,
      "loss": 1.6037,
      "step": 1099
    },
    {
      "epoch": 0.588865096359743,
      "grad_norm": 0.0,
      "learning_rate": 8.23340471092077e-06,
      "loss": 1.5611,
      "step": 1100
    },
    {
      "epoch": 0.5894004282655246,
      "grad_norm": 0.0,
      "learning_rate": 8.22269807280514e-06,
      "loss": 1.5126,
      "step": 1101
    },
    {
      "epoch": 0.5899357601713062,
      "grad_norm": 0.0,
      "learning_rate": 8.211991434689508e-06,
      "loss": 1.6282,
      "step": 1102
    },
    {
      "epoch": 0.5904710920770878,
      "grad_norm": 0.0,
      "learning_rate": 8.201284796573877e-06,
      "loss": 1.5122,
      "step": 1103
    },
    {
      "epoch": 0.5910064239828694,
      "grad_norm": 0.0,
      "learning_rate": 8.190578158458244e-06,
      "loss": 1.512,
      "step": 1104
    },
    {
      "epoch": 0.591541755888651,
      "grad_norm": 0.0,
      "learning_rate": 8.179871520342612e-06,
      "loss": 1.4737,
      "step": 1105
    },
    {
      "epoch": 0.5920770877944326,
      "grad_norm": 0.0,
      "learning_rate": 8.169164882226981e-06,
      "loss": 1.5799,
      "step": 1106
    },
    {
      "epoch": 0.5926124197002142,
      "grad_norm": 0.0,
      "learning_rate": 8.15845824411135e-06,
      "loss": 1.944,
      "step": 1107
    },
    {
      "epoch": 0.5931477516059958,
      "grad_norm": 0.0,
      "learning_rate": 8.147751605995718e-06,
      "loss": 1.5444,
      "step": 1108
    },
    {
      "epoch": 0.5936830835117773,
      "grad_norm": 0.0,
      "learning_rate": 8.137044967880087e-06,
      "loss": 1.6168,
      "step": 1109
    },
    {
      "epoch": 0.5942184154175589,
      "grad_norm": 0.0,
      "learning_rate": 8.126338329764456e-06,
      "loss": 1.5696,
      "step": 1110
    },
    {
      "epoch": 0.5947537473233405,
      "grad_norm": 0.0,
      "learning_rate": 8.115631691648823e-06,
      "loss": 1.6037,
      "step": 1111
    },
    {
      "epoch": 0.5952890792291221,
      "grad_norm": 0.0,
      "learning_rate": 8.104925053533191e-06,
      "loss": 1.6196,
      "step": 1112
    },
    {
      "epoch": 0.5958244111349036,
      "grad_norm": 0.0,
      "learning_rate": 8.09421841541756e-06,
      "loss": 1.4141,
      "step": 1113
    },
    {
      "epoch": 0.5963597430406852,
      "grad_norm": 0.0,
      "learning_rate": 8.083511777301927e-06,
      "loss": 1.6473,
      "step": 1114
    },
    {
      "epoch": 0.5968950749464668,
      "grad_norm": 0.0,
      "learning_rate": 8.072805139186296e-06,
      "loss": 1.5228,
      "step": 1115
    },
    {
      "epoch": 0.5974304068522484,
      "grad_norm": 0.0,
      "learning_rate": 8.062098501070664e-06,
      "loss": 1.6033,
      "step": 1116
    },
    {
      "epoch": 0.5979657387580299,
      "grad_norm": 0.0,
      "learning_rate": 8.051391862955033e-06,
      "loss": 1.5553,
      "step": 1117
    },
    {
      "epoch": 0.5985010706638115,
      "grad_norm": 0.0,
      "learning_rate": 8.0406852248394e-06,
      "loss": 1.5511,
      "step": 1118
    },
    {
      "epoch": 0.5990364025695931,
      "grad_norm": 0.0,
      "learning_rate": 8.029978586723769e-06,
      "loss": 1.522,
      "step": 1119
    },
    {
      "epoch": 0.5995717344753747,
      "grad_norm": 0.0,
      "learning_rate": 8.019271948608137e-06,
      "loss": 1.544,
      "step": 1120
    },
    {
      "epoch": 0.6001070663811563,
      "grad_norm": 0.0,
      "learning_rate": 8.008565310492506e-06,
      "loss": 1.972,
      "step": 1121
    },
    {
      "epoch": 0.6006423982869379,
      "grad_norm": 0.0,
      "learning_rate": 7.997858672376875e-06,
      "loss": 1.8202,
      "step": 1122
    },
    {
      "epoch": 0.6011777301927195,
      "grad_norm": 0.0,
      "learning_rate": 7.987152034261243e-06,
      "loss": 1.4548,
      "step": 1123
    },
    {
      "epoch": 0.6017130620985011,
      "grad_norm": 0.0,
      "learning_rate": 7.97644539614561e-06,
      "loss": 1.7399,
      "step": 1124
    },
    {
      "epoch": 0.6022483940042827,
      "grad_norm": 0.0,
      "learning_rate": 7.965738758029979e-06,
      "loss": 1.5667,
      "step": 1125
    },
    {
      "epoch": 0.6027837259100642,
      "grad_norm": 0.0,
      "learning_rate": 7.955032119914348e-06,
      "loss": 1.7324,
      "step": 1126
    },
    {
      "epoch": 0.6033190578158458,
      "grad_norm": 0.0,
      "learning_rate": 7.944325481798716e-06,
      "loss": 1.9158,
      "step": 1127
    },
    {
      "epoch": 0.6038543897216274,
      "grad_norm": 0.0,
      "learning_rate": 7.933618843683083e-06,
      "loss": 1.6805,
      "step": 1128
    },
    {
      "epoch": 0.604389721627409,
      "grad_norm": 0.0,
      "learning_rate": 7.922912205567452e-06,
      "loss": 1.6929,
      "step": 1129
    },
    {
      "epoch": 0.6049250535331906,
      "grad_norm": 0.0,
      "learning_rate": 7.91220556745182e-06,
      "loss": 1.5867,
      "step": 1130
    },
    {
      "epoch": 0.6054603854389722,
      "grad_norm": 0.0,
      "learning_rate": 7.90149892933619e-06,
      "loss": 1.7996,
      "step": 1131
    },
    {
      "epoch": 0.6059957173447538,
      "grad_norm": 0.0,
      "learning_rate": 7.890792291220556e-06,
      "loss": 1.4743,
      "step": 1132
    },
    {
      "epoch": 0.6065310492505354,
      "grad_norm": 0.0,
      "learning_rate": 7.880085653104925e-06,
      "loss": 1.7278,
      "step": 1133
    },
    {
      "epoch": 0.607066381156317,
      "grad_norm": 0.0,
      "learning_rate": 7.869379014989294e-06,
      "loss": 1.6534,
      "step": 1134
    },
    {
      "epoch": 0.6076017130620985,
      "grad_norm": 0.0,
      "learning_rate": 7.858672376873662e-06,
      "loss": 1.8749,
      "step": 1135
    },
    {
      "epoch": 0.6081370449678801,
      "grad_norm": 0.0,
      "learning_rate": 7.847965738758031e-06,
      "loss": 1.5868,
      "step": 1136
    },
    {
      "epoch": 0.6086723768736617,
      "grad_norm": 0.0,
      "learning_rate": 7.8372591006424e-06,
      "loss": 1.6494,
      "step": 1137
    },
    {
      "epoch": 0.6092077087794433,
      "grad_norm": 0.0,
      "learning_rate": 7.826552462526767e-06,
      "loss": 1.5224,
      "step": 1138
    },
    {
      "epoch": 0.6097430406852249,
      "grad_norm": 0.0,
      "learning_rate": 7.815845824411135e-06,
      "loss": 1.2811,
      "step": 1139
    },
    {
      "epoch": 0.6102783725910065,
      "grad_norm": 0.0,
      "learning_rate": 7.805139186295504e-06,
      "loss": 1.5639,
      "step": 1140
    },
    {
      "epoch": 0.610813704496788,
      "grad_norm": 0.0,
      "learning_rate": 7.794432548179873e-06,
      "loss": 1.6688,
      "step": 1141
    },
    {
      "epoch": 0.6113490364025695,
      "grad_norm": 0.0,
      "learning_rate": 7.78372591006424e-06,
      "loss": 1.8475,
      "step": 1142
    },
    {
      "epoch": 0.6118843683083511,
      "grad_norm": 0.0,
      "learning_rate": 7.773019271948608e-06,
      "loss": 1.4099,
      "step": 1143
    },
    {
      "epoch": 0.6124197002141327,
      "grad_norm": 0.0,
      "learning_rate": 7.762312633832977e-06,
      "loss": 1.5382,
      "step": 1144
    },
    {
      "epoch": 0.6129550321199143,
      "grad_norm": 0.0,
      "learning_rate": 7.751605995717346e-06,
      "loss": 1.5775,
      "step": 1145
    },
    {
      "epoch": 0.6134903640256959,
      "grad_norm": 0.0,
      "learning_rate": 7.740899357601713e-06,
      "loss": 1.6399,
      "step": 1146
    },
    {
      "epoch": 0.6140256959314775,
      "grad_norm": 0.0,
      "learning_rate": 7.730192719486081e-06,
      "loss": 1.7746,
      "step": 1147
    },
    {
      "epoch": 0.6145610278372591,
      "grad_norm": 0.0,
      "learning_rate": 7.71948608137045e-06,
      "loss": 1.6333,
      "step": 1148
    },
    {
      "epoch": 0.6150963597430407,
      "grad_norm": 0.0,
      "learning_rate": 7.708779443254819e-06,
      "loss": 1.7807,
      "step": 1149
    },
    {
      "epoch": 0.6156316916488223,
      "grad_norm": 0.0,
      "learning_rate": 7.698072805139187e-06,
      "loss": 1.6632,
      "step": 1150
    },
    {
      "epoch": 0.6161670235546038,
      "grad_norm": 0.0,
      "learning_rate": 7.687366167023556e-06,
      "loss": 1.5072,
      "step": 1151
    },
    {
      "epoch": 0.6167023554603854,
      "grad_norm": 0.0,
      "learning_rate": 7.676659528907923e-06,
      "loss": 1.4496,
      "step": 1152
    },
    {
      "epoch": 0.617237687366167,
      "grad_norm": 0.0,
      "learning_rate": 7.665952890792292e-06,
      "loss": 1.7868,
      "step": 1153
    },
    {
      "epoch": 0.6177730192719486,
      "grad_norm": 0.0,
      "learning_rate": 7.65524625267666e-06,
      "loss": 1.3486,
      "step": 1154
    },
    {
      "epoch": 0.6183083511777302,
      "grad_norm": 0.0,
      "learning_rate": 7.644539614561029e-06,
      "loss": 1.6824,
      "step": 1155
    },
    {
      "epoch": 0.6188436830835118,
      "grad_norm": 0.0,
      "learning_rate": 7.633832976445396e-06,
      "loss": 1.6713,
      "step": 1156
    },
    {
      "epoch": 0.6193790149892934,
      "grad_norm": 0.0,
      "learning_rate": 7.623126338329765e-06,
      "loss": 1.6026,
      "step": 1157
    },
    {
      "epoch": 0.619914346895075,
      "grad_norm": 0.0,
      "learning_rate": 7.612419700214133e-06,
      "loss": 1.6534,
      "step": 1158
    },
    {
      "epoch": 0.6204496788008566,
      "grad_norm": 0.0,
      "learning_rate": 7.601713062098501e-06,
      "loss": 1.577,
      "step": 1159
    },
    {
      "epoch": 0.6209850107066381,
      "grad_norm": 0.0,
      "learning_rate": 7.59100642398287e-06,
      "loss": 1.5069,
      "step": 1160
    },
    {
      "epoch": 0.6215203426124197,
      "grad_norm": 0.0,
      "learning_rate": 7.580299785867238e-06,
      "loss": 1.514,
      "step": 1161
    },
    {
      "epoch": 0.6220556745182013,
      "grad_norm": 0.0,
      "learning_rate": 7.569593147751607e-06,
      "loss": 1.5746,
      "step": 1162
    },
    {
      "epoch": 0.6225910064239829,
      "grad_norm": 0.0,
      "learning_rate": 7.558886509635975e-06,
      "loss": 1.5544,
      "step": 1163
    },
    {
      "epoch": 0.6231263383297645,
      "grad_norm": 0.0,
      "learning_rate": 7.548179871520344e-06,
      "loss": 1.5172,
      "step": 1164
    },
    {
      "epoch": 0.6236616702355461,
      "grad_norm": 0.0,
      "learning_rate": 7.5374732334047115e-06,
      "loss": 1.7104,
      "step": 1165
    },
    {
      "epoch": 0.6241970021413277,
      "grad_norm": 0.0,
      "learning_rate": 7.52676659528908e-06,
      "loss": 1.4192,
      "step": 1166
    },
    {
      "epoch": 0.6247323340471093,
      "grad_norm": 0.0,
      "learning_rate": 7.516059957173448e-06,
      "loss": 1.7018,
      "step": 1167
    },
    {
      "epoch": 0.6252676659528907,
      "grad_norm": 0.0,
      "learning_rate": 7.505353319057817e-06,
      "loss": 1.5202,
      "step": 1168
    },
    {
      "epoch": 0.6258029978586723,
      "grad_norm": 0.0,
      "learning_rate": 7.4946466809421845e-06,
      "loss": 1.6834,
      "step": 1169
    },
    {
      "epoch": 0.6263383297644539,
      "grad_norm": 0.0,
      "learning_rate": 7.483940042826553e-06,
      "loss": 1.8246,
      "step": 1170
    },
    {
      "epoch": 0.6268736616702355,
      "grad_norm": 0.0,
      "learning_rate": 7.473233404710921e-06,
      "loss": 1.8189,
      "step": 1171
    },
    {
      "epoch": 0.6274089935760171,
      "grad_norm": 0.0,
      "learning_rate": 7.46252676659529e-06,
      "loss": 1.4728,
      "step": 1172
    },
    {
      "epoch": 0.6279443254817987,
      "grad_norm": 0.0,
      "learning_rate": 7.4518201284796575e-06,
      "loss": 1.5043,
      "step": 1173
    },
    {
      "epoch": 0.6284796573875803,
      "grad_norm": 0.0,
      "learning_rate": 7.441113490364026e-06,
      "loss": 1.7812,
      "step": 1174
    },
    {
      "epoch": 0.6290149892933619,
      "grad_norm": 0.0,
      "learning_rate": 7.430406852248394e-06,
      "loss": 1.8327,
      "step": 1175
    },
    {
      "epoch": 0.6295503211991434,
      "grad_norm": 0.0,
      "learning_rate": 7.4197002141327635e-06,
      "loss": 1.5232,
      "step": 1176
    },
    {
      "epoch": 0.630085653104925,
      "grad_norm": 0.0,
      "learning_rate": 7.408993576017131e-06,
      "loss": 1.5915,
      "step": 1177
    },
    {
      "epoch": 0.6306209850107066,
      "grad_norm": 0.0,
      "learning_rate": 7.3982869379015e-06,
      "loss": 1.6312,
      "step": 1178
    },
    {
      "epoch": 0.6311563169164882,
      "grad_norm": 0.0,
      "learning_rate": 7.387580299785868e-06,
      "loss": 1.7008,
      "step": 1179
    },
    {
      "epoch": 0.6316916488222698,
      "grad_norm": 0.0,
      "learning_rate": 7.3768736616702365e-06,
      "loss": 1.4051,
      "step": 1180
    },
    {
      "epoch": 0.6322269807280514,
      "grad_norm": 0.0,
      "learning_rate": 7.366167023554604e-06,
      "loss": 1.4656,
      "step": 1181
    },
    {
      "epoch": 0.632762312633833,
      "grad_norm": 0.0,
      "learning_rate": 7.355460385438973e-06,
      "loss": 1.5608,
      "step": 1182
    },
    {
      "epoch": 0.6332976445396146,
      "grad_norm": 0.0,
      "learning_rate": 7.344753747323341e-06,
      "loss": 1.6204,
      "step": 1183
    },
    {
      "epoch": 0.6338329764453962,
      "grad_norm": 0.0,
      "learning_rate": 7.3340471092077095e-06,
      "loss": 1.5835,
      "step": 1184
    },
    {
      "epoch": 0.6343683083511777,
      "grad_norm": 0.0,
      "learning_rate": 7.323340471092077e-06,
      "loss": 1.5416,
      "step": 1185
    },
    {
      "epoch": 0.6349036402569593,
      "grad_norm": 0.0,
      "learning_rate": 7.312633832976446e-06,
      "loss": 1.6059,
      "step": 1186
    },
    {
      "epoch": 0.6354389721627409,
      "grad_norm": 0.0,
      "learning_rate": 7.301927194860814e-06,
      "loss": 1.4569,
      "step": 1187
    },
    {
      "epoch": 0.6359743040685225,
      "grad_norm": 0.0,
      "learning_rate": 7.2912205567451825e-06,
      "loss": 1.6077,
      "step": 1188
    },
    {
      "epoch": 0.6365096359743041,
      "grad_norm": 0.0,
      "learning_rate": 7.28051391862955e-06,
      "loss": 1.7132,
      "step": 1189
    },
    {
      "epoch": 0.6370449678800857,
      "grad_norm": 0.0,
      "learning_rate": 7.26980728051392e-06,
      "loss": 1.5996,
      "step": 1190
    },
    {
      "epoch": 0.6375802997858673,
      "grad_norm": 0.0,
      "learning_rate": 7.259100642398288e-06,
      "loss": 1.4249,
      "step": 1191
    },
    {
      "epoch": 0.6381156316916489,
      "grad_norm": 0.0,
      "learning_rate": 7.248394004282656e-06,
      "loss": 1.6132,
      "step": 1192
    },
    {
      "epoch": 0.6386509635974305,
      "grad_norm": 0.0,
      "learning_rate": 7.237687366167024e-06,
      "loss": 1.7164,
      "step": 1193
    },
    {
      "epoch": 0.639186295503212,
      "grad_norm": 0.0,
      "learning_rate": 7.226980728051393e-06,
      "loss": 1.8151,
      "step": 1194
    },
    {
      "epoch": 0.6397216274089935,
      "grad_norm": 0.0,
      "learning_rate": 7.216274089935761e-06,
      "loss": 1.5855,
      "step": 1195
    },
    {
      "epoch": 0.6402569593147751,
      "grad_norm": 0.0,
      "learning_rate": 7.205567451820129e-06,
      "loss": 1.4652,
      "step": 1196
    },
    {
      "epoch": 0.6407922912205567,
      "grad_norm": 0.0,
      "learning_rate": 7.194860813704497e-06,
      "loss": 1.842,
      "step": 1197
    },
    {
      "epoch": 0.6413276231263383,
      "grad_norm": 0.0,
      "learning_rate": 7.184154175588866e-06,
      "loss": 1.5638,
      "step": 1198
    },
    {
      "epoch": 0.6418629550321199,
      "grad_norm": 0.0,
      "learning_rate": 7.173447537473234e-06,
      "loss": 1.5801,
      "step": 1199
    },
    {
      "epoch": 0.6423982869379015,
      "grad_norm": 0.0,
      "learning_rate": 7.162740899357602e-06,
      "loss": 1.8322,
      "step": 1200
    },
    {
      "epoch": 0.642933618843683,
      "grad_norm": 0.0,
      "learning_rate": 7.15203426124197e-06,
      "loss": 1.5415,
      "step": 1201
    },
    {
      "epoch": 0.6434689507494646,
      "grad_norm": 0.0,
      "learning_rate": 7.141327623126339e-06,
      "loss": 1.5149,
      "step": 1202
    },
    {
      "epoch": 0.6440042826552462,
      "grad_norm": 0.0,
      "learning_rate": 7.1306209850107075e-06,
      "loss": 1.5714,
      "step": 1203
    },
    {
      "epoch": 0.6445396145610278,
      "grad_norm": 0.0,
      "learning_rate": 7.119914346895076e-06,
      "loss": 1.5436,
      "step": 1204
    },
    {
      "epoch": 0.6450749464668094,
      "grad_norm": 0.0,
      "learning_rate": 7.109207708779444e-06,
      "loss": 1.665,
      "step": 1205
    },
    {
      "epoch": 0.645610278372591,
      "grad_norm": 0.0,
      "learning_rate": 7.098501070663813e-06,
      "loss": 1.6379,
      "step": 1206
    },
    {
      "epoch": 0.6461456102783726,
      "grad_norm": 0.0,
      "learning_rate": 7.0877944325481805e-06,
      "loss": 1.6612,
      "step": 1207
    },
    {
      "epoch": 0.6466809421841542,
      "grad_norm": 0.0,
      "learning_rate": 7.077087794432549e-06,
      "loss": 1.7775,
      "step": 1208
    },
    {
      "epoch": 0.6472162740899358,
      "grad_norm": 0.0,
      "learning_rate": 7.066381156316917e-06,
      "loss": 1.425,
      "step": 1209
    },
    {
      "epoch": 0.6477516059957173,
      "grad_norm": 0.0,
      "learning_rate": 7.055674518201286e-06,
      "loss": 1.5397,
      "step": 1210
    },
    {
      "epoch": 0.6482869379014989,
      "grad_norm": 0.0,
      "learning_rate": 7.0449678800856535e-06,
      "loss": 1.7458,
      "step": 1211
    },
    {
      "epoch": 0.6488222698072805,
      "grad_norm": 0.0,
      "learning_rate": 7.034261241970022e-06,
      "loss": 1.4677,
      "step": 1212
    },
    {
      "epoch": 0.6493576017130621,
      "grad_norm": 0.0,
      "learning_rate": 7.02355460385439e-06,
      "loss": 1.8171,
      "step": 1213
    },
    {
      "epoch": 0.6498929336188437,
      "grad_norm": 0.0,
      "learning_rate": 7.012847965738759e-06,
      "loss": 1.5683,
      "step": 1214
    },
    {
      "epoch": 0.6504282655246253,
      "grad_norm": 0.0,
      "learning_rate": 7.0021413276231265e-06,
      "loss": 1.5137,
      "step": 1215
    },
    {
      "epoch": 0.6509635974304069,
      "grad_norm": 0.0,
      "learning_rate": 6.991434689507494e-06,
      "loss": 1.5424,
      "step": 1216
    },
    {
      "epoch": 0.6514989293361885,
      "grad_norm": 0.0,
      "learning_rate": 6.980728051391864e-06,
      "loss": 1.5876,
      "step": 1217
    },
    {
      "epoch": 0.6520342612419701,
      "grad_norm": 0.0,
      "learning_rate": 6.9700214132762325e-06,
      "loss": 1.3907,
      "step": 1218
    },
    {
      "epoch": 0.6525695931477516,
      "grad_norm": 0.0,
      "learning_rate": 6.9593147751606e-06,
      "loss": 1.4034,
      "step": 1219
    },
    {
      "epoch": 0.6531049250535332,
      "grad_norm": 0.0,
      "learning_rate": 6.948608137044969e-06,
      "loss": 1.519,
      "step": 1220
    },
    {
      "epoch": 0.6536402569593148,
      "grad_norm": 0.0,
      "learning_rate": 6.937901498929337e-06,
      "loss": 1.5403,
      "step": 1221
    },
    {
      "epoch": 0.6541755888650964,
      "grad_norm": 0.0,
      "learning_rate": 6.9271948608137055e-06,
      "loss": 1.5307,
      "step": 1222
    },
    {
      "epoch": 0.6547109207708779,
      "grad_norm": 0.0,
      "learning_rate": 6.916488222698073e-06,
      "loss": 1.7919,
      "step": 1223
    },
    {
      "epoch": 0.6552462526766595,
      "grad_norm": 0.0,
      "learning_rate": 6.905781584582442e-06,
      "loss": 1.5606,
      "step": 1224
    },
    {
      "epoch": 0.6557815845824411,
      "grad_norm": 0.0,
      "learning_rate": 6.89507494646681e-06,
      "loss": 1.6288,
      "step": 1225
    },
    {
      "epoch": 0.6563169164882227,
      "grad_norm": 0.0,
      "learning_rate": 6.8843683083511785e-06,
      "loss": 1.5444,
      "step": 1226
    },
    {
      "epoch": 0.6568522483940042,
      "grad_norm": 0.0,
      "learning_rate": 6.873661670235546e-06,
      "loss": 1.4329,
      "step": 1227
    },
    {
      "epoch": 0.6573875802997858,
      "grad_norm": 0.0,
      "learning_rate": 6.862955032119914e-06,
      "loss": 1.413,
      "step": 1228
    },
    {
      "epoch": 0.6579229122055674,
      "grad_norm": 0.0,
      "learning_rate": 6.852248394004283e-06,
      "loss": 1.4507,
      "step": 1229
    },
    {
      "epoch": 0.658458244111349,
      "grad_norm": 0.0,
      "learning_rate": 6.841541755888651e-06,
      "loss": 1.6391,
      "step": 1230
    },
    {
      "epoch": 0.6589935760171306,
      "grad_norm": 0.0,
      "learning_rate": 6.83083511777302e-06,
      "loss": 1.3781,
      "step": 1231
    },
    {
      "epoch": 0.6595289079229122,
      "grad_norm": 0.0,
      "learning_rate": 6.820128479657389e-06,
      "loss": 1.4945,
      "step": 1232
    },
    {
      "epoch": 0.6600642398286938,
      "grad_norm": 0.0,
      "learning_rate": 6.809421841541757e-06,
      "loss": 1.7455,
      "step": 1233
    },
    {
      "epoch": 0.6605995717344754,
      "grad_norm": 0.0,
      "learning_rate": 6.798715203426125e-06,
      "loss": 1.8004,
      "step": 1234
    },
    {
      "epoch": 0.661134903640257,
      "grad_norm": 0.0,
      "learning_rate": 6.788008565310493e-06,
      "loss": 1.7252,
      "step": 1235
    },
    {
      "epoch": 0.6616702355460385,
      "grad_norm": 0.0,
      "learning_rate": 6.777301927194862e-06,
      "loss": 1.731,
      "step": 1236
    },
    {
      "epoch": 0.6622055674518201,
      "grad_norm": 0.0,
      "learning_rate": 6.76659528907923e-06,
      "loss": 1.9447,
      "step": 1237
    },
    {
      "epoch": 0.6627408993576017,
      "grad_norm": 0.0,
      "learning_rate": 6.755888650963598e-06,
      "loss": 1.5344,
      "step": 1238
    },
    {
      "epoch": 0.6632762312633833,
      "grad_norm": 0.0,
      "learning_rate": 6.745182012847966e-06,
      "loss": 1.5798,
      "step": 1239
    },
    {
      "epoch": 0.6638115631691649,
      "grad_norm": 0.0,
      "learning_rate": 6.734475374732334e-06,
      "loss": 1.613,
      "step": 1240
    },
    {
      "epoch": 0.6643468950749465,
      "grad_norm": 0.0,
      "learning_rate": 6.723768736616703e-06,
      "loss": 1.7086,
      "step": 1241
    },
    {
      "epoch": 0.6648822269807281,
      "grad_norm": 0.0,
      "learning_rate": 6.7130620985010705e-06,
      "loss": 1.4386,
      "step": 1242
    },
    {
      "epoch": 0.6654175588865097,
      "grad_norm": 0.0,
      "learning_rate": 6.702355460385439e-06,
      "loss": 1.6573,
      "step": 1243
    },
    {
      "epoch": 0.6659528907922913,
      "grad_norm": 0.0,
      "learning_rate": 6.691648822269807e-06,
      "loss": 1.8877,
      "step": 1244
    },
    {
      "epoch": 0.6664882226980728,
      "grad_norm": 0.0,
      "learning_rate": 6.6809421841541765e-06,
      "loss": 1.9188,
      "step": 1245
    },
    {
      "epoch": 0.6670235546038544,
      "grad_norm": 0.0,
      "learning_rate": 6.670235546038545e-06,
      "loss": 1.6569,
      "step": 1246
    },
    {
      "epoch": 0.667558886509636,
      "grad_norm": 0.0,
      "learning_rate": 6.659528907922913e-06,
      "loss": 1.7672,
      "step": 1247
    },
    {
      "epoch": 0.6680942184154176,
      "grad_norm": 0.0,
      "learning_rate": 6.648822269807282e-06,
      "loss": 1.5018,
      "step": 1248
    },
    {
      "epoch": 0.6686295503211992,
      "grad_norm": 0.0,
      "learning_rate": 6.6381156316916495e-06,
      "loss": 1.5781,
      "step": 1249
    },
    {
      "epoch": 0.6691648822269807,
      "grad_norm": 0.0,
      "learning_rate": 6.627408993576018e-06,
      "loss": 1.5622,
      "step": 1250
    },
    {
      "epoch": 0.6697002141327623,
      "grad_norm": 0.0,
      "learning_rate": 6.616702355460386e-06,
      "loss": 1.8936,
      "step": 1251
    },
    {
      "epoch": 0.6702355460385439,
      "grad_norm": 0.0,
      "learning_rate": 6.605995717344754e-06,
      "loss": 1.5019,
      "step": 1252
    },
    {
      "epoch": 0.6707708779443254,
      "grad_norm": 0.0,
      "learning_rate": 6.5952890792291225e-06,
      "loss": 2.2618,
      "step": 1253
    },
    {
      "epoch": 0.671306209850107,
      "grad_norm": 0.0,
      "learning_rate": 6.58458244111349e-06,
      "loss": 1.2795,
      "step": 1254
    },
    {
      "epoch": 0.6718415417558886,
      "grad_norm": 0.0,
      "learning_rate": 6.573875802997859e-06,
      "loss": 1.4981,
      "step": 1255
    },
    {
      "epoch": 0.6723768736616702,
      "grad_norm": 0.0,
      "learning_rate": 6.563169164882227e-06,
      "loss": 1.6394,
      "step": 1256
    },
    {
      "epoch": 0.6729122055674518,
      "grad_norm": 0.0,
      "learning_rate": 6.5524625267665955e-06,
      "loss": 1.2696,
      "step": 1257
    },
    {
      "epoch": 0.6734475374732334,
      "grad_norm": 0.0,
      "learning_rate": 6.541755888650965e-06,
      "loss": 1.4127,
      "step": 1258
    },
    {
      "epoch": 0.673982869379015,
      "grad_norm": 0.0,
      "learning_rate": 6.531049250535333e-06,
      "loss": 1.4057,
      "step": 1259
    },
    {
      "epoch": 0.6745182012847966,
      "grad_norm": 0.0,
      "learning_rate": 6.5203426124197015e-06,
      "loss": 1.6625,
      "step": 1260
    },
    {
      "epoch": 0.6750535331905781,
      "grad_norm": 0.0,
      "learning_rate": 6.509635974304069e-06,
      "loss": 1.4381,
      "step": 1261
    },
    {
      "epoch": 0.6755888650963597,
      "grad_norm": 0.0,
      "learning_rate": 6.498929336188438e-06,
      "loss": 1.327,
      "step": 1262
    },
    {
      "epoch": 0.6761241970021413,
      "grad_norm": 0.0,
      "learning_rate": 6.488222698072806e-06,
      "loss": 1.7191,
      "step": 1263
    },
    {
      "epoch": 0.6766595289079229,
      "grad_norm": 0.0,
      "learning_rate": 6.477516059957174e-06,
      "loss": 1.6897,
      "step": 1264
    },
    {
      "epoch": 0.6771948608137045,
      "grad_norm": 0.0,
      "learning_rate": 6.466809421841542e-06,
      "loss": 1.4543,
      "step": 1265
    },
    {
      "epoch": 0.6777301927194861,
      "grad_norm": 0.0,
      "learning_rate": 6.45610278372591e-06,
      "loss": 1.3968,
      "step": 1266
    },
    {
      "epoch": 0.6782655246252677,
      "grad_norm": 0.0,
      "learning_rate": 6.445396145610279e-06,
      "loss": 1.6226,
      "step": 1267
    },
    {
      "epoch": 0.6788008565310493,
      "grad_norm": 0.0,
      "learning_rate": 6.434689507494647e-06,
      "loss": 1.4893,
      "step": 1268
    },
    {
      "epoch": 0.6793361884368309,
      "grad_norm": 0.0,
      "learning_rate": 6.423982869379015e-06,
      "loss": 1.523,
      "step": 1269
    },
    {
      "epoch": 0.6798715203426124,
      "grad_norm": 0.0,
      "learning_rate": 6.413276231263383e-06,
      "loss": 1.5815,
      "step": 1270
    },
    {
      "epoch": 0.680406852248394,
      "grad_norm": 0.0,
      "learning_rate": 6.402569593147752e-06,
      "loss": 1.4358,
      "step": 1271
    },
    {
      "epoch": 0.6809421841541756,
      "grad_norm": 0.0,
      "learning_rate": 6.391862955032121e-06,
      "loss": 1.569,
      "step": 1272
    },
    {
      "epoch": 0.6814775160599572,
      "grad_norm": 0.0,
      "learning_rate": 6.381156316916489e-06,
      "loss": 1.341,
      "step": 1273
    },
    {
      "epoch": 0.6820128479657388,
      "grad_norm": 0.0,
      "learning_rate": 6.370449678800858e-06,
      "loss": 1.6767,
      "step": 1274
    },
    {
      "epoch": 0.6825481798715204,
      "grad_norm": 0.0,
      "learning_rate": 6.359743040685226e-06,
      "loss": 1.4429,
      "step": 1275
    },
    {
      "epoch": 0.683083511777302,
      "grad_norm": 0.0,
      "learning_rate": 6.3490364025695935e-06,
      "loss": 1.5079,
      "step": 1276
    },
    {
      "epoch": 0.6836188436830836,
      "grad_norm": 0.0,
      "learning_rate": 6.338329764453962e-06,
      "loss": 1.8366,
      "step": 1277
    },
    {
      "epoch": 0.684154175588865,
      "grad_norm": 0.0,
      "learning_rate": 6.32762312633833e-06,
      "loss": 1.5944,
      "step": 1278
    },
    {
      "epoch": 0.6846895074946466,
      "grad_norm": 0.0,
      "learning_rate": 6.316916488222699e-06,
      "loss": 1.5738,
      "step": 1279
    },
    {
      "epoch": 0.6852248394004282,
      "grad_norm": 0.0,
      "learning_rate": 6.3062098501070665e-06,
      "loss": 1.5884,
      "step": 1280
    },
    {
      "epoch": 0.6857601713062098,
      "grad_norm": 0.0,
      "learning_rate": 6.295503211991435e-06,
      "loss": 1.5879,
      "step": 1281
    },
    {
      "epoch": 0.6862955032119914,
      "grad_norm": 0.0,
      "learning_rate": 6.284796573875803e-06,
      "loss": 1.5551,
      "step": 1282
    },
    {
      "epoch": 0.686830835117773,
      "grad_norm": 0.0,
      "learning_rate": 6.274089935760172e-06,
      "loss": 1.4008,
      "step": 1283
    },
    {
      "epoch": 0.6873661670235546,
      "grad_norm": 0.0,
      "learning_rate": 6.2633832976445395e-06,
      "loss": 1.3302,
      "step": 1284
    },
    {
      "epoch": 0.6879014989293362,
      "grad_norm": 0.0,
      "learning_rate": 6.252676659528908e-06,
      "loss": 1.877,
      "step": 1285
    },
    {
      "epoch": 0.6884368308351178,
      "grad_norm": 0.0,
      "learning_rate": 6.241970021413278e-06,
      "loss": 1.4675,
      "step": 1286
    },
    {
      "epoch": 0.6889721627408993,
      "grad_norm": 0.0,
      "learning_rate": 6.2312633832976455e-06,
      "loss": 1.6003,
      "step": 1287
    },
    {
      "epoch": 0.6895074946466809,
      "grad_norm": 0.0,
      "learning_rate": 6.220556745182013e-06,
      "loss": 1.5215,
      "step": 1288
    },
    {
      "epoch": 0.6900428265524625,
      "grad_norm": 0.0,
      "learning_rate": 6.209850107066382e-06,
      "loss": 1.6533,
      "step": 1289
    },
    {
      "epoch": 0.6905781584582441,
      "grad_norm": 0.0,
      "learning_rate": 6.19914346895075e-06,
      "loss": 1.4464,
      "step": 1290
    },
    {
      "epoch": 0.6911134903640257,
      "grad_norm": 0.0,
      "learning_rate": 6.1884368308351185e-06,
      "loss": 1.6322,
      "step": 1291
    },
    {
      "epoch": 0.6916488222698073,
      "grad_norm": 0.0,
      "learning_rate": 6.177730192719486e-06,
      "loss": 1.4745,
      "step": 1292
    },
    {
      "epoch": 0.6921841541755889,
      "grad_norm": 0.0,
      "learning_rate": 6.167023554603855e-06,
      "loss": 1.5083,
      "step": 1293
    },
    {
      "epoch": 0.6927194860813705,
      "grad_norm": 0.0,
      "learning_rate": 6.156316916488223e-06,
      "loss": 1.5439,
      "step": 1294
    },
    {
      "epoch": 0.693254817987152,
      "grad_norm": 0.0,
      "learning_rate": 6.1456102783725915e-06,
      "loss": 1.7328,
      "step": 1295
    },
    {
      "epoch": 0.6937901498929336,
      "grad_norm": 0.0,
      "learning_rate": 6.134903640256959e-06,
      "loss": 1.8547,
      "step": 1296
    },
    {
      "epoch": 0.6943254817987152,
      "grad_norm": 0.0,
      "learning_rate": 6.124197002141328e-06,
      "loss": 1.5382,
      "step": 1297
    },
    {
      "epoch": 0.6948608137044968,
      "grad_norm": 0.0,
      "learning_rate": 6.113490364025696e-06,
      "loss": 1.8632,
      "step": 1298
    },
    {
      "epoch": 0.6953961456102784,
      "grad_norm": 0.0,
      "learning_rate": 6.102783725910065e-06,
      "loss": 1.5139,
      "step": 1299
    },
    {
      "epoch": 0.69593147751606,
      "grad_norm": 0.0,
      "learning_rate": 6.092077087794433e-06,
      "loss": 1.5916,
      "step": 1300
    },
    {
      "epoch": 0.6964668094218416,
      "grad_norm": 0.0,
      "learning_rate": 6.081370449678802e-06,
      "loss": 1.5749,
      "step": 1301
    },
    {
      "epoch": 0.6970021413276232,
      "grad_norm": 0.0,
      "learning_rate": 6.07066381156317e-06,
      "loss": 1.552,
      "step": 1302
    },
    {
      "epoch": 0.6975374732334048,
      "grad_norm": 0.0,
      "learning_rate": 6.059957173447538e-06,
      "loss": 1.5062,
      "step": 1303
    },
    {
      "epoch": 0.6980728051391863,
      "grad_norm": 0.0,
      "learning_rate": 6.049250535331906e-06,
      "loss": 1.7575,
      "step": 1304
    },
    {
      "epoch": 0.6986081370449678,
      "grad_norm": 0.0,
      "learning_rate": 6.038543897216275e-06,
      "loss": 1.5751,
      "step": 1305
    },
    {
      "epoch": 0.6991434689507494,
      "grad_norm": 0.0,
      "learning_rate": 6.027837259100643e-06,
      "loss": 1.4905,
      "step": 1306
    },
    {
      "epoch": 0.699678800856531,
      "grad_norm": 0.0,
      "learning_rate": 6.017130620985011e-06,
      "loss": 1.6561,
      "step": 1307
    },
    {
      "epoch": 0.7002141327623126,
      "grad_norm": 0.0,
      "learning_rate": 6.006423982869379e-06,
      "loss": 1.4798,
      "step": 1308
    },
    {
      "epoch": 0.7007494646680942,
      "grad_norm": 0.0,
      "learning_rate": 5.995717344753748e-06,
      "loss": 1.6022,
      "step": 1309
    },
    {
      "epoch": 0.7012847965738758,
      "grad_norm": 0.0,
      "learning_rate": 5.985010706638116e-06,
      "loss": 1.4262,
      "step": 1310
    },
    {
      "epoch": 0.7018201284796574,
      "grad_norm": 0.0,
      "learning_rate": 5.974304068522484e-06,
      "loss": 1.5894,
      "step": 1311
    },
    {
      "epoch": 0.702355460385439,
      "grad_norm": 0.0,
      "learning_rate": 5.963597430406852e-06,
      "loss": 1.566,
      "step": 1312
    },
    {
      "epoch": 0.7028907922912205,
      "grad_norm": 0.0,
      "learning_rate": 5.952890792291222e-06,
      "loss": 1.5652,
      "step": 1313
    },
    {
      "epoch": 0.7034261241970021,
      "grad_norm": 0.0,
      "learning_rate": 5.9421841541755895e-06,
      "loss": 1.5068,
      "step": 1314
    },
    {
      "epoch": 0.7039614561027837,
      "grad_norm": 0.0,
      "learning_rate": 5.931477516059958e-06,
      "loss": 1.6266,
      "step": 1315
    },
    {
      "epoch": 0.7044967880085653,
      "grad_norm": 0.0,
      "learning_rate": 5.920770877944326e-06,
      "loss": 1.4906,
      "step": 1316
    },
    {
      "epoch": 0.7050321199143469,
      "grad_norm": 0.0,
      "learning_rate": 5.910064239828695e-06,
      "loss": 1.657,
      "step": 1317
    },
    {
      "epoch": 0.7055674518201285,
      "grad_norm": 0.0,
      "learning_rate": 5.8993576017130625e-06,
      "loss": 1.5433,
      "step": 1318
    },
    {
      "epoch": 0.7061027837259101,
      "grad_norm": 0.0,
      "learning_rate": 5.888650963597431e-06,
      "loss": 1.8118,
      "step": 1319
    },
    {
      "epoch": 0.7066381156316917,
      "grad_norm": 0.0,
      "learning_rate": 5.877944325481799e-06,
      "loss": 1.8221,
      "step": 1320
    },
    {
      "epoch": 0.7071734475374732,
      "grad_norm": 0.0,
      "learning_rate": 5.867237687366168e-06,
      "loss": 1.6629,
      "step": 1321
    },
    {
      "epoch": 0.7077087794432548,
      "grad_norm": 0.0,
      "learning_rate": 5.8565310492505354e-06,
      "loss": 1.5735,
      "step": 1322
    },
    {
      "epoch": 0.7082441113490364,
      "grad_norm": 0.0,
      "learning_rate": 5.845824411134904e-06,
      "loss": 1.493,
      "step": 1323
    },
    {
      "epoch": 0.708779443254818,
      "grad_norm": 0.0,
      "learning_rate": 5.835117773019272e-06,
      "loss": 1.9054,
      "step": 1324
    },
    {
      "epoch": 0.7093147751605996,
      "grad_norm": 0.0,
      "learning_rate": 5.824411134903641e-06,
      "loss": 1.5618,
      "step": 1325
    },
    {
      "epoch": 0.7098501070663812,
      "grad_norm": 0.0,
      "learning_rate": 5.8137044967880084e-06,
      "loss": 1.4862,
      "step": 1326
    },
    {
      "epoch": 0.7103854389721628,
      "grad_norm": 0.0,
      "learning_rate": 5.802997858672378e-06,
      "loss": 1.6732,
      "step": 1327
    },
    {
      "epoch": 0.7109207708779444,
      "grad_norm": 0.0,
      "learning_rate": 5.792291220556746e-06,
      "loss": 1.576,
      "step": 1328
    },
    {
      "epoch": 0.711456102783726,
      "grad_norm": 0.0,
      "learning_rate": 5.7815845824411145e-06,
      "loss": 1.7592,
      "step": 1329
    },
    {
      "epoch": 0.7119914346895075,
      "grad_norm": 0.0,
      "learning_rate": 5.770877944325482e-06,
      "loss": 1.4864,
      "step": 1330
    },
    {
      "epoch": 0.7125267665952891,
      "grad_norm": 0.0,
      "learning_rate": 5.760171306209851e-06,
      "loss": 1.403,
      "step": 1331
    },
    {
      "epoch": 0.7130620985010707,
      "grad_norm": 0.0,
      "learning_rate": 5.749464668094219e-06,
      "loss": 1.4198,
      "step": 1332
    },
    {
      "epoch": 0.7135974304068522,
      "grad_norm": 0.0,
      "learning_rate": 5.7387580299785874e-06,
      "loss": 1.4436,
      "step": 1333
    },
    {
      "epoch": 0.7141327623126338,
      "grad_norm": 0.0,
      "learning_rate": 5.728051391862955e-06,
      "loss": 1.53,
      "step": 1334
    },
    {
      "epoch": 0.7146680942184154,
      "grad_norm": 0.0,
      "learning_rate": 5.717344753747324e-06,
      "loss": 1.5567,
      "step": 1335
    },
    {
      "epoch": 0.715203426124197,
      "grad_norm": 0.0,
      "learning_rate": 5.706638115631692e-06,
      "loss": 1.8102,
      "step": 1336
    },
    {
      "epoch": 0.7157387580299786,
      "grad_norm": 0.0,
      "learning_rate": 5.6959314775160604e-06,
      "loss": 1.5072,
      "step": 1337
    },
    {
      "epoch": 0.7162740899357601,
      "grad_norm": 0.0,
      "learning_rate": 5.685224839400428e-06,
      "loss": 1.6399,
      "step": 1338
    },
    {
      "epoch": 0.7168094218415417,
      "grad_norm": 0.0,
      "learning_rate": 5.674518201284797e-06,
      "loss": 1.641,
      "step": 1339
    },
    {
      "epoch": 0.7173447537473233,
      "grad_norm": 0.0,
      "learning_rate": 5.663811563169165e-06,
      "loss": 1.635,
      "step": 1340
    },
    {
      "epoch": 0.7178800856531049,
      "grad_norm": 0.0,
      "learning_rate": 5.653104925053534e-06,
      "loss": 1.6439,
      "step": 1341
    },
    {
      "epoch": 0.7184154175588865,
      "grad_norm": 0.0,
      "learning_rate": 5.642398286937902e-06,
      "loss": 1.6882,
      "step": 1342
    },
    {
      "epoch": 0.7189507494646681,
      "grad_norm": 0.0,
      "learning_rate": 5.631691648822271e-06,
      "loss": 1.3428,
      "step": 1343
    },
    {
      "epoch": 0.7194860813704497,
      "grad_norm": 0.0,
      "learning_rate": 5.620985010706639e-06,
      "loss": 1.5744,
      "step": 1344
    },
    {
      "epoch": 0.7200214132762313,
      "grad_norm": 0.0,
      "learning_rate": 5.610278372591007e-06,
      "loss": 1.6107,
      "step": 1345
    },
    {
      "epoch": 0.7205567451820128,
      "grad_norm": 0.0,
      "learning_rate": 5.599571734475375e-06,
      "loss": 1.5425,
      "step": 1346
    },
    {
      "epoch": 0.7210920770877944,
      "grad_norm": 0.0,
      "learning_rate": 5.588865096359744e-06,
      "loss": 1.2892,
      "step": 1347
    },
    {
      "epoch": 0.721627408993576,
      "grad_norm": 0.0,
      "learning_rate": 5.578158458244112e-06,
      "loss": 1.595,
      "step": 1348
    },
    {
      "epoch": 0.7221627408993576,
      "grad_norm": 0.0,
      "learning_rate": 5.56745182012848e-06,
      "loss": 1.7869,
      "step": 1349
    },
    {
      "epoch": 0.7226980728051392,
      "grad_norm": 0.0,
      "learning_rate": 5.556745182012848e-06,
      "loss": 1.8183,
      "step": 1350
    },
    {
      "epoch": 0.7232334047109208,
      "grad_norm": 0.0,
      "learning_rate": 5.546038543897217e-06,
      "loss": 1.5969,
      "step": 1351
    },
    {
      "epoch": 0.7237687366167024,
      "grad_norm": 0.0,
      "learning_rate": 5.535331905781585e-06,
      "loss": 1.7971,
      "step": 1352
    },
    {
      "epoch": 0.724304068522484,
      "grad_norm": 0.0,
      "learning_rate": 5.524625267665953e-06,
      "loss": 1.4276,
      "step": 1353
    },
    {
      "epoch": 0.7248394004282656,
      "grad_norm": 0.0,
      "learning_rate": 5.513918629550322e-06,
      "loss": 1.8487,
      "step": 1354
    },
    {
      "epoch": 0.7253747323340471,
      "grad_norm": 0.0,
      "learning_rate": 5.503211991434691e-06,
      "loss": 1.6235,
      "step": 1355
    },
    {
      "epoch": 0.7259100642398287,
      "grad_norm": 0.0,
      "learning_rate": 5.4925053533190584e-06,
      "loss": 1.4698,
      "step": 1356
    },
    {
      "epoch": 0.7264453961456103,
      "grad_norm": 0.0,
      "learning_rate": 5.481798715203427e-06,
      "loss": 1.6894,
      "step": 1357
    },
    {
      "epoch": 0.7269807280513919,
      "grad_norm": 0.0,
      "learning_rate": 5.471092077087795e-06,
      "loss": 1.4858,
      "step": 1358
    },
    {
      "epoch": 0.7275160599571735,
      "grad_norm": 0.0,
      "learning_rate": 5.460385438972164e-06,
      "loss": 1.5988,
      "step": 1359
    },
    {
      "epoch": 0.728051391862955,
      "grad_norm": 0.0,
      "learning_rate": 5.4496788008565314e-06,
      "loss": 1.8028,
      "step": 1360
    },
    {
      "epoch": 0.7285867237687366,
      "grad_norm": 0.0,
      "learning_rate": 5.4389721627409e-06,
      "loss": 1.9529,
      "step": 1361
    },
    {
      "epoch": 0.7291220556745182,
      "grad_norm": 0.0,
      "learning_rate": 5.428265524625268e-06,
      "loss": 1.5494,
      "step": 1362
    },
    {
      "epoch": 0.7296573875802997,
      "grad_norm": 0.0,
      "learning_rate": 5.417558886509637e-06,
      "loss": 1.6151,
      "step": 1363
    },
    {
      "epoch": 0.7301927194860813,
      "grad_norm": 0.0,
      "learning_rate": 5.4068522483940044e-06,
      "loss": 1.5918,
      "step": 1364
    },
    {
      "epoch": 0.7307280513918629,
      "grad_norm": 0.0,
      "learning_rate": 5.396145610278373e-06,
      "loss": 1.69,
      "step": 1365
    },
    {
      "epoch": 0.7312633832976445,
      "grad_norm": 0.0,
      "learning_rate": 5.385438972162741e-06,
      "loss": 1.848,
      "step": 1366
    },
    {
      "epoch": 0.7317987152034261,
      "grad_norm": 0.0,
      "learning_rate": 5.374732334047109e-06,
      "loss": 1.6873,
      "step": 1367
    },
    {
      "epoch": 0.7323340471092077,
      "grad_norm": 0.0,
      "learning_rate": 5.364025695931478e-06,
      "loss": 1.5937,
      "step": 1368
    },
    {
      "epoch": 0.7328693790149893,
      "grad_norm": 0.0,
      "learning_rate": 5.353319057815847e-06,
      "loss": 1.6428,
      "step": 1369
    },
    {
      "epoch": 0.7334047109207709,
      "grad_norm": 0.0,
      "learning_rate": 5.342612419700215e-06,
      "loss": 1.4438,
      "step": 1370
    },
    {
      "epoch": 0.7339400428265525,
      "grad_norm": 0.0,
      "learning_rate": 5.3319057815845834e-06,
      "loss": 1.7782,
      "step": 1371
    },
    {
      "epoch": 0.734475374732334,
      "grad_norm": 0.0,
      "learning_rate": 5.321199143468951e-06,
      "loss": 1.6828,
      "step": 1372
    },
    {
      "epoch": 0.7350107066381156,
      "grad_norm": 0.0,
      "learning_rate": 5.31049250535332e-06,
      "loss": 2.0319,
      "step": 1373
    },
    {
      "epoch": 0.7355460385438972,
      "grad_norm": 0.0,
      "learning_rate": 5.299785867237688e-06,
      "loss": 1.7582,
      "step": 1374
    },
    {
      "epoch": 0.7360813704496788,
      "grad_norm": 0.0,
      "learning_rate": 5.2890792291220564e-06,
      "loss": 1.4073,
      "step": 1375
    },
    {
      "epoch": 0.7366167023554604,
      "grad_norm": 0.0,
      "learning_rate": 5.278372591006424e-06,
      "loss": 1.5173,
      "step": 1376
    },
    {
      "epoch": 0.737152034261242,
      "grad_norm": 0.0,
      "learning_rate": 5.267665952890793e-06,
      "loss": 1.4912,
      "step": 1377
    },
    {
      "epoch": 0.7376873661670236,
      "grad_norm": 0.0,
      "learning_rate": 5.256959314775161e-06,
      "loss": 1.5997,
      "step": 1378
    },
    {
      "epoch": 0.7382226980728052,
      "grad_norm": 0.0,
      "learning_rate": 5.2462526766595286e-06,
      "loss": 1.5827,
      "step": 1379
    },
    {
      "epoch": 0.7387580299785867,
      "grad_norm": 0.0,
      "learning_rate": 5.235546038543897e-06,
      "loss": 1.5414,
      "step": 1380
    },
    {
      "epoch": 0.7392933618843683,
      "grad_norm": 0.0,
      "learning_rate": 5.224839400428265e-06,
      "loss": 1.4695,
      "step": 1381
    },
    {
      "epoch": 0.7398286937901499,
      "grad_norm": 0.0,
      "learning_rate": 5.214132762312635e-06,
      "loss": 1.6968,
      "step": 1382
    },
    {
      "epoch": 0.7403640256959315,
      "grad_norm": 0.0,
      "learning_rate": 5.203426124197003e-06,
      "loss": 1.376,
      "step": 1383
    },
    {
      "epoch": 0.7408993576017131,
      "grad_norm": 0.0,
      "learning_rate": 5.192719486081371e-06,
      "loss": 1.3844,
      "step": 1384
    },
    {
      "epoch": 0.7414346895074947,
      "grad_norm": 0.0,
      "learning_rate": 5.18201284796574e-06,
      "loss": 1.5116,
      "step": 1385
    },
    {
      "epoch": 0.7419700214132763,
      "grad_norm": 0.0,
      "learning_rate": 5.171306209850108e-06,
      "loss": 1.6784,
      "step": 1386
    },
    {
      "epoch": 0.7425053533190579,
      "grad_norm": 0.0,
      "learning_rate": 5.160599571734476e-06,
      "loss": 1.6096,
      "step": 1387
    },
    {
      "epoch": 0.7430406852248393,
      "grad_norm": 0.0,
      "learning_rate": 5.149892933618844e-06,
      "loss": 1.7164,
      "step": 1388
    },
    {
      "epoch": 0.7435760171306209,
      "grad_norm": 0.0,
      "learning_rate": 5.139186295503213e-06,
      "loss": 1.6866,
      "step": 1389
    },
    {
      "epoch": 0.7441113490364025,
      "grad_norm": 0.0,
      "learning_rate": 5.128479657387581e-06,
      "loss": 1.5358,
      "step": 1390
    },
    {
      "epoch": 0.7446466809421841,
      "grad_norm": 0.0,
      "learning_rate": 5.117773019271948e-06,
      "loss": 1.8353,
      "step": 1391
    },
    {
      "epoch": 0.7451820128479657,
      "grad_norm": 0.0,
      "learning_rate": 5.107066381156317e-06,
      "loss": 2.032,
      "step": 1392
    },
    {
      "epoch": 0.7457173447537473,
      "grad_norm": 0.0,
      "learning_rate": 5.096359743040685e-06,
      "loss": 1.4567,
      "step": 1393
    },
    {
      "epoch": 0.7462526766595289,
      "grad_norm": 0.0,
      "learning_rate": 5.0856531049250536e-06,
      "loss": 1.5649,
      "step": 1394
    },
    {
      "epoch": 0.7467880085653105,
      "grad_norm": 0.0,
      "learning_rate": 5.074946466809421e-06,
      "loss": 1.6326,
      "step": 1395
    },
    {
      "epoch": 0.7473233404710921,
      "grad_norm": 0.0,
      "learning_rate": 5.064239828693791e-06,
      "loss": 1.4965,
      "step": 1396
    },
    {
      "epoch": 0.7478586723768736,
      "grad_norm": 0.0,
      "learning_rate": 5.05353319057816e-06,
      "loss": 1.6945,
      "step": 1397
    },
    {
      "epoch": 0.7483940042826552,
      "grad_norm": 0.0,
      "learning_rate": 5.042826552462527e-06,
      "loss": 1.6072,
      "step": 1398
    },
    {
      "epoch": 0.7489293361884368,
      "grad_norm": 0.0,
      "learning_rate": 5.032119914346896e-06,
      "loss": 1.6429,
      "step": 1399
    },
    {
      "epoch": 0.7494646680942184,
      "grad_norm": 0.0,
      "learning_rate": 5.021413276231264e-06,
      "loss": 1.61,
      "step": 1400
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.0,
      "learning_rate": 5.010706638115633e-06,
      "loss": 1.3556,
      "step": 1401
    },
    {
      "epoch": 0.7505353319057816,
      "grad_norm": 0.0,
      "learning_rate": 5e-06,
      "loss": 1.3868,
      "step": 1402
    },
    {
      "epoch": 0.7510706638115632,
      "grad_norm": 0.0,
      "learning_rate": 4.989293361884368e-06,
      "loss": 1.5047,
      "step": 1403
    },
    {
      "epoch": 0.7516059957173448,
      "grad_norm": 0.0,
      "learning_rate": 4.978586723768737e-06,
      "loss": 1.4633,
      "step": 1404
    },
    {
      "epoch": 0.7521413276231264,
      "grad_norm": 0.0,
      "learning_rate": 4.967880085653105e-06,
      "loss": 1.6143,
      "step": 1405
    },
    {
      "epoch": 0.7526766595289079,
      "grad_norm": 0.0,
      "learning_rate": 4.957173447537474e-06,
      "loss": 1.5254,
      "step": 1406
    },
    {
      "epoch": 0.7532119914346895,
      "grad_norm": 0.0,
      "learning_rate": 4.946466809421842e-06,
      "loss": 1.5216,
      "step": 1407
    },
    {
      "epoch": 0.7537473233404711,
      "grad_norm": 0.0,
      "learning_rate": 4.935760171306211e-06,
      "loss": 1.7244,
      "step": 1408
    },
    {
      "epoch": 0.7542826552462527,
      "grad_norm": 0.0,
      "learning_rate": 4.9250535331905786e-06,
      "loss": 2.0616,
      "step": 1409
    },
    {
      "epoch": 0.7548179871520343,
      "grad_norm": 0.0,
      "learning_rate": 4.914346895074946e-06,
      "loss": 1.3568,
      "step": 1410
    },
    {
      "epoch": 0.7553533190578159,
      "grad_norm": 0.0,
      "learning_rate": 4.903640256959315e-06,
      "loss": 1.6476,
      "step": 1411
    },
    {
      "epoch": 0.7558886509635975,
      "grad_norm": 0.0,
      "learning_rate": 4.892933618843683e-06,
      "loss": 1.3416,
      "step": 1412
    },
    {
      "epoch": 0.7564239828693791,
      "grad_norm": 0.0,
      "learning_rate": 4.882226980728052e-06,
      "loss": 1.6092,
      "step": 1413
    },
    {
      "epoch": 0.7569593147751607,
      "grad_norm": 0.0,
      "learning_rate": 4.87152034261242e-06,
      "loss": 1.4922,
      "step": 1414
    },
    {
      "epoch": 0.7574946466809421,
      "grad_norm": 0.0,
      "learning_rate": 4.860813704496788e-06,
      "loss": 1.5209,
      "step": 1415
    },
    {
      "epoch": 0.7580299785867237,
      "grad_norm": 0.0,
      "learning_rate": 4.850107066381157e-06,
      "loss": 1.5168,
      "step": 1416
    },
    {
      "epoch": 0.7585653104925053,
      "grad_norm": 0.0,
      "learning_rate": 4.8394004282655246e-06,
      "loss": 1.634,
      "step": 1417
    },
    {
      "epoch": 0.7591006423982869,
      "grad_norm": 0.0,
      "learning_rate": 4.828693790149893e-06,
      "loss": 1.4775,
      "step": 1418
    },
    {
      "epoch": 0.7596359743040685,
      "grad_norm": 0.0,
      "learning_rate": 4.817987152034261e-06,
      "loss": 1.6296,
      "step": 1419
    },
    {
      "epoch": 0.7601713062098501,
      "grad_norm": 0.0,
      "learning_rate": 4.807280513918631e-06,
      "loss": 1.5848,
      "step": 1420
    },
    {
      "epoch": 0.7607066381156317,
      "grad_norm": 0.0,
      "learning_rate": 4.796573875802998e-06,
      "loss": 1.4366,
      "step": 1421
    },
    {
      "epoch": 0.7612419700214133,
      "grad_norm": 0.0,
      "learning_rate": 4.785867237687366e-06,
      "loss": 1.4763,
      "step": 1422
    },
    {
      "epoch": 0.7617773019271948,
      "grad_norm": 0.0,
      "learning_rate": 4.775160599571735e-06,
      "loss": 1.8161,
      "step": 1423
    },
    {
      "epoch": 0.7623126338329764,
      "grad_norm": 0.0,
      "learning_rate": 4.764453961456103e-06,
      "loss": 1.5182,
      "step": 1424
    },
    {
      "epoch": 0.762847965738758,
      "grad_norm": 0.0,
      "learning_rate": 4.753747323340471e-06,
      "loss": 1.6298,
      "step": 1425
    },
    {
      "epoch": 0.7633832976445396,
      "grad_norm": 0.0,
      "learning_rate": 4.743040685224839e-06,
      "loss": 1.5145,
      "step": 1426
    },
    {
      "epoch": 0.7639186295503212,
      "grad_norm": 0.0,
      "learning_rate": 4.732334047109208e-06,
      "loss": 1.5879,
      "step": 1427
    },
    {
      "epoch": 0.7644539614561028,
      "grad_norm": 0.0,
      "learning_rate": 4.7216274089935766e-06,
      "loss": 1.5981,
      "step": 1428
    },
    {
      "epoch": 0.7649892933618844,
      "grad_norm": 0.0,
      "learning_rate": 4.710920770877944e-06,
      "loss": 1.612,
      "step": 1429
    },
    {
      "epoch": 0.765524625267666,
      "grad_norm": 0.0,
      "learning_rate": 4.700214132762313e-06,
      "loss": 1.5229,
      "step": 1430
    },
    {
      "epoch": 0.7660599571734475,
      "grad_norm": 0.0,
      "learning_rate": 4.689507494646681e-06,
      "loss": 1.7626,
      "step": 1431
    },
    {
      "epoch": 0.7665952890792291,
      "grad_norm": 0.0,
      "learning_rate": 4.6788008565310496e-06,
      "loss": 1.9157,
      "step": 1432
    },
    {
      "epoch": 0.7671306209850107,
      "grad_norm": 0.0,
      "learning_rate": 4.668094218415418e-06,
      "loss": 1.5502,
      "step": 1433
    },
    {
      "epoch": 0.7676659528907923,
      "grad_norm": 0.0,
      "learning_rate": 4.657387580299786e-06,
      "loss": 1.7043,
      "step": 1434
    },
    {
      "epoch": 0.7682012847965739,
      "grad_norm": 0.0,
      "learning_rate": 4.646680942184155e-06,
      "loss": 1.543,
      "step": 1435
    },
    {
      "epoch": 0.7687366167023555,
      "grad_norm": 0.0,
      "learning_rate": 4.6359743040685226e-06,
      "loss": 1.7346,
      "step": 1436
    },
    {
      "epoch": 0.7692719486081371,
      "grad_norm": 0.0,
      "learning_rate": 4.625267665952891e-06,
      "loss": 1.6047,
      "step": 1437
    },
    {
      "epoch": 0.7698072805139187,
      "grad_norm": 0.0,
      "learning_rate": 4.614561027837259e-06,
      "loss": 1.5122,
      "step": 1438
    },
    {
      "epoch": 0.7703426124197003,
      "grad_norm": 0.0,
      "learning_rate": 4.603854389721628e-06,
      "loss": 1.506,
      "step": 1439
    },
    {
      "epoch": 0.7708779443254818,
      "grad_norm": 0.0,
      "learning_rate": 4.593147751605996e-06,
      "loss": 1.5232,
      "step": 1440
    },
    {
      "epoch": 0.7714132762312634,
      "grad_norm": 0.0,
      "learning_rate": 4.582441113490364e-06,
      "loss": 1.5976,
      "step": 1441
    },
    {
      "epoch": 0.771948608137045,
      "grad_norm": 0.0,
      "learning_rate": 4.571734475374733e-06,
      "loss": 1.5065,
      "step": 1442
    },
    {
      "epoch": 0.7724839400428265,
      "grad_norm": 0.0,
      "learning_rate": 4.561027837259101e-06,
      "loss": 1.6765,
      "step": 1443
    },
    {
      "epoch": 0.7730192719486081,
      "grad_norm": 0.0,
      "learning_rate": 4.550321199143469e-06,
      "loss": 1.739,
      "step": 1444
    },
    {
      "epoch": 0.7735546038543897,
      "grad_norm": 0.0,
      "learning_rate": 4.539614561027837e-06,
      "loss": 1.695,
      "step": 1445
    },
    {
      "epoch": 0.7740899357601713,
      "grad_norm": 0.0,
      "learning_rate": 4.528907922912206e-06,
      "loss": 1.3632,
      "step": 1446
    },
    {
      "epoch": 0.7746252676659529,
      "grad_norm": 0.0,
      "learning_rate": 4.5182012847965746e-06,
      "loss": 1.6117,
      "step": 1447
    },
    {
      "epoch": 0.7751605995717344,
      "grad_norm": 0.0,
      "learning_rate": 4.507494646680942e-06,
      "loss": 1.5098,
      "step": 1448
    },
    {
      "epoch": 0.775695931477516,
      "grad_norm": 0.0,
      "learning_rate": 4.496788008565311e-06,
      "loss": 1.3804,
      "step": 1449
    },
    {
      "epoch": 0.7762312633832976,
      "grad_norm": 0.0,
      "learning_rate": 4.486081370449679e-06,
      "loss": 1.4385,
      "step": 1450
    },
    {
      "epoch": 0.7767665952890792,
      "grad_norm": 0.0,
      "learning_rate": 4.4753747323340476e-06,
      "loss": 1.6685,
      "step": 1451
    },
    {
      "epoch": 0.7773019271948608,
      "grad_norm": 0.0,
      "learning_rate": 4.464668094218415e-06,
      "loss": 1.483,
      "step": 1452
    },
    {
      "epoch": 0.7778372591006424,
      "grad_norm": 0.0,
      "learning_rate": 4.453961456102784e-06,
      "loss": 1.848,
      "step": 1453
    },
    {
      "epoch": 0.778372591006424,
      "grad_norm": 0.0,
      "learning_rate": 4.443254817987153e-06,
      "loss": 1.6594,
      "step": 1454
    },
    {
      "epoch": 0.7789079229122056,
      "grad_norm": 0.0,
      "learning_rate": 4.4325481798715205e-06,
      "loss": 1.6877,
      "step": 1455
    },
    {
      "epoch": 0.7794432548179872,
      "grad_norm": 0.0,
      "learning_rate": 4.421841541755889e-06,
      "loss": 1.7459,
      "step": 1456
    },
    {
      "epoch": 0.7799785867237687,
      "grad_norm": 0.0,
      "learning_rate": 4.411134903640257e-06,
      "loss": 1.5795,
      "step": 1457
    },
    {
      "epoch": 0.7805139186295503,
      "grad_norm": 0.0,
      "learning_rate": 4.400428265524626e-06,
      "loss": 1.7532,
      "step": 1458
    },
    {
      "epoch": 0.7810492505353319,
      "grad_norm": 0.0,
      "learning_rate": 4.3897216274089935e-06,
      "loss": 1.9105,
      "step": 1459
    },
    {
      "epoch": 0.7815845824411135,
      "grad_norm": 0.0,
      "learning_rate": 4.379014989293362e-06,
      "loss": 1.5804,
      "step": 1460
    },
    {
      "epoch": 0.7821199143468951,
      "grad_norm": 0.0,
      "learning_rate": 4.368308351177731e-06,
      "loss": 1.478,
      "step": 1461
    },
    {
      "epoch": 0.7826552462526767,
      "grad_norm": 0.0,
      "learning_rate": 4.357601713062099e-06,
      "loss": 1.7875,
      "step": 1462
    },
    {
      "epoch": 0.7831905781584583,
      "grad_norm": 0.0,
      "learning_rate": 4.346895074946467e-06,
      "loss": 1.4965,
      "step": 1463
    },
    {
      "epoch": 0.7837259100642399,
      "grad_norm": 0.0,
      "learning_rate": 4.336188436830835e-06,
      "loss": 1.5642,
      "step": 1464
    },
    {
      "epoch": 0.7842612419700214,
      "grad_norm": 0.0,
      "learning_rate": 4.325481798715204e-06,
      "loss": 2.152,
      "step": 1465
    },
    {
      "epoch": 0.784796573875803,
      "grad_norm": 0.0,
      "learning_rate": 4.314775160599572e-06,
      "loss": 1.6052,
      "step": 1466
    },
    {
      "epoch": 0.7853319057815846,
      "grad_norm": 0.0,
      "learning_rate": 4.30406852248394e-06,
      "loss": 1.5246,
      "step": 1467
    },
    {
      "epoch": 0.7858672376873662,
      "grad_norm": 0.0,
      "learning_rate": 4.293361884368309e-06,
      "loss": 1.8819,
      "step": 1468
    },
    {
      "epoch": 0.7864025695931478,
      "grad_norm": 0.0,
      "learning_rate": 4.282655246252677e-06,
      "loss": 1.8827,
      "step": 1469
    },
    {
      "epoch": 0.7869379014989293,
      "grad_norm": 0.0,
      "learning_rate": 4.2719486081370455e-06,
      "loss": 1.4145,
      "step": 1470
    },
    {
      "epoch": 0.7874732334047109,
      "grad_norm": 0.0,
      "learning_rate": 4.261241970021413e-06,
      "loss": 1.801,
      "step": 1471
    },
    {
      "epoch": 0.7880085653104925,
      "grad_norm": 0.0,
      "learning_rate": 4.250535331905782e-06,
      "loss": 1.4127,
      "step": 1472
    },
    {
      "epoch": 0.788543897216274,
      "grad_norm": 0.0,
      "learning_rate": 4.23982869379015e-06,
      "loss": 1.4884,
      "step": 1473
    },
    {
      "epoch": 0.7890792291220556,
      "grad_norm": 0.0,
      "learning_rate": 4.2291220556745185e-06,
      "loss": 1.5602,
      "step": 1474
    },
    {
      "epoch": 0.7896145610278372,
      "grad_norm": 0.0,
      "learning_rate": 4.218415417558887e-06,
      "loss": 1.7105,
      "step": 1475
    },
    {
      "epoch": 0.7901498929336188,
      "grad_norm": 0.0,
      "learning_rate": 4.207708779443255e-06,
      "loss": 1.6124,
      "step": 1476
    },
    {
      "epoch": 0.7906852248394004,
      "grad_norm": 0.0,
      "learning_rate": 4.197002141327624e-06,
      "loss": 1.4686,
      "step": 1477
    },
    {
      "epoch": 0.791220556745182,
      "grad_norm": 0.0,
      "learning_rate": 4.1862955032119915e-06,
      "loss": 1.617,
      "step": 1478
    },
    {
      "epoch": 0.7917558886509636,
      "grad_norm": 0.0,
      "learning_rate": 4.17558886509636e-06,
      "loss": 1.8431,
      "step": 1479
    },
    {
      "epoch": 0.7922912205567452,
      "grad_norm": 0.0,
      "learning_rate": 4.164882226980728e-06,
      "loss": 1.5107,
      "step": 1480
    },
    {
      "epoch": 0.7928265524625268,
      "grad_norm": 0.0,
      "learning_rate": 4.154175588865097e-06,
      "loss": 1.4504,
      "step": 1481
    },
    {
      "epoch": 0.7933618843683083,
      "grad_norm": 0.0,
      "learning_rate": 4.143468950749465e-06,
      "loss": 1.7063,
      "step": 1482
    },
    {
      "epoch": 0.7938972162740899,
      "grad_norm": 0.0,
      "learning_rate": 4.132762312633833e-06,
      "loss": 1.4424,
      "step": 1483
    },
    {
      "epoch": 0.7944325481798715,
      "grad_norm": 0.0,
      "learning_rate": 4.122055674518202e-06,
      "loss": 1.4308,
      "step": 1484
    },
    {
      "epoch": 0.7949678800856531,
      "grad_norm": 0.0,
      "learning_rate": 4.11134903640257e-06,
      "loss": 1.7592,
      "step": 1485
    },
    {
      "epoch": 0.7955032119914347,
      "grad_norm": 0.0,
      "learning_rate": 4.100642398286938e-06,
      "loss": 1.4995,
      "step": 1486
    },
    {
      "epoch": 0.7960385438972163,
      "grad_norm": 0.0,
      "learning_rate": 4.089935760171306e-06,
      "loss": 1.5764,
      "step": 1487
    },
    {
      "epoch": 0.7965738758029979,
      "grad_norm": 0.0,
      "learning_rate": 4.079229122055675e-06,
      "loss": 1.8148,
      "step": 1488
    },
    {
      "epoch": 0.7971092077087795,
      "grad_norm": 0.0,
      "learning_rate": 4.0685224839400435e-06,
      "loss": 1.4323,
      "step": 1489
    },
    {
      "epoch": 0.797644539614561,
      "grad_norm": 0.0,
      "learning_rate": 4.057815845824411e-06,
      "loss": 1.5523,
      "step": 1490
    },
    {
      "epoch": 0.7981798715203426,
      "grad_norm": 0.0,
      "learning_rate": 4.04710920770878e-06,
      "loss": 1.4168,
      "step": 1491
    },
    {
      "epoch": 0.7987152034261242,
      "grad_norm": 0.0,
      "learning_rate": 4.036402569593148e-06,
      "loss": 1.5967,
      "step": 1492
    },
    {
      "epoch": 0.7992505353319058,
      "grad_norm": 0.0,
      "learning_rate": 4.0256959314775165e-06,
      "loss": 1.4657,
      "step": 1493
    },
    {
      "epoch": 0.7997858672376874,
      "grad_norm": 0.0,
      "learning_rate": 4.014989293361884e-06,
      "loss": 1.4064,
      "step": 1494
    },
    {
      "epoch": 0.800321199143469,
      "grad_norm": 0.0,
      "learning_rate": 4.004282655246253e-06,
      "loss": 1.3596,
      "step": 1495
    },
    {
      "epoch": 0.8008565310492506,
      "grad_norm": 0.0,
      "learning_rate": 3.993576017130622e-06,
      "loss": 1.612,
      "step": 1496
    },
    {
      "epoch": 0.8013918629550322,
      "grad_norm": 0.0,
      "learning_rate": 3.9828693790149895e-06,
      "loss": 1.6082,
      "step": 1497
    },
    {
      "epoch": 0.8019271948608137,
      "grad_norm": 0.0,
      "learning_rate": 3.972162740899358e-06,
      "loss": 1.5702,
      "step": 1498
    },
    {
      "epoch": 0.8024625267665952,
      "grad_norm": 0.0,
      "learning_rate": 3.961456102783726e-06,
      "loss": 1.7267,
      "step": 1499
    },
    {
      "epoch": 0.8029978586723768,
      "grad_norm": 0.0,
      "learning_rate": 3.950749464668095e-06,
      "loss": 1.6084,
      "step": 1500
    },
    {
      "epoch": 0.8035331905781584,
      "grad_norm": 0.0,
      "learning_rate": 3.9400428265524625e-06,
      "loss": 1.5704,
      "step": 1501
    },
    {
      "epoch": 0.80406852248394,
      "grad_norm": 0.0,
      "learning_rate": 3.929336188436831e-06,
      "loss": 1.5258,
      "step": 1502
    },
    {
      "epoch": 0.8046038543897216,
      "grad_norm": 0.0,
      "learning_rate": 3.9186295503212e-06,
      "loss": 2.3489,
      "step": 1503
    },
    {
      "epoch": 0.8051391862955032,
      "grad_norm": 0.0,
      "learning_rate": 3.907922912205568e-06,
      "loss": 1.3257,
      "step": 1504
    },
    {
      "epoch": 0.8056745182012848,
      "grad_norm": 0.0,
      "learning_rate": 3.897216274089936e-06,
      "loss": 1.8999,
      "step": 1505
    },
    {
      "epoch": 0.8062098501070664,
      "grad_norm": 0.0,
      "learning_rate": 3.886509635974304e-06,
      "loss": 1.9602,
      "step": 1506
    },
    {
      "epoch": 0.806745182012848,
      "grad_norm": 0.0,
      "learning_rate": 3.875802997858673e-06,
      "loss": 1.8423,
      "step": 1507
    },
    {
      "epoch": 0.8072805139186295,
      "grad_norm": 0.0,
      "learning_rate": 3.865096359743041e-06,
      "loss": 1.5738,
      "step": 1508
    },
    {
      "epoch": 0.8078158458244111,
      "grad_norm": 0.0,
      "learning_rate": 3.854389721627409e-06,
      "loss": 1.4696,
      "step": 1509
    },
    {
      "epoch": 0.8083511777301927,
      "grad_norm": 0.0,
      "learning_rate": 3.843683083511778e-06,
      "loss": 1.6042,
      "step": 1510
    },
    {
      "epoch": 0.8088865096359743,
      "grad_norm": 0.0,
      "learning_rate": 3.832976445396146e-06,
      "loss": 1.359,
      "step": 1511
    },
    {
      "epoch": 0.8094218415417559,
      "grad_norm": 0.0,
      "learning_rate": 3.8222698072805145e-06,
      "loss": 1.5137,
      "step": 1512
    },
    {
      "epoch": 0.8099571734475375,
      "grad_norm": 0.0,
      "learning_rate": 3.8115631691648823e-06,
      "loss": 1.8995,
      "step": 1513
    },
    {
      "epoch": 0.8104925053533191,
      "grad_norm": 0.0,
      "learning_rate": 3.8008565310492506e-06,
      "loss": 1.5465,
      "step": 1514
    },
    {
      "epoch": 0.8110278372591007,
      "grad_norm": 0.0,
      "learning_rate": 3.790149892933619e-06,
      "loss": 1.7807,
      "step": 1515
    },
    {
      "epoch": 0.8115631691648822,
      "grad_norm": 0.0,
      "learning_rate": 3.7794432548179875e-06,
      "loss": 1.8175,
      "step": 1516
    },
    {
      "epoch": 0.8120985010706638,
      "grad_norm": 0.0,
      "learning_rate": 3.7687366167023558e-06,
      "loss": 1.5064,
      "step": 1517
    },
    {
      "epoch": 0.8126338329764454,
      "grad_norm": 0.0,
      "learning_rate": 3.758029978586724e-06,
      "loss": 1.5714,
      "step": 1518
    },
    {
      "epoch": 0.813169164882227,
      "grad_norm": 0.0,
      "learning_rate": 3.7473233404710923e-06,
      "loss": 1.4928,
      "step": 1519
    },
    {
      "epoch": 0.8137044967880086,
      "grad_norm": 0.0,
      "learning_rate": 3.7366167023554605e-06,
      "loss": 1.8425,
      "step": 1520
    },
    {
      "epoch": 0.8142398286937902,
      "grad_norm": 0.0,
      "learning_rate": 3.7259100642398288e-06,
      "loss": 1.4131,
      "step": 1521
    },
    {
      "epoch": 0.8147751605995718,
      "grad_norm": 0.0,
      "learning_rate": 3.715203426124197e-06,
      "loss": 1.8545,
      "step": 1522
    },
    {
      "epoch": 0.8153104925053534,
      "grad_norm": 0.0,
      "learning_rate": 3.7044967880085657e-06,
      "loss": 1.8575,
      "step": 1523
    },
    {
      "epoch": 0.815845824411135,
      "grad_norm": 0.0,
      "learning_rate": 3.693790149892934e-06,
      "loss": 1.3004,
      "step": 1524
    },
    {
      "epoch": 0.8163811563169164,
      "grad_norm": 0.0,
      "learning_rate": 3.683083511777302e-06,
      "loss": 1.4208,
      "step": 1525
    },
    {
      "epoch": 0.816916488222698,
      "grad_norm": 0.0,
      "learning_rate": 3.6723768736616704e-06,
      "loss": 1.4811,
      "step": 1526
    },
    {
      "epoch": 0.8174518201284796,
      "grad_norm": 0.0,
      "learning_rate": 3.6616702355460387e-06,
      "loss": 1.4761,
      "step": 1527
    },
    {
      "epoch": 0.8179871520342612,
      "grad_norm": 0.0,
      "learning_rate": 3.650963597430407e-06,
      "loss": 1.6804,
      "step": 1528
    },
    {
      "epoch": 0.8185224839400428,
      "grad_norm": 0.0,
      "learning_rate": 3.640256959314775e-06,
      "loss": 1.4884,
      "step": 1529
    },
    {
      "epoch": 0.8190578158458244,
      "grad_norm": 0.0,
      "learning_rate": 3.629550321199144e-06,
      "loss": 1.8302,
      "step": 1530
    },
    {
      "epoch": 0.819593147751606,
      "grad_norm": 0.0,
      "learning_rate": 3.618843683083512e-06,
      "loss": 1.5578,
      "step": 1531
    },
    {
      "epoch": 0.8201284796573876,
      "grad_norm": 0.0,
      "learning_rate": 3.6081370449678803e-06,
      "loss": 1.3976,
      "step": 1532
    },
    {
      "epoch": 0.8206638115631691,
      "grad_norm": 0.0,
      "learning_rate": 3.5974304068522486e-06,
      "loss": 1.3842,
      "step": 1533
    },
    {
      "epoch": 0.8211991434689507,
      "grad_norm": 0.0,
      "learning_rate": 3.586723768736617e-06,
      "loss": 1.7818,
      "step": 1534
    },
    {
      "epoch": 0.8217344753747323,
      "grad_norm": 0.0,
      "learning_rate": 3.576017130620985e-06,
      "loss": 1.5633,
      "step": 1535
    },
    {
      "epoch": 0.8222698072805139,
      "grad_norm": 0.0,
      "learning_rate": 3.5653104925053538e-06,
      "loss": 1.8734,
      "step": 1536
    },
    {
      "epoch": 0.8228051391862955,
      "grad_norm": 0.0,
      "learning_rate": 3.554603854389722e-06,
      "loss": 2.0943,
      "step": 1537
    },
    {
      "epoch": 0.8233404710920771,
      "grad_norm": 0.0,
      "learning_rate": 3.5438972162740903e-06,
      "loss": 1.3852,
      "step": 1538
    },
    {
      "epoch": 0.8238758029978587,
      "grad_norm": 0.0,
      "learning_rate": 3.5331905781584585e-06,
      "loss": 1.7067,
      "step": 1539
    },
    {
      "epoch": 0.8244111349036403,
      "grad_norm": 0.0,
      "learning_rate": 3.5224839400428268e-06,
      "loss": 1.3857,
      "step": 1540
    },
    {
      "epoch": 0.8249464668094219,
      "grad_norm": 0.0,
      "learning_rate": 3.511777301927195e-06,
      "loss": 1.3379,
      "step": 1541
    },
    {
      "epoch": 0.8254817987152034,
      "grad_norm": 0.0,
      "learning_rate": 3.5010706638115632e-06,
      "loss": 1.5837,
      "step": 1542
    },
    {
      "epoch": 0.826017130620985,
      "grad_norm": 0.0,
      "learning_rate": 3.490364025695932e-06,
      "loss": 1.6782,
      "step": 1543
    },
    {
      "epoch": 0.8265524625267666,
      "grad_norm": 0.0,
      "learning_rate": 3.4796573875803e-06,
      "loss": 1.6875,
      "step": 1544
    },
    {
      "epoch": 0.8270877944325482,
      "grad_norm": 0.0,
      "learning_rate": 3.4689507494646684e-06,
      "loss": 1.5155,
      "step": 1545
    },
    {
      "epoch": 0.8276231263383298,
      "grad_norm": 0.0,
      "learning_rate": 3.4582441113490367e-06,
      "loss": 1.4987,
      "step": 1546
    },
    {
      "epoch": 0.8281584582441114,
      "grad_norm": 0.0,
      "learning_rate": 3.447537473233405e-06,
      "loss": 1.7655,
      "step": 1547
    },
    {
      "epoch": 0.828693790149893,
      "grad_norm": 0.0,
      "learning_rate": 3.436830835117773e-06,
      "loss": 1.7295,
      "step": 1548
    },
    {
      "epoch": 0.8292291220556746,
      "grad_norm": 0.0,
      "learning_rate": 3.4261241970021414e-06,
      "loss": 1.4783,
      "step": 1549
    },
    {
      "epoch": 0.8297644539614561,
      "grad_norm": 0.0,
      "learning_rate": 3.41541755888651e-06,
      "loss": 1.962,
      "step": 1550
    },
    {
      "epoch": 0.8302997858672377,
      "grad_norm": 0.0,
      "learning_rate": 3.4047109207708783e-06,
      "loss": 1.9642,
      "step": 1551
    },
    {
      "epoch": 0.8308351177730193,
      "grad_norm": 0.0,
      "learning_rate": 3.3940042826552466e-06,
      "loss": 1.5349,
      "step": 1552
    },
    {
      "epoch": 0.8313704496788008,
      "grad_norm": 0.0,
      "learning_rate": 3.383297644539615e-06,
      "loss": 1.5329,
      "step": 1553
    },
    {
      "epoch": 0.8319057815845824,
      "grad_norm": 0.0,
      "learning_rate": 3.372591006423983e-06,
      "loss": 1.3361,
      "step": 1554
    },
    {
      "epoch": 0.832441113490364,
      "grad_norm": 0.0,
      "learning_rate": 3.3618843683083513e-06,
      "loss": 1.6266,
      "step": 1555
    },
    {
      "epoch": 0.8329764453961456,
      "grad_norm": 0.0,
      "learning_rate": 3.3511777301927196e-06,
      "loss": 1.6215,
      "step": 1556
    },
    {
      "epoch": 0.8335117773019272,
      "grad_norm": 0.0,
      "learning_rate": 3.3404710920770882e-06,
      "loss": 1.7911,
      "step": 1557
    },
    {
      "epoch": 0.8340471092077087,
      "grad_norm": 0.0,
      "learning_rate": 3.3297644539614565e-06,
      "loss": 1.4962,
      "step": 1558
    },
    {
      "epoch": 0.8345824411134903,
      "grad_norm": 0.0,
      "learning_rate": 3.3190578158458247e-06,
      "loss": 1.5481,
      "step": 1559
    },
    {
      "epoch": 0.8351177730192719,
      "grad_norm": 0.0,
      "learning_rate": 3.308351177730193e-06,
      "loss": 1.458,
      "step": 1560
    },
    {
      "epoch": 0.8356531049250535,
      "grad_norm": 0.0,
      "learning_rate": 3.2976445396145612e-06,
      "loss": 2.0314,
      "step": 1561
    },
    {
      "epoch": 0.8361884368308351,
      "grad_norm": 0.0,
      "learning_rate": 3.2869379014989295e-06,
      "loss": 1.4436,
      "step": 1562
    },
    {
      "epoch": 0.8367237687366167,
      "grad_norm": 0.0,
      "learning_rate": 3.2762312633832977e-06,
      "loss": 1.636,
      "step": 1563
    },
    {
      "epoch": 0.8372591006423983,
      "grad_norm": 0.0,
      "learning_rate": 3.2655246252676664e-06,
      "loss": 1.7773,
      "step": 1564
    },
    {
      "epoch": 0.8377944325481799,
      "grad_norm": 0.0,
      "learning_rate": 3.2548179871520347e-06,
      "loss": 1.3563,
      "step": 1565
    },
    {
      "epoch": 0.8383297644539615,
      "grad_norm": 0.0,
      "learning_rate": 3.244111349036403e-06,
      "loss": 1.4938,
      "step": 1566
    },
    {
      "epoch": 0.838865096359743,
      "grad_norm": 0.0,
      "learning_rate": 3.233404710920771e-06,
      "loss": 1.4886,
      "step": 1567
    },
    {
      "epoch": 0.8394004282655246,
      "grad_norm": 0.0,
      "learning_rate": 3.2226980728051394e-06,
      "loss": 1.7759,
      "step": 1568
    },
    {
      "epoch": 0.8399357601713062,
      "grad_norm": 0.0,
      "learning_rate": 3.2119914346895077e-06,
      "loss": 1.6282,
      "step": 1569
    },
    {
      "epoch": 0.8404710920770878,
      "grad_norm": 0.0,
      "learning_rate": 3.201284796573876e-06,
      "loss": 1.4098,
      "step": 1570
    },
    {
      "epoch": 0.8410064239828694,
      "grad_norm": 0.0,
      "learning_rate": 3.1905781584582446e-06,
      "loss": 1.5011,
      "step": 1571
    },
    {
      "epoch": 0.841541755888651,
      "grad_norm": 0.0,
      "learning_rate": 3.179871520342613e-06,
      "loss": 1.8498,
      "step": 1572
    },
    {
      "epoch": 0.8420770877944326,
      "grad_norm": 0.0,
      "learning_rate": 3.169164882226981e-06,
      "loss": 1.4183,
      "step": 1573
    },
    {
      "epoch": 0.8426124197002142,
      "grad_norm": 0.0,
      "learning_rate": 3.1584582441113493e-06,
      "loss": 1.3477,
      "step": 1574
    },
    {
      "epoch": 0.8431477516059958,
      "grad_norm": 0.0,
      "learning_rate": 3.1477516059957176e-06,
      "loss": 1.5262,
      "step": 1575
    },
    {
      "epoch": 0.8436830835117773,
      "grad_norm": 0.0,
      "learning_rate": 3.137044967880086e-06,
      "loss": 1.5993,
      "step": 1576
    },
    {
      "epoch": 0.8442184154175589,
      "grad_norm": 0.0,
      "learning_rate": 3.126338329764454e-06,
      "loss": 1.3232,
      "step": 1577
    },
    {
      "epoch": 0.8447537473233405,
      "grad_norm": 0.0,
      "learning_rate": 3.1156316916488227e-06,
      "loss": 1.5281,
      "step": 1578
    },
    {
      "epoch": 0.8452890792291221,
      "grad_norm": 0.0,
      "learning_rate": 3.104925053533191e-06,
      "loss": 1.5035,
      "step": 1579
    },
    {
      "epoch": 0.8458244111349036,
      "grad_norm": 0.0,
      "learning_rate": 3.0942184154175592e-06,
      "loss": 1.6527,
      "step": 1580
    },
    {
      "epoch": 0.8463597430406852,
      "grad_norm": 0.0,
      "learning_rate": 3.0835117773019275e-06,
      "loss": 1.5529,
      "step": 1581
    },
    {
      "epoch": 0.8468950749464668,
      "grad_norm": 0.0,
      "learning_rate": 3.0728051391862957e-06,
      "loss": 1.8345,
      "step": 1582
    },
    {
      "epoch": 0.8474304068522484,
      "grad_norm": 0.0,
      "learning_rate": 3.062098501070664e-06,
      "loss": 1.3898,
      "step": 1583
    },
    {
      "epoch": 0.8479657387580299,
      "grad_norm": 0.0,
      "learning_rate": 3.0513918629550327e-06,
      "loss": 1.5719,
      "step": 1584
    },
    {
      "epoch": 0.8485010706638115,
      "grad_norm": 0.0,
      "learning_rate": 3.040685224839401e-06,
      "loss": 1.3604,
      "step": 1585
    },
    {
      "epoch": 0.8490364025695931,
      "grad_norm": 0.0,
      "learning_rate": 3.029978586723769e-06,
      "loss": 1.6187,
      "step": 1586
    },
    {
      "epoch": 0.8495717344753747,
      "grad_norm": 0.0,
      "learning_rate": 3.0192719486081374e-06,
      "loss": 1.5228,
      "step": 1587
    },
    {
      "epoch": 0.8501070663811563,
      "grad_norm": 0.0,
      "learning_rate": 3.0085653104925056e-06,
      "loss": 1.8286,
      "step": 1588
    },
    {
      "epoch": 0.8506423982869379,
      "grad_norm": 0.0,
      "learning_rate": 2.997858672376874e-06,
      "loss": 2.2033,
      "step": 1589
    },
    {
      "epoch": 0.8511777301927195,
      "grad_norm": 0.0,
      "learning_rate": 2.987152034261242e-06,
      "loss": 1.7353,
      "step": 1590
    },
    {
      "epoch": 0.8517130620985011,
      "grad_norm": 0.0,
      "learning_rate": 2.976445396145611e-06,
      "loss": 1.4803,
      "step": 1591
    },
    {
      "epoch": 0.8522483940042827,
      "grad_norm": 0.0,
      "learning_rate": 2.965738758029979e-06,
      "loss": 1.5328,
      "step": 1592
    },
    {
      "epoch": 0.8527837259100642,
      "grad_norm": 0.0,
      "learning_rate": 2.9550321199143473e-06,
      "loss": 1.5477,
      "step": 1593
    },
    {
      "epoch": 0.8533190578158458,
      "grad_norm": 0.0,
      "learning_rate": 2.9443254817987156e-06,
      "loss": 1.5484,
      "step": 1594
    },
    {
      "epoch": 0.8538543897216274,
      "grad_norm": 0.0,
      "learning_rate": 2.933618843683084e-06,
      "loss": 1.6809,
      "step": 1595
    },
    {
      "epoch": 0.854389721627409,
      "grad_norm": 0.0,
      "learning_rate": 2.922912205567452e-06,
      "loss": 1.4586,
      "step": 1596
    },
    {
      "epoch": 0.8549250535331906,
      "grad_norm": 0.0,
      "learning_rate": 2.9122055674518203e-06,
      "loss": 1.4092,
      "step": 1597
    },
    {
      "epoch": 0.8554603854389722,
      "grad_norm": 0.0,
      "learning_rate": 2.901498929336189e-06,
      "loss": 1.5753,
      "step": 1598
    },
    {
      "epoch": 0.8559957173447538,
      "grad_norm": 0.0,
      "learning_rate": 2.8907922912205572e-06,
      "loss": 1.5468,
      "step": 1599
    },
    {
      "epoch": 0.8565310492505354,
      "grad_norm": 0.0,
      "learning_rate": 2.8800856531049255e-06,
      "loss": 1.4234,
      "step": 1600
    },
    {
      "epoch": 0.857066381156317,
      "grad_norm": 0.0,
      "learning_rate": 2.8693790149892937e-06,
      "loss": 1.5061,
      "step": 1601
    },
    {
      "epoch": 0.8576017130620985,
      "grad_norm": 0.0,
      "learning_rate": 2.858672376873662e-06,
      "loss": 1.6262,
      "step": 1602
    },
    {
      "epoch": 0.8581370449678801,
      "grad_norm": 0.0,
      "learning_rate": 2.8479657387580302e-06,
      "loss": 1.6781,
      "step": 1603
    },
    {
      "epoch": 0.8586723768736617,
      "grad_norm": 0.0,
      "learning_rate": 2.8372591006423985e-06,
      "loss": 1.6116,
      "step": 1604
    },
    {
      "epoch": 0.8592077087794433,
      "grad_norm": 0.0,
      "learning_rate": 2.826552462526767e-06,
      "loss": 1.6933,
      "step": 1605
    },
    {
      "epoch": 0.8597430406852249,
      "grad_norm": 0.0,
      "learning_rate": 2.8158458244111354e-06,
      "loss": 1.6029,
      "step": 1606
    },
    {
      "epoch": 0.8602783725910065,
      "grad_norm": 0.0,
      "learning_rate": 2.8051391862955036e-06,
      "loss": 1.865,
      "step": 1607
    },
    {
      "epoch": 0.860813704496788,
      "grad_norm": 0.0,
      "learning_rate": 2.794432548179872e-06,
      "loss": 2.1752,
      "step": 1608
    },
    {
      "epoch": 0.8613490364025695,
      "grad_norm": 0.0,
      "learning_rate": 2.78372591006424e-06,
      "loss": 1.419,
      "step": 1609
    },
    {
      "epoch": 0.8618843683083511,
      "grad_norm": 0.0,
      "learning_rate": 2.7730192719486084e-06,
      "loss": 1.6495,
      "step": 1610
    },
    {
      "epoch": 0.8624197002141327,
      "grad_norm": 0.0,
      "learning_rate": 2.7623126338329766e-06,
      "loss": 1.6678,
      "step": 1611
    },
    {
      "epoch": 0.8629550321199143,
      "grad_norm": 0.0,
      "learning_rate": 2.7516059957173453e-06,
      "loss": 1.4179,
      "step": 1612
    },
    {
      "epoch": 0.8634903640256959,
      "grad_norm": 0.0,
      "learning_rate": 2.7408993576017136e-06,
      "loss": 1.756,
      "step": 1613
    },
    {
      "epoch": 0.8640256959314775,
      "grad_norm": 0.0,
      "learning_rate": 2.730192719486082e-06,
      "loss": 1.771,
      "step": 1614
    },
    {
      "epoch": 0.8645610278372591,
      "grad_norm": 0.0,
      "learning_rate": 2.71948608137045e-06,
      "loss": 1.5924,
      "step": 1615
    },
    {
      "epoch": 0.8650963597430407,
      "grad_norm": 0.0,
      "learning_rate": 2.7087794432548183e-06,
      "loss": 1.6004,
      "step": 1616
    },
    {
      "epoch": 0.8656316916488223,
      "grad_norm": 0.0,
      "learning_rate": 2.6980728051391865e-06,
      "loss": 1.731,
      "step": 1617
    },
    {
      "epoch": 0.8661670235546038,
      "grad_norm": 0.0,
      "learning_rate": 2.6873661670235544e-06,
      "loss": 1.4865,
      "step": 1618
    },
    {
      "epoch": 0.8667023554603854,
      "grad_norm": 0.0,
      "learning_rate": 2.6766595289079235e-06,
      "loss": 1.6087,
      "step": 1619
    },
    {
      "epoch": 0.867237687366167,
      "grad_norm": 0.0,
      "learning_rate": 2.6659528907922917e-06,
      "loss": 1.5548,
      "step": 1620
    },
    {
      "epoch": 0.8677730192719486,
      "grad_norm": 0.0,
      "learning_rate": 2.65524625267666e-06,
      "loss": 1.5574,
      "step": 1621
    },
    {
      "epoch": 0.8683083511777302,
      "grad_norm": 0.0,
      "learning_rate": 2.6445396145610282e-06,
      "loss": 1.4739,
      "step": 1622
    },
    {
      "epoch": 0.8688436830835118,
      "grad_norm": 0.0,
      "learning_rate": 2.6338329764453965e-06,
      "loss": 1.5139,
      "step": 1623
    },
    {
      "epoch": 0.8693790149892934,
      "grad_norm": 0.0,
      "learning_rate": 2.6231263383297643e-06,
      "loss": 1.6095,
      "step": 1624
    },
    {
      "epoch": 0.869914346895075,
      "grad_norm": 0.0,
      "learning_rate": 2.6124197002141325e-06,
      "loss": 1.498,
      "step": 1625
    },
    {
      "epoch": 0.8704496788008566,
      "grad_norm": 0.0,
      "learning_rate": 2.6017130620985016e-06,
      "loss": 1.5664,
      "step": 1626
    },
    {
      "epoch": 0.8709850107066381,
      "grad_norm": 0.0,
      "learning_rate": 2.59100642398287e-06,
      "loss": 1.4168,
      "step": 1627
    },
    {
      "epoch": 0.8715203426124197,
      "grad_norm": 0.0,
      "learning_rate": 2.580299785867238e-06,
      "loss": 1.4999,
      "step": 1628
    },
    {
      "epoch": 0.8720556745182013,
      "grad_norm": 0.0,
      "learning_rate": 2.5695931477516064e-06,
      "loss": 1.5941,
      "step": 1629
    },
    {
      "epoch": 0.8725910064239829,
      "grad_norm": 0.0,
      "learning_rate": 2.558886509635974e-06,
      "loss": 1.4841,
      "step": 1630
    },
    {
      "epoch": 0.8731263383297645,
      "grad_norm": 0.0,
      "learning_rate": 2.5481798715203425e-06,
      "loss": 1.4787,
      "step": 1631
    },
    {
      "epoch": 0.8736616702355461,
      "grad_norm": 0.0,
      "learning_rate": 2.5374732334047107e-06,
      "loss": 1.4198,
      "step": 1632
    },
    {
      "epoch": 0.8741970021413277,
      "grad_norm": 0.0,
      "learning_rate": 2.52676659528908e-06,
      "loss": 1.6857,
      "step": 1633
    },
    {
      "epoch": 0.8747323340471093,
      "grad_norm": 0.0,
      "learning_rate": 2.516059957173448e-06,
      "loss": 1.5745,
      "step": 1634
    },
    {
      "epoch": 0.8752676659528907,
      "grad_norm": 0.0,
      "learning_rate": 2.5053533190578163e-06,
      "loss": 1.4838,
      "step": 1635
    },
    {
      "epoch": 0.8758029978586723,
      "grad_norm": 0.0,
      "learning_rate": 2.494646680942184e-06,
      "loss": 1.5569,
      "step": 1636
    },
    {
      "epoch": 0.8763383297644539,
      "grad_norm": 0.0,
      "learning_rate": 2.4839400428265524e-06,
      "loss": 1.5463,
      "step": 1637
    },
    {
      "epoch": 0.8768736616702355,
      "grad_norm": 0.0,
      "learning_rate": 2.473233404710921e-06,
      "loss": 1.6041,
      "step": 1638
    },
    {
      "epoch": 0.8774089935760171,
      "grad_norm": 0.0,
      "learning_rate": 2.4625267665952893e-06,
      "loss": 1.5561,
      "step": 1639
    },
    {
      "epoch": 0.8779443254817987,
      "grad_norm": 0.0,
      "learning_rate": 2.4518201284796575e-06,
      "loss": 1.4438,
      "step": 1640
    },
    {
      "epoch": 0.8784796573875803,
      "grad_norm": 0.0,
      "learning_rate": 2.441113490364026e-06,
      "loss": 1.4799,
      "step": 1641
    },
    {
      "epoch": 0.8790149892933619,
      "grad_norm": 0.0,
      "learning_rate": 2.430406852248394e-06,
      "loss": 1.4537,
      "step": 1642
    },
    {
      "epoch": 0.8795503211991434,
      "grad_norm": 0.0,
      "learning_rate": 2.4197002141327623e-06,
      "loss": 1.7298,
      "step": 1643
    },
    {
      "epoch": 0.880085653104925,
      "grad_norm": 0.0,
      "learning_rate": 2.4089935760171305e-06,
      "loss": 1.5742,
      "step": 1644
    },
    {
      "epoch": 0.8806209850107066,
      "grad_norm": 0.0,
      "learning_rate": 2.398286937901499e-06,
      "loss": 1.5017,
      "step": 1645
    },
    {
      "epoch": 0.8811563169164882,
      "grad_norm": 0.0,
      "learning_rate": 2.3875802997858674e-06,
      "loss": 1.6837,
      "step": 1646
    },
    {
      "epoch": 0.8816916488222698,
      "grad_norm": 0.0,
      "learning_rate": 2.3768736616702357e-06,
      "loss": 1.5949,
      "step": 1647
    },
    {
      "epoch": 0.8822269807280514,
      "grad_norm": 0.0,
      "learning_rate": 2.366167023554604e-06,
      "loss": 1.5031,
      "step": 1648
    },
    {
      "epoch": 0.882762312633833,
      "grad_norm": 0.0,
      "learning_rate": 2.355460385438972e-06,
      "loss": 1.967,
      "step": 1649
    },
    {
      "epoch": 0.8832976445396146,
      "grad_norm": 0.0,
      "learning_rate": 2.3447537473233404e-06,
      "loss": 1.6445,
      "step": 1650
    },
    {
      "epoch": 0.8838329764453962,
      "grad_norm": 0.0,
      "learning_rate": 2.334047109207709e-06,
      "loss": 1.5979,
      "step": 1651
    },
    {
      "epoch": 0.8843683083511777,
      "grad_norm": 0.0,
      "learning_rate": 2.3233404710920774e-06,
      "loss": 2.0136,
      "step": 1652
    },
    {
      "epoch": 0.8849036402569593,
      "grad_norm": 0.0,
      "learning_rate": 2.3126338329764456e-06,
      "loss": 1.6637,
      "step": 1653
    },
    {
      "epoch": 0.8854389721627409,
      "grad_norm": 0.0,
      "learning_rate": 2.301927194860814e-06,
      "loss": 1.532,
      "step": 1654
    },
    {
      "epoch": 0.8859743040685225,
      "grad_norm": 0.0,
      "learning_rate": 2.291220556745182e-06,
      "loss": 1.4678,
      "step": 1655
    },
    {
      "epoch": 0.8865096359743041,
      "grad_norm": 0.0,
      "learning_rate": 2.2805139186295504e-06,
      "loss": 1.4185,
      "step": 1656
    },
    {
      "epoch": 0.8870449678800857,
      "grad_norm": 0.0,
      "learning_rate": 2.2698072805139186e-06,
      "loss": 1.4639,
      "step": 1657
    },
    {
      "epoch": 0.8875802997858673,
      "grad_norm": 0.0,
      "learning_rate": 2.2591006423982873e-06,
      "loss": 1.7974,
      "step": 1658
    },
    {
      "epoch": 0.8881156316916489,
      "grad_norm": 0.0,
      "learning_rate": 2.2483940042826555e-06,
      "loss": 1.6051,
      "step": 1659
    },
    {
      "epoch": 0.8886509635974305,
      "grad_norm": 0.0,
      "learning_rate": 2.2376873661670238e-06,
      "loss": 1.7761,
      "step": 1660
    },
    {
      "epoch": 0.889186295503212,
      "grad_norm": 0.0,
      "learning_rate": 2.226980728051392e-06,
      "loss": 1.5817,
      "step": 1661
    },
    {
      "epoch": 0.8897216274089935,
      "grad_norm": 0.0,
      "learning_rate": 2.2162740899357603e-06,
      "loss": 1.6562,
      "step": 1662
    },
    {
      "epoch": 0.8902569593147751,
      "grad_norm": 0.0,
      "learning_rate": 2.2055674518201285e-06,
      "loss": 1.5197,
      "step": 1663
    },
    {
      "epoch": 0.8907922912205567,
      "grad_norm": 0.0,
      "learning_rate": 2.1948608137044968e-06,
      "loss": 1.9148,
      "step": 1664
    },
    {
      "epoch": 0.8913276231263383,
      "grad_norm": 0.0,
      "learning_rate": 2.1841541755888654e-06,
      "loss": 1.5995,
      "step": 1665
    },
    {
      "epoch": 0.8918629550321199,
      "grad_norm": 0.0,
      "learning_rate": 2.1734475374732337e-06,
      "loss": 1.6018,
      "step": 1666
    },
    {
      "epoch": 0.8923982869379015,
      "grad_norm": 0.0,
      "learning_rate": 2.162740899357602e-06,
      "loss": 1.6438,
      "step": 1667
    },
    {
      "epoch": 0.892933618843683,
      "grad_norm": 0.0,
      "learning_rate": 2.15203426124197e-06,
      "loss": 1.5618,
      "step": 1668
    },
    {
      "epoch": 0.8934689507494646,
      "grad_norm": 0.0,
      "learning_rate": 2.1413276231263384e-06,
      "loss": 1.367,
      "step": 1669
    },
    {
      "epoch": 0.8940042826552462,
      "grad_norm": 0.0,
      "learning_rate": 2.1306209850107067e-06,
      "loss": 1.9338,
      "step": 1670
    },
    {
      "epoch": 0.8945396145610278,
      "grad_norm": 0.0,
      "learning_rate": 2.119914346895075e-06,
      "loss": 1.6201,
      "step": 1671
    },
    {
      "epoch": 0.8950749464668094,
      "grad_norm": 0.0,
      "learning_rate": 2.1092077087794436e-06,
      "loss": 1.4599,
      "step": 1672
    },
    {
      "epoch": 0.895610278372591,
      "grad_norm": 0.0,
      "learning_rate": 2.098501070663812e-06,
      "loss": 1.7688,
      "step": 1673
    },
    {
      "epoch": 0.8961456102783726,
      "grad_norm": 0.0,
      "learning_rate": 2.08779443254818e-06,
      "loss": 1.5552,
      "step": 1674
    },
    {
      "epoch": 0.8966809421841542,
      "grad_norm": 0.0,
      "learning_rate": 2.0770877944325484e-06,
      "loss": 1.5365,
      "step": 1675
    },
    {
      "epoch": 0.8972162740899358,
      "grad_norm": 0.0,
      "learning_rate": 2.0663811563169166e-06,
      "loss": 1.7277,
      "step": 1676
    },
    {
      "epoch": 0.8977516059957173,
      "grad_norm": 0.0,
      "learning_rate": 2.055674518201285e-06,
      "loss": 1.5926,
      "step": 1677
    },
    {
      "epoch": 0.8982869379014989,
      "grad_norm": 0.0,
      "learning_rate": 2.044967880085653e-06,
      "loss": 1.6639,
      "step": 1678
    },
    {
      "epoch": 0.8988222698072805,
      "grad_norm": 0.0,
      "learning_rate": 2.0342612419700218e-06,
      "loss": 1.5582,
      "step": 1679
    },
    {
      "epoch": 0.8993576017130621,
      "grad_norm": 0.0,
      "learning_rate": 2.02355460385439e-06,
      "loss": 1.5053,
      "step": 1680
    },
    {
      "epoch": 0.8998929336188437,
      "grad_norm": 0.0,
      "learning_rate": 2.0128479657387583e-06,
      "loss": 1.6185,
      "step": 1681
    },
    {
      "epoch": 0.9004282655246253,
      "grad_norm": 0.0,
      "learning_rate": 2.0021413276231265e-06,
      "loss": 1.5084,
      "step": 1682
    },
    {
      "epoch": 0.9009635974304069,
      "grad_norm": 0.0,
      "learning_rate": 1.9914346895074948e-06,
      "loss": 1.7921,
      "step": 1683
    },
    {
      "epoch": 0.9014989293361885,
      "grad_norm": 0.0,
      "learning_rate": 1.980728051391863e-06,
      "loss": 1.5716,
      "step": 1684
    },
    {
      "epoch": 0.9020342612419701,
      "grad_norm": 0.0,
      "learning_rate": 1.9700214132762313e-06,
      "loss": 1.368,
      "step": 1685
    },
    {
      "epoch": 0.9025695931477516,
      "grad_norm": 0.0,
      "learning_rate": 1.9593147751606e-06,
      "loss": 1.733,
      "step": 1686
    },
    {
      "epoch": 0.9031049250535332,
      "grad_norm": 0.0,
      "learning_rate": 1.948608137044968e-06,
      "loss": 1.4168,
      "step": 1687
    },
    {
      "epoch": 0.9036402569593148,
      "grad_norm": 0.0,
      "learning_rate": 1.9379014989293364e-06,
      "loss": 1.4071,
      "step": 1688
    },
    {
      "epoch": 0.9041755888650964,
      "grad_norm": 0.0,
      "learning_rate": 1.9271948608137047e-06,
      "loss": 1.568,
      "step": 1689
    },
    {
      "epoch": 0.9047109207708779,
      "grad_norm": 0.0,
      "learning_rate": 1.916488222698073e-06,
      "loss": 1.4141,
      "step": 1690
    },
    {
      "epoch": 0.9052462526766595,
      "grad_norm": 0.0,
      "learning_rate": 1.9057815845824412e-06,
      "loss": 1.8665,
      "step": 1691
    },
    {
      "epoch": 0.9057815845824411,
      "grad_norm": 0.0,
      "learning_rate": 1.8950749464668094e-06,
      "loss": 1.7527,
      "step": 1692
    },
    {
      "epoch": 0.9063169164882227,
      "grad_norm": 0.0,
      "learning_rate": 1.8843683083511779e-06,
      "loss": 1.3469,
      "step": 1693
    },
    {
      "epoch": 0.9068522483940042,
      "grad_norm": 0.0,
      "learning_rate": 1.8736616702355461e-06,
      "loss": 1.4254,
      "step": 1694
    },
    {
      "epoch": 0.9073875802997858,
      "grad_norm": 0.0,
      "learning_rate": 1.8629550321199144e-06,
      "loss": 1.6451,
      "step": 1695
    },
    {
      "epoch": 0.9079229122055674,
      "grad_norm": 0.0,
      "learning_rate": 1.8522483940042828e-06,
      "loss": 1.5777,
      "step": 1696
    },
    {
      "epoch": 0.908458244111349,
      "grad_norm": 0.0,
      "learning_rate": 1.841541755888651e-06,
      "loss": 1.496,
      "step": 1697
    },
    {
      "epoch": 0.9089935760171306,
      "grad_norm": 0.0,
      "learning_rate": 1.8308351177730193e-06,
      "loss": 1.4822,
      "step": 1698
    },
    {
      "epoch": 0.9095289079229122,
      "grad_norm": 0.0,
      "learning_rate": 1.8201284796573876e-06,
      "loss": 1.4545,
      "step": 1699
    },
    {
      "epoch": 0.9100642398286938,
      "grad_norm": 0.0,
      "learning_rate": 1.809421841541756e-06,
      "loss": 1.592,
      "step": 1700
    },
    {
      "epoch": 0.9105995717344754,
      "grad_norm": 0.0,
      "learning_rate": 1.7987152034261243e-06,
      "loss": 1.4637,
      "step": 1701
    },
    {
      "epoch": 0.911134903640257,
      "grad_norm": 0.0,
      "learning_rate": 1.7880085653104925e-06,
      "loss": 1.5699,
      "step": 1702
    },
    {
      "epoch": 0.9116702355460385,
      "grad_norm": 0.0,
      "learning_rate": 1.777301927194861e-06,
      "loss": 1.7179,
      "step": 1703
    },
    {
      "epoch": 0.9122055674518201,
      "grad_norm": 0.0,
      "learning_rate": 1.7665952890792293e-06,
      "loss": 1.4634,
      "step": 1704
    },
    {
      "epoch": 0.9127408993576017,
      "grad_norm": 0.0,
      "learning_rate": 1.7558886509635975e-06,
      "loss": 1.7257,
      "step": 1705
    },
    {
      "epoch": 0.9132762312633833,
      "grad_norm": 0.0,
      "learning_rate": 1.745182012847966e-06,
      "loss": 2.0024,
      "step": 1706
    },
    {
      "epoch": 0.9138115631691649,
      "grad_norm": 0.0,
      "learning_rate": 1.7344753747323342e-06,
      "loss": 1.6815,
      "step": 1707
    },
    {
      "epoch": 0.9143468950749465,
      "grad_norm": 0.0,
      "learning_rate": 1.7237687366167025e-06,
      "loss": 1.4343,
      "step": 1708
    },
    {
      "epoch": 0.9148822269807281,
      "grad_norm": 0.0,
      "learning_rate": 1.7130620985010707e-06,
      "loss": 1.7176,
      "step": 1709
    },
    {
      "epoch": 0.9154175588865097,
      "grad_norm": 0.0,
      "learning_rate": 1.7023554603854392e-06,
      "loss": 1.5141,
      "step": 1710
    },
    {
      "epoch": 0.9159528907922913,
      "grad_norm": 0.0,
      "learning_rate": 1.6916488222698074e-06,
      "loss": 1.4844,
      "step": 1711
    },
    {
      "epoch": 0.9164882226980728,
      "grad_norm": 0.0,
      "learning_rate": 1.6809421841541757e-06,
      "loss": 1.524,
      "step": 1712
    },
    {
      "epoch": 0.9170235546038544,
      "grad_norm": 0.0,
      "learning_rate": 1.6702355460385441e-06,
      "loss": 1.7281,
      "step": 1713
    },
    {
      "epoch": 0.917558886509636,
      "grad_norm": 0.0,
      "learning_rate": 1.6595289079229124e-06,
      "loss": 1.8031,
      "step": 1714
    },
    {
      "epoch": 0.9180942184154176,
      "grad_norm": 0.0,
      "learning_rate": 1.6488222698072806e-06,
      "loss": 1.7111,
      "step": 1715
    },
    {
      "epoch": 0.9186295503211992,
      "grad_norm": 0.0,
      "learning_rate": 1.6381156316916489e-06,
      "loss": 1.4848,
      "step": 1716
    },
    {
      "epoch": 0.9191648822269807,
      "grad_norm": 0.0,
      "learning_rate": 1.6274089935760173e-06,
      "loss": 1.8578,
      "step": 1717
    },
    {
      "epoch": 0.9197002141327623,
      "grad_norm": 0.0,
      "learning_rate": 1.6167023554603856e-06,
      "loss": 1.7048,
      "step": 1718
    },
    {
      "epoch": 0.9202355460385439,
      "grad_norm": 0.0,
      "learning_rate": 1.6059957173447538e-06,
      "loss": 1.6392,
      "step": 1719
    },
    {
      "epoch": 0.9207708779443254,
      "grad_norm": 0.0,
      "learning_rate": 1.5952890792291223e-06,
      "loss": 1.5885,
      "step": 1720
    },
    {
      "epoch": 0.921306209850107,
      "grad_norm": 0.0,
      "learning_rate": 1.5845824411134905e-06,
      "loss": 1.5073,
      "step": 1721
    },
    {
      "epoch": 0.9218415417558886,
      "grad_norm": 0.0,
      "learning_rate": 1.5738758029978588e-06,
      "loss": 1.5186,
      "step": 1722
    },
    {
      "epoch": 0.9223768736616702,
      "grad_norm": 0.0,
      "learning_rate": 1.563169164882227e-06,
      "loss": 1.5777,
      "step": 1723
    },
    {
      "epoch": 0.9229122055674518,
      "grad_norm": 0.0,
      "learning_rate": 1.5524625267665955e-06,
      "loss": 1.5382,
      "step": 1724
    },
    {
      "epoch": 0.9234475374732334,
      "grad_norm": 0.0,
      "learning_rate": 1.5417558886509637e-06,
      "loss": 1.6615,
      "step": 1725
    },
    {
      "epoch": 0.923982869379015,
      "grad_norm": 0.0,
      "learning_rate": 1.531049250535332e-06,
      "loss": 1.3531,
      "step": 1726
    },
    {
      "epoch": 0.9245182012847966,
      "grad_norm": 0.0,
      "learning_rate": 1.5203426124197005e-06,
      "loss": 1.8088,
      "step": 1727
    },
    {
      "epoch": 0.9250535331905781,
      "grad_norm": 0.0,
      "learning_rate": 1.5096359743040687e-06,
      "loss": 1.5741,
      "step": 1728
    },
    {
      "epoch": 0.9255888650963597,
      "grad_norm": 0.0,
      "learning_rate": 1.498929336188437e-06,
      "loss": 1.6222,
      "step": 1729
    },
    {
      "epoch": 0.9261241970021413,
      "grad_norm": 0.0,
      "learning_rate": 1.4882226980728054e-06,
      "loss": 1.5044,
      "step": 1730
    },
    {
      "epoch": 0.9266595289079229,
      "grad_norm": 0.0,
      "learning_rate": 1.4775160599571737e-06,
      "loss": 1.6995,
      "step": 1731
    },
    {
      "epoch": 0.9271948608137045,
      "grad_norm": 0.0,
      "learning_rate": 1.466809421841542e-06,
      "loss": 1.7818,
      "step": 1732
    },
    {
      "epoch": 0.9277301927194861,
      "grad_norm": 0.0,
      "learning_rate": 1.4561027837259102e-06,
      "loss": 1.7484,
      "step": 1733
    },
    {
      "epoch": 0.9282655246252677,
      "grad_norm": 0.0,
      "learning_rate": 1.4453961456102786e-06,
      "loss": 1.7262,
      "step": 1734
    },
    {
      "epoch": 0.9288008565310493,
      "grad_norm": 0.0,
      "learning_rate": 1.4346895074946469e-06,
      "loss": 1.5343,
      "step": 1735
    },
    {
      "epoch": 0.9293361884368309,
      "grad_norm": 0.0,
      "learning_rate": 1.4239828693790151e-06,
      "loss": 1.6232,
      "step": 1736
    },
    {
      "epoch": 0.9298715203426124,
      "grad_norm": 0.0,
      "learning_rate": 1.4132762312633836e-06,
      "loss": 1.7168,
      "step": 1737
    },
    {
      "epoch": 0.930406852248394,
      "grad_norm": 0.0,
      "learning_rate": 1.4025695931477518e-06,
      "loss": 1.6244,
      "step": 1738
    },
    {
      "epoch": 0.9309421841541756,
      "grad_norm": 0.0,
      "learning_rate": 1.39186295503212e-06,
      "loss": 1.61,
      "step": 1739
    },
    {
      "epoch": 0.9314775160599572,
      "grad_norm": 0.0,
      "learning_rate": 1.3811563169164883e-06,
      "loss": 1.5207,
      "step": 1740
    },
    {
      "epoch": 0.9320128479657388,
      "grad_norm": 0.0,
      "learning_rate": 1.3704496788008568e-06,
      "loss": 1.7098,
      "step": 1741
    },
    {
      "epoch": 0.9325481798715204,
      "grad_norm": 0.0,
      "learning_rate": 1.359743040685225e-06,
      "loss": 1.6784,
      "step": 1742
    },
    {
      "epoch": 0.933083511777302,
      "grad_norm": 0.0,
      "learning_rate": 1.3490364025695933e-06,
      "loss": 1.8451,
      "step": 1743
    },
    {
      "epoch": 0.9336188436830836,
      "grad_norm": 0.0,
      "learning_rate": 1.3383297644539617e-06,
      "loss": 1.5605,
      "step": 1744
    },
    {
      "epoch": 0.934154175588865,
      "grad_norm": 0.0,
      "learning_rate": 1.32762312633833e-06,
      "loss": 1.643,
      "step": 1745
    },
    {
      "epoch": 0.9346895074946466,
      "grad_norm": 0.0,
      "learning_rate": 1.3169164882226982e-06,
      "loss": 1.6646,
      "step": 1746
    },
    {
      "epoch": 0.9352248394004282,
      "grad_norm": 0.0,
      "learning_rate": 1.3062098501070663e-06,
      "loss": 1.85,
      "step": 1747
    },
    {
      "epoch": 0.9357601713062098,
      "grad_norm": 0.0,
      "learning_rate": 1.295503211991435e-06,
      "loss": 2.0149,
      "step": 1748
    },
    {
      "epoch": 0.9362955032119914,
      "grad_norm": 0.0,
      "learning_rate": 1.2847965738758032e-06,
      "loss": 1.8082,
      "step": 1749
    },
    {
      "epoch": 0.936830835117773,
      "grad_norm": 0.0,
      "learning_rate": 1.2740899357601712e-06,
      "loss": 2.0948,
      "step": 1750
    },
    {
      "epoch": 0.9373661670235546,
      "grad_norm": 0.0,
      "learning_rate": 1.26338329764454e-06,
      "loss": 1.5539,
      "step": 1751
    },
    {
      "epoch": 0.9379014989293362,
      "grad_norm": 0.0,
      "learning_rate": 1.2526766595289081e-06,
      "loss": 2.0943,
      "step": 1752
    },
    {
      "epoch": 0.9384368308351178,
      "grad_norm": 0.0,
      "learning_rate": 1.2419700214132762e-06,
      "loss": 1.6483,
      "step": 1753
    },
    {
      "epoch": 0.9389721627408993,
      "grad_norm": 0.0,
      "learning_rate": 1.2312633832976446e-06,
      "loss": 1.9631,
      "step": 1754
    },
    {
      "epoch": 0.9395074946466809,
      "grad_norm": 0.0,
      "learning_rate": 1.220556745182013e-06,
      "loss": 1.6744,
      "step": 1755
    },
    {
      "epoch": 0.9400428265524625,
      "grad_norm": 0.0,
      "learning_rate": 1.2098501070663811e-06,
      "loss": 1.431,
      "step": 1756
    },
    {
      "epoch": 0.9405781584582441,
      "grad_norm": 0.0,
      "learning_rate": 1.1991434689507496e-06,
      "loss": 1.4625,
      "step": 1757
    },
    {
      "epoch": 0.9411134903640257,
      "grad_norm": 0.0,
      "learning_rate": 1.1884368308351178e-06,
      "loss": 1.5116,
      "step": 1758
    },
    {
      "epoch": 0.9416488222698073,
      "grad_norm": 0.0,
      "learning_rate": 1.177730192719486e-06,
      "loss": 1.4248,
      "step": 1759
    },
    {
      "epoch": 0.9421841541755889,
      "grad_norm": 0.0,
      "learning_rate": 1.1670235546038546e-06,
      "loss": 1.5061,
      "step": 1760
    },
    {
      "epoch": 0.9427194860813705,
      "grad_norm": 0.0,
      "learning_rate": 1.1563169164882228e-06,
      "loss": 1.4876,
      "step": 1761
    },
    {
      "epoch": 0.943254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.145610278372591e-06,
      "loss": 1.6216,
      "step": 1762
    },
    {
      "epoch": 0.9437901498929336,
      "grad_norm": 0.0,
      "learning_rate": 1.1349036402569593e-06,
      "loss": 1.5535,
      "step": 1763
    },
    {
      "epoch": 0.9443254817987152,
      "grad_norm": 0.0,
      "learning_rate": 1.1241970021413278e-06,
      "loss": 1.5634,
      "step": 1764
    },
    {
      "epoch": 0.9448608137044968,
      "grad_norm": 0.0,
      "learning_rate": 1.113490364025696e-06,
      "loss": 1.6762,
      "step": 1765
    },
    {
      "epoch": 0.9453961456102784,
      "grad_norm": 0.0,
      "learning_rate": 1.1027837259100643e-06,
      "loss": 1.8063,
      "step": 1766
    },
    {
      "epoch": 0.94593147751606,
      "grad_norm": 0.0,
      "learning_rate": 1.0920770877944327e-06,
      "loss": 1.5818,
      "step": 1767
    },
    {
      "epoch": 0.9464668094218416,
      "grad_norm": 0.0,
      "learning_rate": 1.081370449678801e-06,
      "loss": 1.7372,
      "step": 1768
    },
    {
      "epoch": 0.9470021413276232,
      "grad_norm": 0.0,
      "learning_rate": 1.0706638115631692e-06,
      "loss": 1.4213,
      "step": 1769
    },
    {
      "epoch": 0.9475374732334048,
      "grad_norm": 0.0,
      "learning_rate": 1.0599571734475375e-06,
      "loss": 1.5022,
      "step": 1770
    },
    {
      "epoch": 0.9480728051391863,
      "grad_norm": 0.0,
      "learning_rate": 1.049250535331906e-06,
      "loss": 1.8159,
      "step": 1771
    },
    {
      "epoch": 0.9486081370449678,
      "grad_norm": 0.0,
      "learning_rate": 1.0385438972162742e-06,
      "loss": 1.7954,
      "step": 1772
    },
    {
      "epoch": 0.9491434689507494,
      "grad_norm": 0.0,
      "learning_rate": 1.0278372591006424e-06,
      "loss": 1.8881,
      "step": 1773
    },
    {
      "epoch": 0.949678800856531,
      "grad_norm": 0.0,
      "learning_rate": 1.0171306209850109e-06,
      "loss": 1.4063,
      "step": 1774
    },
    {
      "epoch": 0.9502141327623126,
      "grad_norm": 0.0,
      "learning_rate": 1.0064239828693791e-06,
      "loss": 1.5058,
      "step": 1775
    },
    {
      "epoch": 0.9507494646680942,
      "grad_norm": 0.0,
      "learning_rate": 9.957173447537474e-07,
      "loss": 1.453,
      "step": 1776
    },
    {
      "epoch": 0.9512847965738758,
      "grad_norm": 0.0,
      "learning_rate": 9.850107066381156e-07,
      "loss": 1.769,
      "step": 1777
    },
    {
      "epoch": 0.9518201284796574,
      "grad_norm": 0.0,
      "learning_rate": 9.74304068522484e-07,
      "loss": 1.5467,
      "step": 1778
    },
    {
      "epoch": 0.952355460385439,
      "grad_norm": 0.0,
      "learning_rate": 9.635974304068523e-07,
      "loss": 1.4902,
      "step": 1779
    },
    {
      "epoch": 0.9528907922912205,
      "grad_norm": 0.0,
      "learning_rate": 9.528907922912206e-07,
      "loss": 1.4412,
      "step": 1780
    },
    {
      "epoch": 0.9534261241970021,
      "grad_norm": 0.0,
      "learning_rate": 9.421841541755889e-07,
      "loss": 1.6042,
      "step": 1781
    },
    {
      "epoch": 0.9539614561027837,
      "grad_norm": 0.0,
      "learning_rate": 9.314775160599572e-07,
      "loss": 1.7244,
      "step": 1782
    },
    {
      "epoch": 0.9544967880085653,
      "grad_norm": 0.0,
      "learning_rate": 9.207708779443255e-07,
      "loss": 1.5647,
      "step": 1783
    },
    {
      "epoch": 0.9550321199143469,
      "grad_norm": 0.0,
      "learning_rate": 9.100642398286938e-07,
      "loss": 1.5813,
      "step": 1784
    },
    {
      "epoch": 0.9555674518201285,
      "grad_norm": 0.0,
      "learning_rate": 8.993576017130621e-07,
      "loss": 1.6058,
      "step": 1785
    },
    {
      "epoch": 0.9561027837259101,
      "grad_norm": 0.0,
      "learning_rate": 8.886509635974305e-07,
      "loss": 1.5656,
      "step": 1786
    },
    {
      "epoch": 0.9566381156316917,
      "grad_norm": 0.0,
      "learning_rate": 8.779443254817988e-07,
      "loss": 1.4945,
      "step": 1787
    },
    {
      "epoch": 0.9571734475374732,
      "grad_norm": 0.0,
      "learning_rate": 8.672376873661671e-07,
      "loss": 1.5655,
      "step": 1788
    },
    {
      "epoch": 0.9577087794432548,
      "grad_norm": 0.0,
      "learning_rate": 8.565310492505354e-07,
      "loss": 1.4754,
      "step": 1789
    },
    {
      "epoch": 0.9582441113490364,
      "grad_norm": 0.0,
      "learning_rate": 8.458244111349037e-07,
      "loss": 1.411,
      "step": 1790
    },
    {
      "epoch": 0.958779443254818,
      "grad_norm": 0.0,
      "learning_rate": 8.351177730192721e-07,
      "loss": 1.6422,
      "step": 1791
    },
    {
      "epoch": 0.9593147751605996,
      "grad_norm": 0.0,
      "learning_rate": 8.244111349036403e-07,
      "loss": 1.5829,
      "step": 1792
    },
    {
      "epoch": 0.9598501070663812,
      "grad_norm": 0.0,
      "learning_rate": 8.137044967880087e-07,
      "loss": 1.5452,
      "step": 1793
    },
    {
      "epoch": 0.9603854389721628,
      "grad_norm": 0.0,
      "learning_rate": 8.029978586723769e-07,
      "loss": 1.6536,
      "step": 1794
    },
    {
      "epoch": 0.9609207708779444,
      "grad_norm": 0.0,
      "learning_rate": 7.922912205567453e-07,
      "loss": 1.4552,
      "step": 1795
    },
    {
      "epoch": 0.961456102783726,
      "grad_norm": 0.0,
      "learning_rate": 7.815845824411135e-07,
      "loss": 1.5111,
      "step": 1796
    },
    {
      "epoch": 0.9619914346895075,
      "grad_norm": 0.0,
      "learning_rate": 7.708779443254819e-07,
      "loss": 1.5024,
      "step": 1797
    },
    {
      "epoch": 0.9625267665952891,
      "grad_norm": 0.0,
      "learning_rate": 7.601713062098502e-07,
      "loss": 1.6786,
      "step": 1798
    },
    {
      "epoch": 0.9630620985010707,
      "grad_norm": 0.0,
      "learning_rate": 7.494646680942185e-07,
      "loss": 1.7384,
      "step": 1799
    },
    {
      "epoch": 0.9635974304068522,
      "grad_norm": 0.0,
      "learning_rate": 7.387580299785868e-07,
      "loss": 1.6977,
      "step": 1800
    }
  ],
  "logging_steps": 1,
  "max_steps": 1868,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.037669683822592e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
